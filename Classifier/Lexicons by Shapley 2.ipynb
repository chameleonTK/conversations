{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DNesLV3APJ5e","executionInfo":{"status":"ok","timestamp":1710872533192,"user_tz":0,"elapsed":1945,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"f67cd8c8-24d8-4219-fbcb-4430954fead9"},"id":"DNesLV3APJ5e","execution_count":231,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/TalkLikeMom/src/Classifier"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSKW-5YdPLLp","executionInfo":{"status":"ok","timestamp":1710872533192,"user_tz":0,"elapsed":2,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"611e69b9-edc6-4bff-e269-f27b967ed6f1"},"id":"TSKW-5YdPLLp","execution_count":232,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/PHD/TalkLikeMom/src/Classifier\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('.')"],"metadata":{"id":"iGtcVVbnPLOn","executionInfo":{"status":"ok","timestamp":1710872533762,"user_tz":0,"elapsed":2,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"iGtcVVbnPLOn","execution_count":233,"outputs":[]},{"cell_type":"code","source":["# !pip install -q emoji pythainlp"],"metadata":{"id":"Ta8MgmcKPLR8","executionInfo":{"status":"ok","timestamp":1710872534275,"user_tz":0,"elapsed":1,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"Ta8MgmcKPLR8","execution_count":234,"outputs":[]},{"cell_type":"code","execution_count":235,"id":"12a2543c-adc6-4ccb-a36a-1cf4a92575e0","metadata":{"id":"12a2543c-adc6-4ccb-a36a-1cf4a92575e0","executionInfo":{"status":"ok","timestamp":1710872534621,"user_tz":0,"elapsed":1,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"outputs":[],"source":["from data_loader import get_task1_conver, get_task2_conver, preprocess\n","\n","from transformers import AutoTokenizer\n","import transformers\n","import torch\n","import numpy as np\n","import scipy as sp\n","# import shap\n","\n","from utils import dump_jsonl, load_jsonl, set_random_seed\n","# import torch\n","# from transformers import AutoModelForSequenceClassification, AdamW, BertConfig"]},{"cell_type":"code","execution_count":236,"id":"df0aab9f-76a7-4133-ad38-64586852c0fb","metadata":{"id":"df0aab9f-76a7-4133-ad38-64586852c0fb","executionInfo":{"status":"ok","timestamp":1710872536151,"user_tz":0,"elapsed":2,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"outputs":[],"source":["import pickle\n","def load_obj_values(filepath):\n","    with open(filepath, 'rb') as fin:\n","        obj = pickle.load(fin)\n","    return obj"]},{"cell_type":"code","source":["# !pip install -q pythainlp emoji==1.7"],"metadata":{"id":"hxDForvdPeNk","executionInfo":{"status":"ok","timestamp":1710862721296,"user_tz":0,"elapsed":14062,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"07b6276c-d588-41af-b968-e4ff6fc9b6f6"},"id":"hxDForvdPeNk","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"SuihU-NePwRM","executionInfo":{"status":"ok","timestamp":1710862721296,"user_tz":0,"elapsed":5,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"SuihU-NePwRM","execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":237,"id":"0d320908-70d0-40bd-a9e9-fd12fe85658a","metadata":{"id":"0d320908-70d0-40bd-a9e9-fd12fe85658a","executionInfo":{"status":"ok","timestamp":1710872539408,"user_tz":0,"elapsed":303,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"outputs":[],"source":["import emoji\n","import pythainlp\n","from emoji import UNICODE_EMOJI\n","\n","def is_emoji(s):\n","    for char in s:\n","        if char in UNICODE_EMOJI[\"en\"]:\n","            return True\n","    return False\n","\n","labelmap = {\n","    '1. Close': \"1. Close\",\n","    '2. Know each other': \"2. Acquainted\",\n","    \"3. Don't know each other\": \"3. Unfamiliar\",\n","\n","\n","    '0. Very respect': \"0. Highly Respectful\",\n","    '1. Respect': \"1. Respectful\",\n","    '2. Normal': \"2. Normal\",\n","    '3. Not respect': \"3. Disrespectful\"\n","}\n","\n","def label2newlabel(label):\n","    if type(label) is list or type(label) is np.ndarray:\n","        return [labelmap[l] if l in labelmap else l for l in label ]\n","\n","    if label in labelmap:\n","        return labelmap[label]\n","    return label\n","\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"VOa9G2ZdQF3C","executionInfo":{"status":"ok","timestamp":1710862726513,"user_tz":0,"elapsed":5,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"VOa9G2ZdQF3C","execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":245,"id":"8302ffe5-5ff9-419b-8aeb-34e92bf966dd","metadata":{"id":"8302ffe5-5ff9-419b-8aeb-34e92bf966dd","executionInfo":{"status":"ok","timestamp":1710872826440,"user_tz":0,"elapsed":943,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"01033646-5a74-4d38-ddef-893bb082b9a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 2 records from Lexicons/v3/lexicon_task1_clse.jsonl\n","Loaded 2 records from Lexicons/v3/lexicon_task2_clse.jsonl\n","Loaded 2 records from Lexicons/v3/lexicon_task3_clse.jsonl\n","Loaded 2 records from Lexicons/v3/lexicon_task1_auth.jsonl\n","Loaded 2 records from Lexicons/v3/lexicon_task2_auth.jsonl\n","Loaded 2 records from Lexicons/v3/lexicon_task3_auth.jsonl\n"]}],"source":["fn_abs = False\n","suffix = \"abs\" if fn_abs else ''\n","\n","lexicon_paths = [\n","  f\"Lexicons/v3/lexicon_task1_clse{suffix}.jsonl\",\n","  f\"Lexicons/v3/lexicon_task2_clse{suffix}.jsonl\",\n","  f\"Lexicons/v3/lexicon_task3_clse{suffix}.jsonl\",\n","\n","  f\"Lexicons/v3/lexicon_task1_auth{suffix}.jsonl\",\n","  f\"Lexicons/v3/lexicon_task2_auth{suffix}.jsonl\",\n","  f\"Lexicons/v3/lexicon_task3_auth{suffix}.jsonl\"\n","]\n","\n","def print_lexicon(lexicons, lexicons_by_feat):\n","    s = \"\"\n","    for label in sorted(lexicons.keys()):\n","        if label==\"overall\":\n","          continue\n","\n","        for lextype in [\"all\", \"pronoun\", \"particles\", \"misspelling\"]:\n","\n","          lexlabel = {\n","              \"all\": \"All\",\n","              \"pronoun\": \"Pronoun\",\n","              \"particles\": \"Sentence-final Particle\",\n","              \"misspelling\": \"Spelling Variation\",\n","          }\n","\n","\n","\n","\n","          if lextype==\"all\":\n","            s += \"            \"+label2newlabel(label) +f\" & {lexlabel[lextype]} & \"\n","            words = lexicons[label]\n","          else:\n","            s += \"            \" +f\" & {lexlabel[lextype]} & \"\n","            words = lexicons_by_feat[label][lextype]\n","\n","          sorted_words = dict(sorted(words.items(), key=lambda item: -item[1]))\n","          for k in list(sorted_words.keys())[0:10]:\n","              unique = False\n","\n","              if pythainlp.util.isthai(k):\n","                  s += \"\\\\thaitext{\"+k+\"}, \"\n","              elif is_emoji(k):\n","                  kk = \"\"\n","                  for ch in k:\n","                      if ch in UNICODE_EMOJI[\"en\"]:\n","                        ch = emoji.demojize(ch)\n","                        ch = ch.replace(\"_\", \"-\").replace(\":\", \"\")\n","                        ch = \"\\emoji{\"+ch+\"}\"\n","                        kk += ch\n","                      else:\n","                        kk += ch\n","\n","                  s += f\"{kk}, \"\n","              else:\n","                  s += f\"{k}, \"\n","\n","          s += \"\\\\\\\\\\n\"\n","\n","        s += \"            \\hline\\n\"\n","    # s += \"            \\hline\"\n","    # print(s)\n","    return s\n","\n","texts = []\n","for path in lexicon_paths:\n","  lexicons, lexicons_by_feat = load_jsonl(path)\n","  s = print_lexicon(lexicons, lexicons_by_feat)\n","  texts.append(s)\n","  # print(s)\n","  # break"]},{"cell_type":"code","execution_count":247,"id":"98122ef1-8145-4ceb-b923-e983f5ce1047","metadata":{"id":"98122ef1-8145-4ceb-b923-e983f5ce1047","executionInfo":{"status":"ok","timestamp":1710872963063,"user_tz":0,"elapsed":408,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"outputs":[],"source":["sections = [\n","    \"Setting 1: Private Conversations with Self-Reported Labels\",\n","    \"Setting 2: Public Conversations with Labels from 3rd Party \",\n","    \"Setting 3: Private Conversations with Labels from 3rd Party \",\n","]\n","\n","table_contents = [\n","    (texts[0], texts[3]),\n","    (texts[1], texts[4]),\n","    (texts[2], texts[5]),\n","]\n","\n","printed_text = \"\"\n","for section, (t1, t2) in zip(sections, table_contents):\n","\n","    printed_text += \"\\subsection{\"+section+\"}\"\n","\n","    printed_text += '''\n","\\\\begin{longtable}[h]{\n","        p{\\dimexpr 0.20\\linewidth-2\\\\tabcolsep}\n","        p{\\dimexpr 0.25\\linewidth-2\\\\tabcolsep}\n","        p{\\dimexpr 0.55\\linewidth-2\\\\tabcolsep}\n","    }\n","        \\hline\n","        Relationship Label  & Lexicon Category & Lexicons\\\\\\\\\n","        \\hline\n","        \\endfirsthead\n","        \\hline\n","        Relationship Label  & Lexicon Category & Lexicons\\\\\\\\\n","        \\hline\n","        \\endhead\n","\n","\n","        \\multicolumn{3}{l}{\\\\textit{Closeness}} \\\\\\\\\n","        \\hline\n","'''\n","    printed_text += t1\n","    printed_text += '''\n","            \\hline\n","\n","        \\multicolumn{3}{l}{\\\\textit{Respect}} \\\\\\\\\n","        \\hline\n","'''\n","\n","    printed_text += t2\n","    printed_text += '''\n","            \\hline\n","\\end{longtable}\n","\\clearpage\n","\\n\\n\n","'''\n","\n","# print(printed_text)"]},{"cell_type":"code","execution_count":null,"id":"316ec1ec-dc25-42f4-87d0-784fb39ce092","metadata":{"id":"316ec1ec-dc25-42f4-87d0-784fb39ce092"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"id":"56404aea-e87b-4672-acd9-cfd337d45460","metadata":{"id":"56404aea-e87b-4672-acd9-cfd337d45460","executionInfo":{"status":"ok","timestamp":1710862726513,"user_tz":0,"elapsed":3,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"outputs":[],"source":["# lexicon_paths = [\n","#   # \"Lexicons/v3/lexicon_task1_clse.jsonl\",\n","#   \"Lexicons/v3/lexicon_task2_clse.jsonl\",\n","#   \"Lexicons/v3/lexicon_task3_clse.jsonl\",\n","\n","#   # \"Lexicons/v3/lexicon_task1_auth.jsonl\",\n","#   # \"Lexicons/v3/lexicon_task2_auth.jsonl\",\n","#   # \"Lexicons/v3/lexicon_task3_auth.jsonl\"\n","# ]\n","\n","# allSelectedWords = set()\n","# for path in lexicon_paths:\n","#   lexicons, lexicons_by_feat = load_jsonl(path)\n","\n","#   selectedWords = set()\n","#   for cat in lexicons_by_feat:\n","#     # print(\"all\", len(lexicons[cat].keys()))\n","\n","#     keys = [k for k, v in sorted(lexicons[cat].items(), key=lambda item: -item[1])]\n","#     keys = keys[0:200]\n","#     words = set(keys)\n","#     selectedWords.update(words)\n","#   print(\"Final\", len(selectedWords))\n","\n","#   for cat in lexicons_by_feat:\n","#     # print(\"all\", len(lexicons[cat].keys()))\n","#     for f in lexicons_by_feat[cat]:\n","#       feats = set(lexicons_by_feat[cat][f].keys())\n","#       # if f==\"pronoun\":\n","#       #   print(sorted(feats))\n","#       N = len(lexicons_by_feat[cat][f].keys())\n","#       print(f, len(feats&selectedWords), N, f\"{len(feats&selectedWords)*100/N:.0f}%\")\n","\n","#   allSelectedWords.update(selectedWords)\n","#   print(\"==============\")\n","\n","# print(len(allSelectedWords))"]},{"cell_type":"code","source":["# rows = []\n","# for word in allSelectedWords:\n","#   rows.append({\n","#       \"คำ (Word)\": word,\n","#       \"สนิทกันมาก (Intimate)\": \"\",\n","#       \"สนิทกัน (Close)\": \"\",\n","#       \"แค่คนรู้จักกัน (Acquainted)\": \"\",\n","#       \"ไม่รู้จักกัน (Unfamiliar)\": \"\",\n","#       \"ไม่ชอบหน้ากัน  (Dislike)\": \"\",\n","#       \"บอกไม่ได้ (Cannot describe)\": \"\",\n","#   })\n","\n","# import pandas as pd\n","# df = pd.DataFrame(rows)\n","# df.to_csv(\"clse_lexicons.csv\", index=False)"],"metadata":{"id":"OSdWMyMtAdQe","executionInfo":{"status":"ok","timestamp":1710862726513,"user_tz":0,"elapsed":3,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"OSdWMyMtAdQe","execution_count":10,"outputs":[]},{"cell_type":"code","source":["# lexicon_paths = [\n","#   # \"Lexicons/v3/lexicon_task1_clse.jsonl\",\n","#   # \"Lexicons/v3/lexicon_task2_clse.jsonl\",\n","#   # \"Lexicons/v3/lexicon_task3_clse.jsonl\",\n","\n","#   # \"Lexicons/v3/lexicon_task1_auth.jsonl\",\n","#   \"Lexicons/v3/lexicon_task2_auth.jsonl\",\n","#   \"Lexicons/v3/lexicon_task3_auth.jsonl\"\n","# ]\n","\n","# allSelectedWords = set()\n","# for path in lexicon_paths:\n","#   lexicons, lexicons_by_feat = load_jsonl(path)\n","\n","#   selectedWords = set()\n","#   for cat in lexicons_by_feat:\n","#     # print(\"all\", len(lexicons[cat].keys()))\n","\n","#     keys = [k for k, v in sorted(lexicons[cat].items(), key=lambda item: -item[1])]\n","#     keys = keys[0:200]\n","#     words = set(keys)\n","#     selectedWords.update(words)\n","#   print(\"Final\", len(selectedWords))\n","\n","#   for cat in lexicons_by_feat:\n","#     # print(\"all\", len(lexicons[cat].keys()))\n","#     for f in lexicons_by_feat[cat]:\n","#       feats = set(lexicons_by_feat[cat][f].keys())\n","#       # if f==\"pronoun\":\n","#       #   print(sorted(feats))\n","#       N = len(lexicons_by_feat[cat][f].keys())\n","#       print(f, len(feats&selectedWords), N, f\"{len(feats&selectedWords)*100/N:.0f}%\")\n","\n","#   allSelectedWords.update(selectedWords)\n","#   print(\"==============\")\n","\n","# print(len(allSelectedWords))"],"metadata":{"id":"JnmdECRdAdT1","executionInfo":{"status":"ok","timestamp":1710862727151,"user_tz":0,"elapsed":2,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"JnmdECRdAdT1","execution_count":11,"outputs":[]},{"cell_type":"code","source":["# rows = []\n","# for word in allSelectedWords:\n","#   rows.append({\n","#       \"คำ (Word)\": word,\n","#       \"ให้เกียรติมาก (Highly Respectful)\": \"\",\n","#       \"ให้เกียรติ (Respectful)\": \"\",\n","#       \"ปกติ (Normal)\": \"\",\n","#       \"ไม่ให้เกียรติ (Disrespectful)\": \"\",\n","#       \"ไม่ให้เกียรติมาก (Highly Disrespectful)\": \"\",\n","#       \"บอกไม่ได้ (Cannot describe)\": \"\",\n","#   })\n","\n","# import pandas as pd\n","# df = pd.DataFrame(rows)\n","# df.to_csv(\"auth_lexicons.csv\", index=False)"],"metadata":{"id":"ZUQLzH8eAdXP","executionInfo":{"status":"ok","timestamp":1710862729827,"user_tz":0,"elapsed":1,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"ZUQLzH8eAdXP","execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":206,"id":"420ee96d-4d5e-4f97-9651-b706c5cde1e9","metadata":{"id":"420ee96d-4d5e-4f97-9651-b706c5cde1e9","executionInfo":{"status":"ok","timestamp":1710867222098,"user_tz":0,"elapsed":308,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"outputs":[],"source":[]},{"cell_type":"code","source":["import pandas as pd\n","hum = pd.read_csv(\"closeness_u1.csv\", skiprows=[0])\n","# hum = pd.read_csv(\"authority_u1.csv\", skiprows=[0])\n","\n","words = {}\n","columns = hum.columns\n","for idx, row in hum.iterrows():\n","  w = row[\"คำ (Word)\"]\n","\n","\n","  for col in columns:\n","    if col in [\"คำ (Word)\", \"Unnamed: 7\", \"บอกไม่ได้ \\n(Cannot describe)\"]:\n","      continue\n","\n","    if pd.isna(row[col]):\n","      continue\n","\n","    words[w] = col"],"metadata":{"id":"fmxshjo4aokO","executionInfo":{"status":"ok","timestamp":1710873278921,"user_tz":0,"elapsed":352,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"fmxshjo4aokO","execution_count":279,"outputs":[]},{"cell_type":"code","source":["# words"],"metadata":{"id":"5ErwY2K8baQl","executionInfo":{"status":"ok","timestamp":1710872985480,"user_tz":0,"elapsed":368,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"5ErwY2K8baQl","execution_count":249,"outputs":[]},{"cell_type":"code","source":["lexicon_paths = [\n","  # \"Lexicons/v3/lexicon_task1_clse.jsonl\",\n","  \"Lexicons/v3/lexicon_task2_clse.jsonl\",\n","  \"Lexicons/v3/lexicon_task3_clse.jsonl\",\n","\n","  # \"Lexicons/v3/lexicon_task1_auth.jsonl\",\n","  # \"Lexicons/v3/lexicon_task2_auth.jsonl\",\n","  # \"Lexicons/v3/lexicon_task3_auth.jsonl\"\n","]\n","\n","data = []\n","\n","\n","for path in lexicon_paths:\n","  lexicons, lexicons_by_feat = load_jsonl(path)\n","  for cat in lexicons:\n","\n","    keys = [k for k, v in sorted(lexicons[cat].items(), key=lambda item: -item[1])]\n","    keys = keys[0:200]\n","\n","    for w in keys:\n","      if w not in words:\n","        continue\n","\n","      scores = {\n","        'ไม่ชอบหน้ากัน  (Dislike)': -2,\n","        'ไม่รู้จักกัน (Unfamiliar)': -1,\n","        'แค่คนรู้จักกัน (Acquainted)': 0,\n","        'สนิทกัน (Close)': 1,\n","        'สนิทกันมาก (Intimate)': 2,\n","\n","        'ให้เกียรติมาก \\n(Highly Respectful)': 2,\n","        'ให้เกียรติ (Respectful)': 1,\n","        'ปกติ \\n(Normal)': 0,\n","        'ไม่ให้เกียรติ (Disrespectful)': -1,\n","        'ไม่ให้เกียรติมาก (Highly Disrespectful)': -2,\n","      }\n","\n","      data.append({\n","          \"word\": w,\n","          \"human\": words[w],\n","          \"human_score\": scores[words[w]],\n","          \"shapley\": (lexicons[cat][w]),\n","          \"category\": cat,\n","          \"path\": path\n","      })\n","\n","df = pd.DataFrame(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SxP9m8wgXbyh","executionInfo":{"status":"ok","timestamp":1710873281495,"user_tz":0,"elapsed":332,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"ffc6da0b-3151-4efd-bd11-728148290baf"},"id":"SxP9m8wgXbyh","execution_count":280,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 2 records from Lexicons/v3/lexicon_task2_clse.jsonl\n","Loaded 2 records from Lexicons/v3/lexicon_task3_clse.jsonl\n"]}]},{"cell_type":"code","source":["# df"],"metadata":{"id":"7UhLIFj4coci","executionInfo":{"status":"ok","timestamp":1710873283032,"user_tz":0,"elapsed":441,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"7UhLIFj4coci","execution_count":281,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pXf0KBJsXazf","executionInfo":{"status":"ok","timestamp":1710873283354,"user_tz":0,"elapsed":2,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"pXf0KBJsXazf","execution_count":281,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kQS4l_GOXa2W","executionInfo":{"status":"ok","timestamp":1710873283734,"user_tz":0,"elapsed":13,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"kQS4l_GOXa2W","execution_count":282,"outputs":[]},{"cell_type":"code","source":["o = [\n","    'ไม่ชอบหน้ากัน  (Dislike)',\n","    'ไม่รู้จักกัน (Unfamiliar)',\n","    'แค่คนรู้จักกัน (Acquainted)',\n","    'สนิทกัน (Close)',\n","    'สนิทกันมาก (Intimate)',\n","]\n","\n","ho = [ '1. Close', '2. Know each other', \"3. Don't know each other\", \"overall\"]\n","\n","from scipy import stats\n","for path in lexicon_paths:\n","  d1 = df[df[\"path\"]==path]\n","  # print(path)\n","  # res = stats.spearmanr(d1[\"human_score\"], d1[\"shapley\"])\n","  # print(f\"Overall Corr {res.statistic:.3f} {res.pvalue:.3f}\")\n","\n","  for c in ho:\n","    dd = d1[d1[\"category\"]==c]\n","    # v = (dd.corr(\"spearman\", numeric_only=True))\n","    # print(dd.groupby(\"human\").count()[\"word\"])\n","    res = stats.spearmanr(dd[\"human_score\"], dd[\"shapley\"])\n","    print(f\"{c} {res.statistic:.3f} {res.pvalue:.3f}\")\n","  print(\"=======\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YrFus_iZjobz","executionInfo":{"status":"ok","timestamp":1710873299248,"user_tz":0,"elapsed":308,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"523fdf97-d4db-4dbe-9ced-eb5d717a5796"},"id":"YrFus_iZjobz","execution_count":283,"outputs":[{"output_type":"stream","name":"stdout","text":["1. Close 0.065 0.457\n","2. Know each other 0.222 0.013\n","3. Don't know each other 0.109 0.203\n","overall 0.158 0.057\n","=======\n","1. Close 0.111 0.232\n","2. Know each other 0.044 0.665\n","3. Don't know each other 0.097 0.348\n","overall 0.053 0.575\n","=======\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"DrcsE0Qdo_ZH","executionInfo":{"status":"ok","timestamp":1710873017041,"user_tz":0,"elapsed":349,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"DrcsE0Qdo_ZH","execution_count":256,"outputs":[]},{"cell_type":"code","source":["o = [\n","    'ให้เกียรติมาก \\n(Highly Respectful)',\n","    'ให้เกียรติ (Respectful)',\n","    'ปกติ \\n(Normal)',\n","    'ไม่ให้เกียรติ (Disrespectful)',\n","    'ไม่ให้เกียรติมาก (Highly Disrespectful)',\n","]\n","\n","ho = ['1. Respect', '2. Normal', '3. Not respect', \"overall\"]\n","\n","from scipy import stats\n","for path in lexicon_paths:\n","  d1 = df[df[\"path\"]==path]\n","  # print(path)\n","  # res = stats.spearmanr(d1[\"human_score\"], d1[\"shapley\"])\n","  # print(f\"Overall Corr {res.statistic:.3f} {res.pvalue:.3f}\")\n","\n","  for c in ho:\n","    dd = d1[d1[\"category\"]==c]\n","    # v = (dd.corr(\"spearman\", numeric_only=True))\n","    # print(dd.groupby(\"human\").count()[\"word\"])\n","    res = stats.spearmanr(dd[\"human_score\"], dd[\"shapley\"])\n","    print(f\"{c} {res.statistic:.3f} {res.pvalue:.3f}\")\n","  print(\"=======\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sISYbibTo0-d","executionInfo":{"status":"ok","timestamp":1710873270322,"user_tz":0,"elapsed":315,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"e700bffa-f131-4d22-ccd6-07fb042bbe91"},"id":"sISYbibTo0-d","execution_count":278,"outputs":[{"output_type":"stream","name":"stdout","text":["1. Respect 0.078 0.288\n","2. Normal 0.141 0.053\n","3. Not respect -0.021 0.777\n","overall 0.165 0.025\n","=======\n","1. Respect 0.091 0.207\n","2. Normal -0.057 0.431\n","3. Not respect 0.055 0.447\n","overall -0.054 0.460\n","=======\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GPN5y0vf_UR2","executionInfo":{"status":"ok","timestamp":1710873215194,"user_tz":0,"elapsed":410,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"GPN5y0vf_UR2","execution_count":275,"outputs":[]},{"cell_type":"code","source":["# import matplotlib.pyplot as plt\n","# print(ho[0])\n","# # dd = df[df[\"category\"]==ho[0]]\n","# # dd = df\n","# plot = sns.violinplot(data=dd, x=\"human\", y=\"shapley\", order=o, hue_order=ho)"],"metadata":{"id":"6lqn3EbBXa5N","executionInfo":{"status":"ok","timestamp":1710873394234,"user_tz":0,"elapsed":352,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"6lqn3EbBXa5N","execution_count":285,"outputs":[]},{"cell_type":"code","source":["# dd = df[df[\"category\"]==ho[1]]\n","# plot = sns.violinplot(data=dd, x=\"human\", y=\"shapley\", order=o, hue_order=ho)"],"metadata":{"id":"E4_HAz9NXa8F","executionInfo":{"status":"ok","timestamp":1710873151673,"user_tz":0,"elapsed":338,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"E4_HAz9NXa8F","execution_count":272,"outputs":[]},{"cell_type":"code","source":["# dd = df[df[\"category\"]==ho[2]]\n","# plot = sns.violinplot(data=dd, x=\"human\", y=\"shapley\", order=o, hue_order=ho)"],"metadata":{"id":"aXGjcXbaXa-r","executionInfo":{"status":"ok","timestamp":1710873149359,"user_tz":0,"elapsed":371,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"aXGjcXbaXa-r","execution_count":271,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"s2io-lrjXbBj","executionInfo":{"status":"ok","timestamp":1710865768590,"user_tz":0,"elapsed":302,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"s2io-lrjXbBj","execution_count":143,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Mt7-C4ykXbE8"},"id":"Mt7-C4ykXbE8","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"440b2123-4393-4a0d-99ad-053aa728d4e6","metadata":{"id":"440b2123-4393-4a0d-99ad-053aa728d4e6"},"outputs":[],"source":["# from scipy import stats\n","# import pandas as pd\n","\n","# def cal_corr(shap_lexicons, weights, label_fn):\n","#     df = []\n","#     for label in shap_lexicons:\n","#         count = defaultdict(int)\n","#         for w in shap_lexicons[label]:\n","#             if w not in lexicons:\n","#                 continue\n","\n","#             for t in lexicons[w]:\n","#                 count[t] += 1\n","\n","#         l = label_fn(label)\n","#         A = []\n","#         B = []\n","#         for feat in count:\n","#             k = (l, feat)\n","#             if k in weights and weights[k]!=\"\":\n","#                 A.append(weights[k])\n","#                 B.append(count[feat])\n","\n","#         spm = stats.spearmanr(A, B)\n","#         df.append({\n","#             \"label\": label,\n","#             \"N\": len(A),\n","#             \"spearman\": spm.statistic,\n","#             \"pvalue\": spm.pvalue\n","#         })\n","\n","#     return pd.DataFrame(df)"]},{"cell_type":"code","execution_count":null,"id":"a1fe937c-da1f-4854-b4cb-057c5ea3e41a","metadata":{"id":"a1fe937c-da1f-4854-b4cb-057c5ea3e41a"},"outputs":[],"source":["# shap_lexicons = load_jsonl(\"Classifier/lexicon_task1_clse.jsonl\")[0]\n","# weights = load_obj_values(\"linear_weights_task1_clse.pkl\")\n","\n","# cal_corr(shap_lexicons, weights, closeness_to_eng1)"]},{"cell_type":"code","execution_count":null,"id":"4a40ee15-75cd-462a-9f47-a10d61c9477d","metadata":{"id":"4a40ee15-75cd-462a-9f47-a10d61c9477d"},"outputs":[],"source":["# lexicon_paths = [\n","#   \"Lexicons/v3/lexicon_task1_clse.jsonl\",\n","#   \"Lexicons/v3/lexicon_task2_clse.jsonl\",\n","#   \"Lexicons/v3/lexicon_task3_clse.jsonl\",\n","\n","#   \"Lexicons/v3/lexicon_task1_auth.jsonl\",\n","#   \"Lexicons/v3/lexicon_task2_auth.jsonl\",\n","#   \"Lexicons/v3/lexicon_task3_auth.jsonl\"\n","# ]\n","\n","# texts = []\n","# for path in lexicon_paths:\n","#   lexicons, lexicons_by_feat = load_jsonl(path)\n","#   print(path)\n","\n","\n","#   N = 20\n","#   count = {}\n","#   # dict_keys(['pronoun', 'particles', 'misspelling'])\n","#   for cat in lexicons_by_feat:\n","#     for idx, w in enumerate(lexicons_by_feat[cat][\"pronoun\"]):\n","#       if idx >= N:\n","#         break\n","\n","#       if w in count:\n","#         count[w].append(idx)\n","#       else:\n","#         count[w] = [idx]\n","\n","#   words = {\n","#       (1, \"same\"):[],\n","#       (1, \"div\"):[],\n","#       (2, \"same\"):[],\n","#       (2, \"div\"):[],\n","#       (3, \"same\"):[],\n","#       (3, \"div\"):[],\n","#   }\n","#   for w in count:\n","#     n = len(count[w])\n","\n","#     if n==1:\n","#       words[(n, \"same\")].append(w)\n","#     elif n>=2:\n","#       # print(w, count[w])\n","#       mx = max(count[w])\n","#       mn = min(count[w])\n","\n","#       if mx-mn > 5:\n","#         words[(n, \"div\")].append((w, count[w]))\n","#       else:\n","#         words[(n, \"same\")].append((w, count[w]))\n","\n","#   for n in words:\n","#     print(n, len(words[n]))\n","#     print(words[n])\n","#     print()\n","#   print(\"------------------\")"]},{"cell_type":"code","source":["# !wget -q http://www.arts.chula.ac.th/ling/wp-content/uploads/TH-Sarabun_Chula1.1.zip -O font.zip\n","# !unzip -qj font.zip TH-Sarabun_Chula1.1/THSarabunChula-Regular.ttf\n","\n","import matplotlib\n","matplotlib.font_manager.fontManager.addfont('THSarabunChula-Regular.ttf')\n","matplotlib.rc('font', family='TH Sarabun Chula')\n"],"metadata":{"id":"NRNAYi8yCv6d","executionInfo":{"status":"ok","timestamp":1710864357146,"user_tz":0,"elapsed":891,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"NRNAYi8yCv6d","execution_count":69,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","import pandas as pd\n","\n","def quadrant_chart(x, y, xtick_labels=None, ytick_labels=None, data_labels=None,\n"," highlight_quadrants=None, ax=None):\n","    \"\"\"\n","    Create the classic four-quadrant chart.\n","    Args:\n","        x -- array-like, the x-coordinates to plot\n","        y -- array-like, the y-coordinates to plot\n","        xtick_labels -- list, default: None, a two-value list xtick labels\n","        ytick_labels -- list, default: None, a two-value list of ytick labels\n","        data_labels -- array-like, default: None, data point annotations\n","        highlight_quadrants -- list, default: None, list of quadrants to\n","            emphasize (quadrants are numbered 1-4)\n","        ax -- matplotlib.axes object, default: None, the user can pass their own\n","            axes object if desired\n","    \"\"\"\n","    # allow user to specify their own axes\n","    ax = ax if ax else plt.axes()\n","\n","    data = pd.DataFrame({'x': x, 'y': y, 'data_labels': data_labels})\n","\n","    # calculate averages up front to avoid repeated calculations\n","    y_avg = data['y'].mean()\n","    x_avg = data['x'].mean()\n","\n","    # set x limits\n","    adj_x = max((data['x'].max() - x_avg), (x_avg - data['x'].min())) * 1.1\n","    lb_x, ub_x = (x_avg - adj_x, x_avg + adj_x)\n","    ax.set_xlim(lb_x, ub_x)\n","\n","    # set y limits\n","    adj_y = max((data['y'].max() - y_avg), (y_avg - data['y'].min())) * 1.1\n","    lb_y, ub_y = (y_avg - adj_y, y_avg + adj_y)\n","    ax.set_ylim(lb_y, ub_y)\n","\n","    # set x tick labels\n","    if xtick_labels:\n","        ax.set_xticks([(x_avg - adj_x / 2), (x_avg + adj_x / 2)])\n","        ax.set_xticklabels(xtick_labels)\n","\n","    # set y tick labels\n","    if ytick_labels:\n","        ax.set_yticks([(y_avg - adj_y / 2), (y_avg + adj_y / 2)])\n","        ax.set_yticklabels(ytick_labels, rotation='vertical', va='center')\n","\n","    # determine which points to highlight\n","    if highlight_quadrants:\n","        quadrants = []\n","        for x_val, y_val in zip(x, y):\n","            q = []\n","            if (x_val >= x_avg) and (y_val >= y_avg):\n","                q.append(1)\n","            if (x_val <= x_avg) and (y_val >= y_avg):\n","                q.append(2)\n","            if (x_val <= x_avg) and (y_val <= y_avg):\n","                q.append(3)\n","            if (x_val >= x_avg) and (y_val <= y_avg):\n","                q.append(4)\n","            quadrants.append(q)\n","        data['quadrant'] = quadrants\n","\n","        # boolean mask - True = highlight, False = don't highlight\n","        highlight = data['quadrant'].apply(lambda q: len(set(\n","        highlight_quadrants) & set(q)) > 0)\n","\n","        # plot the non-highlighted points within the conditional block\n","        ax.scatter(data['x'][~highlight], data['y'][~highlight], alpha=0.5,\n","        c='lightblue', edgecolor='darkblue', zorder=99)\n","        data = data[highlight]\n","\n","    # plot remaining points and quadrant lines\n","    ax.scatter(x=data['x'], y=data['y'], c='lightblue', edgecolor='darkblue',\n","    zorder=99)\n","    ax.axvline(x_avg, c='k', lw=1)\n","    ax.axhline(y_avg, c='k', lw=1)\n","\n","    # add data labels\n","    for ix, row in data.iterrows():\n","        ax.annotate(row['data_labels'], (row['x'], row['y']), xytext=(2, 5),\n","        textcoords='offset pixels')"],"metadata":{"id":"OnymKicLCyZg"},"id":"OnymKicLCyZg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# lexicon_paths = [\n","#   \"Lexicons/v3/lexicon_task1_clse.jsonl\",\n","#   \"Lexicons/v3/lexicon_task2_clse.jsonl\",\n","#   \"Lexicons/v3/lexicon_task3_clse.jsonl\",\n","\n","#   \"Lexicons/v3/lexicon_task1_auth.jsonl\",\n","#   \"Lexicons/v3/lexicon_task2_auth.jsonl\",\n","#   \"Lexicons/v3/lexicon_task3_auth.jsonl\"\n","# ]\n","\n","# import numpy as np\n","\n","# texts = []\n","# for path in lexicon_paths:\n","#   lexicons, lexicons_by_feat = load_jsonl(path)\n","#   print(path)\n","\n","\n","#   N = 50\n","#   count = {}\n","#   # dict_keys(['pronoun', 'particles', 'misspelling'])\n","#   for cat in lexicons_by_feat:\n","#     for idx, w in enumerate(lexicons_by_feat[cat][\"misspelling\"]):\n","#       if idx >= N:\n","#         break\n","\n","#       if w in count:\n","#         count[w].append(idx)\n","#       else:\n","#         count[w] = [idx]\n","\n","#   words = []\n","#   points = []\n","\n","#   for w in count:\n","#     n = len(count[w])\n","\n","#     if n==1:\n","#       x = count[w][0]\n","#       y = 0\n","#       continue\n","#     elif n>=2:\n","#       x = np.mean(count[w])\n","#       y = np.std(count[w])\n","#     points.append((x, y, w))\n","\n","\n","\n","#   # plt.rcParams.update({'font.size': 25})\n","#   x = [p1 for p1, p2, _ in points]\n","#   y = [p2 for p1, p2, _ in points]\n","#   l = [p3 for p1, p2, p3 in points]\n","\n","#   quadrant_chart(\n","#       x=x,\n","#       y=y,\n","#       xtick_labels=['Top', 'Bottom'],\n","#       ytick_labels=['Low', 'High'],\n","#       data_labels=l,\n","#       # highlight_quadrants=[2]\n","#   )\n","#   plt.title('', fontsize=16)\n","#   plt.ylabel('Variance', fontsize=14)\n","#   plt.xlabel('Average Rank', fontsize=14)\n","#   plt.show()\n","#   plt.clf()\n","#   # break"],"metadata":{"id":"UEbjwSTV05_A","executionInfo":{"status":"ok","timestamp":1710864367078,"user_tz":0,"elapsed":419,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"id":"UEbjwSTV05_A","execution_count":70,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"egNo9WQF_c0Q"},"id":"egNo9WQF_c0Q","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"meZwciVh1BdN"},"id":"meZwciVh1BdN","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QwiKFYSc2MjH"},"id":"QwiKFYSc2MjH","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZpHbcQI1B8sQ"},"id":"ZpHbcQI1B8sQ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}