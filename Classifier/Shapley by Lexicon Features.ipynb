{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826189f6-f662-4078-b677-686f7866488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import get_task1_conver, get_task2_conver\n",
    "from utils import dump_jsonl, load_jsonl\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "def load_shap_values(filepath):\n",
    "  with open(filepath, 'rb') as fin:\n",
    "    obj = pickle.load(fin)\n",
    "  return obj\n",
    "\n",
    "def save_shap_values(filepath, obj):\n",
    "  with open(filepath, 'wb') as fin:\n",
    "    pickle.dump(obj, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae1169a-3167-4ba9-b958-f9135805f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666cb3a3-2ec9-4842-870a-b89b96f75e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "num_added_toks = tokenizer.add_special_tokens({\"additional_special_tokens\": [\"usr\", \"sys\", \"rep\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8edb0a8-9802-47dc-bed9-b2189b1fe41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7cec2-f5eb-4a72-9cb0-b6d88e97707e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53dd5afe-b3b9-484e-8628-c9d0c60c3122",
   "metadata": {},
   "source": [
    "## Load Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52407bf-66ad-4a78-b7ff-cecd72d64d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345c8438-4810-453d-8e69-a7c2504e5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../words.json\", encoding=\"utf-8\") as fin:\n",
    "    raw = json.load(fin)\n",
    "    thaidict_royal = set()\n",
    "    for k in raw:\n",
    "        thaidict_royal.update(raw[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07775b4b-a694-471c-9e00-07157af10be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25573 records from ../lexicons.jsonl\n"
     ]
    }
   ],
   "source": [
    "lexicons_arr = load_jsonl(\"../lexicons.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99344938-fa6d-48cf-97e2-04aa8353adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "tags = set()\n",
    "lexicons = {}\n",
    "lexicons_keys = defaultdict(list)\n",
    "\n",
    "for key, values  in lexicons_arr:\n",
    "    if len(key) <= 1:\n",
    "        continue\n",
    "        \n",
    "    key = key.lower()\n",
    "    if key.endswith(\"rep\"):\n",
    "        key = key.replace(\"rep\", \"\")\n",
    "        \n",
    "    w = word_tokenize(key)\n",
    "    \n",
    "    lexicons_keys[w[0]].append(key)\n",
    "    \n",
    "    tag = [t for t in values[\"tags\"] if not t.startswith(\"cat:\")]\n",
    "    lexicons[key] = tag\n",
    "    tags.update(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad5b26e3-65f2-4adf-8901-dd81f83d7dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = 0\n",
    "for k in lexicons:\n",
    "    for t in lexicons[k]:\n",
    "        if t==\"transliterated\":\n",
    "            cc += 1\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25524732-2d62-4a46-b49a-e7dded1affbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74004a85-74b4-4e91-82a9-e71d60abb0aa",
   "metadata": {},
   "source": [
    "## Calculate Shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd74d9f2-c5cc-4c07-9b55-618539ecca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = {\n",
    "    \"Reference\" : {\n",
    "        \"all\": \"All words\",\n",
    "        \"pertoken\": \"Average per token\"\n",
    "    },\n",
    "    \n",
    "    \"Linguistic Complexity\" : {\n",
    "        \"nthai\": \"Code-switching\",\n",
    "        \"nlongword\": \"Long words\",\n",
    "        \"ndict\": \"Dictionary words\",\n",
    "        \"transliterated\": \"Transliteration\",\n",
    "    },\n",
    "    \"Pronoun\": {\n",
    "        \"pronoun\": \"All pronoun\",\n",
    "        \"pronoun_1st\": \">> 1st person pronoun\",\n",
    "        \"pronoun_2nd\": \">> 2nd person pronoun\",\n",
    "        \"pronoun_3rd\": \">> 3rd person pronoun\",\n",
    "        \"pronoun_misspelling\": \">> Pronoun in non-standard spelling\",\n",
    "    },\n",
    "    \n",
    "    \"Sentence-ending Particles\": {\n",
    "        \"particles\": \"All particles\",\n",
    "        \"particles_SARP\": \">> Socially-related particles\",\n",
    "        \"particles_notSARP\": \">> Non-socially-related particles\",\n",
    "        \"particles_misspelling\": \">> Particle in non-standard spelling\",\n",
    "    },\n",
    "    \n",
    "    \"Sentiment-related\": {\n",
    "        \"sentiment\": \"Sentiment words\",\n",
    "        \"sentiment_positive\": \">> Positive words\",\n",
    "        \"sentiment_negative\": \">> Negative words\",\n",
    "    },\n",
    "    \n",
    "    \"Spelling variation\": {\n",
    "        \"misspelling\": \"Spelling variation\",\n",
    "        \"misspelling_common\": \">> Common misspelt words\",\n",
    "        \"misspelling_intention\": \">> Morphophonemic variation\",\n",
    "        \"misspelling_shorten\": \">> Simplified variation\",\n",
    "        \"nrepeat\": \">> Repeated characters\",\n",
    "    },\n",
    "    \"Other Common Internet Lexicons\": {\n",
    "        \"abbr\": \"Abbreviation\",\n",
    "#         \"slang\": \"Slang\",\n",
    "        \"swear\": \"Swear words\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2702eead-4dbf-41bc-80a5-d59c87993d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_token_2_words(words, shap_tokens, debug=False):\n",
    "    tokens = [w for w, _ in  shap_tokens]\n",
    "    values = np.array([v for _, v in  shap_tokens])\n",
    "    \n",
    "    idxs = []\n",
    "    sidx = 0\n",
    "    windows = 10\n",
    "        \n",
    "    newwords = []\n",
    "    newtokens = []\n",
    "    newvalues = []\n",
    "    \n",
    "    \n",
    "    widx = 0\n",
    "    w = \"\"\n",
    "    while widx < len(words):\n",
    "        w += words[widx]\n",
    "        if sidx >= len(tokens):\n",
    "#             print(newwords)\n",
    "#             assert(False)\n",
    "            break\n",
    "            \n",
    "#         print(widx, w, sidx, tokens[sidx])\n",
    "#         break\n",
    "        s = \"\"\n",
    "        matched = False\n",
    "        for tidx in range(sidx, min(sidx+windows, len(tokens))):\n",
    "            s += tokens[tidx]\n",
    "            if s==w:\n",
    "                matched = True\n",
    "                break\n",
    "                \n",
    "        if matched:\n",
    "            if debug:\n",
    "                print(\"MATCHED\", w)\n",
    "            idxs.append([sidx, tidx+1])\n",
    "            newwords.append(w)\n",
    "            newtokens.append(\"\".join(tokens[sidx:tidx+1]))\n",
    "            newvalues.append(values[sidx:tidx+1].sum())\n",
    "            sidx = tidx+1\n",
    "            w = \"\"\n",
    "            widx += 1\n",
    "            continue\n",
    "        \n",
    "        if debug:\n",
    "            print(\"NOT MATCHED\", w, s)\n",
    "            \n",
    "        if not s.startswith(w):\n",
    "            sidx += 1\n",
    "            w = \"\"\n",
    "#             print(\"SKIP TOKEN\")\n",
    "            continue\n",
    "        else:                \n",
    "            widx += 1\n",
    "#             print(\"MERGE WORDS\")\n",
    "            continue\n",
    "            \n",
    "    if debug:    \n",
    "        print(newwords)\n",
    "        print(newtokens)\n",
    "    \n",
    "    \n",
    "    return newtokens, newvalues\n",
    "\n",
    "def get_shap_lexicons(df, raw_shap_values):\n",
    "    shap_lexicons = {}\n",
    "    label_values = df[\"label\"].unique()\n",
    "    \n",
    "\n",
    "    _tmp = raw_shap_values[:, :]\n",
    "    shap_data = _tmp.data\n",
    "    shap_values = _tmp.values\n",
    "\n",
    "    for _, label in enumerate(label_values):\n",
    "        feats = []\n",
    "        for idx, row in df.iterrows():\n",
    "            if row[\"label\"]!=label:\n",
    "                continue\n",
    "            \n",
    "            text = row[\"text\"]\n",
    "            words = word_tokenize(preprocess(row[\"text\"]))\n",
    "            words = [w.strip() for w in words if len(w.strip())>0]\n",
    "            \n",
    "            shap_tokens = [(w.strip(), v) for w,v in zip(shap_data[idx], shap_values[idx]) if len(w.strip())>0]\n",
    "            shap_tokens = map_token_2_words(words, shap_tokens, debug=False)\n",
    "            feats.append(shap_tokens)\n",
    "        shap_lexicons[label] = feats\n",
    "    return shap_lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d5717b6-9cf1-4ee6-bf34-71a650055789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.util import countthai\n",
    "\n",
    "def get_lexicon_feats(token, ref_text):\n",
    "    \n",
    "    if token not in lexicons_keys:\n",
    "        return []\n",
    "    \n",
    "    feats = [\"all\"]\n",
    "    for l in lexicons_keys[token]:\n",
    "        if not ref_text.startswith(l):\n",
    "            continue\n",
    "        \n",
    "        feats.extend(lexicons[l])\n",
    "    \n",
    "    if token==\"rep\":\n",
    "        assert(False)\n",
    "        feats.append(\"nrepeat\")\n",
    "    \n",
    "    if token in thaidict_royal:\n",
    "        feats.append(\"ndict\")\n",
    "    \n",
    "    if len(token) > 7:\n",
    "        feats.append(\"nlongword\")\n",
    "    \n",
    "    if countthai(token) > 50:\n",
    "        feats.append(\"nthai\")\n",
    "        \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22de286d-e8d1-4402-aa6d-1f17f66ff010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_feats(shap_lexicons):\n",
    "    output = {}\n",
    "    for label in shap_lexicons:\n",
    "        all_shap_feats = []\n",
    "        for tokens, values in shap_lexicons[label]:\n",
    "            shap_feats = defaultdict(int)\n",
    "            for tidx, (t, v) in enumerate(zip(tokens, values)):\n",
    "                feats = get_lexicon_feats(t, \"\".join(tokens[tidx:]))\n",
    "                    \n",
    "                for f in feats:\n",
    "                    shap_feats[f] += v\n",
    "            \n",
    "            shap_feats[\"pertoken\"] = sum(values)/len(values)\n",
    "            all_shap_feats.append(shap_feats)\n",
    "            \n",
    "        mean_shap_feats = {}\n",
    "        for g in metric_names:\n",
    "            for m in metric_names[g]:\n",
    "                values = []\n",
    "                for feats in all_shap_feats:\n",
    "                    if m in feats:\n",
    "                        values.append(feats[m])\n",
    "                \n",
    "                if len(values)==0:\n",
    "                    mean_shap_feats[m] = 0\n",
    "                    continue\n",
    "                    \n",
    "                values = np.array(values)\n",
    "                rms = np.sqrt(np.mean(values**2))\n",
    "                mean_shap_feats[m] = rms\n",
    "        \n",
    "        output[label] = mean_shap_feats\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5bff40ac-916b-4112-8515-f9fc1e074186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38d92ffa-4e27-4dc7-86ff-bdf87a52907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "from data_loader import preprocess\n",
    "\n",
    "def run_preprocess(train, val, test):\n",
    "    train[\"text\"] = train[\"text\"].apply(preprocess)\n",
    "    val[\"text\"] = val[\"text\"].apply(preprocess)\n",
    "    test[\"text\"] = test[\"text\"].apply(preprocess)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4247e-6a21-4fdf-ae2d-8bed8674f10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24a91f89-942a-4214-9c3d-b24e70d17e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lexicons(df, shap_path):\n",
    "    train, val, test = df\n",
    "    train[\"split\"] = \"train\"\n",
    "    val[\"split\"] = \"val\"\n",
    "    test[\"split\"] = \"test\"\n",
    "\n",
    "    df = pd.concat([train, test, val])\n",
    "    shap_values = load_shap_values(shap_path)\n",
    "\n",
    "    assert(len(df)==len(shap_values))\n",
    "    \n",
    "    shap_lexicons = get_shap_lexicons(df, shap_values)\n",
    "    shap_feats = get_shap_feats(shap_lexicons)\n",
    "    return shap_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c0cc5-c51a-4397-bbad-8986f83686f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c0bd5f35-d78d-46fd-98bd-1e761348178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1234 records from ../Task1/annotated_conersations.jsonl\n",
      "N 1096 60 60\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.util import countthai\n",
    "\n",
    "def get_lexicon_feats(token, ref_text):\n",
    "    feats = [\"all\"]\n",
    "    \n",
    "    if token==\"rep\":\n",
    "        feats.append(\"nrepeat\")\n",
    "        \n",
    "    if token in lexicons_keys:\n",
    "        for l in lexicons_keys[token]:\n",
    "            if not ref_text.startswith(l):\n",
    "                continue\n",
    "\n",
    "            feats.extend(lexicons[l])\n",
    "            \n",
    "    if token in thaidict_royal:\n",
    "        feats.append(\"ndict\")\n",
    "    \n",
    "    if len(token) > 7:\n",
    "        feats.append(\"nlongword\")\n",
    "    \n",
    "    if countthai(token) > 50:\n",
    "        feats.append(\"nthai\")\n",
    "    \n",
    "    if \"particles\" in feats and \"particles_SARP\" not in feats:\n",
    "        feats.append(\"particles_notSARP\")\n",
    "    return feats\n",
    "\n",
    "df = get_task1_conver(\"../Task1/annotated_conersations.jsonl\", \"closeness\", skips = [\"4. Don't like each other\"], only_user=True)\n",
    "df = run_preprocess(*df)\n",
    "shap_feats1 = run_lexicons(df, f\"./ShapleyValues/task1_clse_regressor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53bdfd3a-ef93-4617-9adf-4e3ed2abc961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1234 records from ../Task1/annotated_conersations.jsonl\n",
      "N 1098 61 61\n"
     ]
    }
   ],
   "source": [
    "df = get_task1_conver(\"../Task1/annotated_conersations.jsonl\", \"authority\", skips = [\"3. Not respect\"], only_user=True)\n",
    "df = run_preprocess(*df)\n",
    "shap_feats2 = run_lexicons(df, f\"./ShapleyValues/task1_auth_regressor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23316172-1250-4382-bc8f-536304b03837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55770a4f-723b-4d05-8a75-6a25c2cf0586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f57ea61c-16e1-44ee-b03e-91799e04d4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2486 records from ../Task2/annotated/annotated.jsonl\n",
      "N 1495 186 186\n"
     ]
    }
   ],
   "source": [
    "df = df = get_task2_conver(\"../Task2/annotated/annotated.jsonl\", \"closeness\", skips = [\"4. Don't like each other\"], only_user=True)\n",
    "df = run_preprocess(*df)\n",
    "shap_feats3 = run_lexicons(df, f\"./ShapleyValues/task2_clse_regressor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a934c67-2576-4279-afb7-94922d146e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2486 records from ../Task2/annotated/annotated.jsonl\n",
      "N 1876 234 234\n"
     ]
    }
   ],
   "source": [
    "df = get_task2_conver(\"../Task2/annotated/annotated.jsonl\", \"authority\", skips = [], only_user=True)\n",
    "df = run_preprocess(*df)\n",
    "shap_feats4 = run_lexicons(df, f\"./ShapleyValues/task2_auth_regressor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db6f715-29e6-466d-bf9e-53fea698d56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2103cd4-4000-4215-bb1c-4893aad27503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac61f618-6857-4a33-8263-33a5bb4482d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1221 records from ../Task3/annotated/annotated.jsonl\n",
      "N 1090 60 60\n"
     ]
    }
   ],
   "source": [
    "df = get_task1_conver(\"../Task3/annotated/annotated.jsonl\", \"closeness\", skips = [\"4. Don't like each other\"], only_user=True)\n",
    "df = run_preprocess(*df)\n",
    "shap_feats5 = run_lexicons(df, f\"./ShapleyValues/task3_clse_regressor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51caf043-eef6-4c61-8569-d75710699aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1221 records from ../Task3/annotated/annotated.jsonl\n",
      "N 1099 61 61\n"
     ]
    }
   ],
   "source": [
    "df = get_task1_conver(\"../Task3/annotated/annotated.jsonl\", \"authority\", skips = [], only_user=True)\n",
    "df = run_preprocess(*df)\n",
    "shap_feats6 = run_lexicons(df, f\"./ShapleyValues/task3_auth_regressor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a2b71-6e9f-429b-a573-23a68120b2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1f454-7223-4697-8333-40ea073ad662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7197af2d-bf31-412a-84db-00e7ff675496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0d775-a0f4-450f-807b-09faf6b9e9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ad025-fe9b-47e8-b42e-9b2d310643de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5bf3225b-68a6-4507-9c72-f31aa090c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shap(shap_feats, print_labels):\n",
    "    print_text = \"\"\n",
    "    for g in metric_names:\n",
    "        if g!=\"Reference\":\n",
    "            print_text += (\"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\") +\"\\n\"\n",
    "            \n",
    "        for m in metric_names[g]:\n",
    "            s = f\"{metric_names[g][m]} \"\n",
    "            for l in print_labels:\n",
    "                if l not in shap_feats:\n",
    "                    s += f\"& - \"\n",
    "                elif m not in shap_feats[l]:\n",
    "                    s += f\"& 0.00 \"\n",
    "                else:\n",
    "                    s += f\"& {shap_feats[l][m]*100:.3f} \"\n",
    "\n",
    "            s += \"\\\\\\\\\"\n",
    "            print_text += (s)+\"\\n\"\n",
    "        \n",
    "        if g!=\"Reference\":\n",
    "            print_text += (\"&  & &  & \\\\\\\\\") +\"\\n\"\n",
    "        print_text += (\"\\hline\")+\"\\n\"\n",
    "    return print_text\n",
    "\n",
    "clse_print_labels = ['1. Close', '2. Know each other', \"3. Don't know each other\", \"4. Don't like each other\"]\n",
    "auth_print_labels = ['0. Very respect', '1. Respect', '2. Normal', '3. Not respect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a19ebad8-36dd-4331-b924-18ed850562f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\n",
    "    \"Setting 1: Private Conversations with Self-Reported Labels\",\n",
    "    \"Setting 2: Public Conversations with Labels from 3rd Party \",\n",
    "    \"Setting 3: Private Conversations with Labels from 3rd Party \",\n",
    "]\n",
    "\n",
    "table_contents = [\n",
    "    (shap_feats1, shap_feats2),\n",
    "    (shap_feats3, shap_feats4),\n",
    "    (shap_feats5, shap_feats6),\n",
    "]\n",
    "\n",
    "printed_text = \"\"\n",
    "for section, (t1, t2) in zip(sections, table_contents):\n",
    "    \n",
    "    printed_text += \"\\subsection{\"+section+\"}\"\n",
    "    \n",
    "    printed_text += '''\n",
    "\\subsubsection{Closeness}\n",
    "\\\\begin{longtable}[h]{\n",
    "        p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\n",
    "        p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "        p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "        p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "        p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    }\n",
    "        \\hline\n",
    "\n",
    "        Lexical Features & Close & Know each other & Don't know each other &  Don't like each other\\\\\\\\\n",
    "        \\hline\n",
    "        \\endfirsthead\n",
    "        \n",
    "        \\endhead\n",
    "            '''\n",
    "    \n",
    "    s = print_shap(t1, clse_print_labels)\n",
    "    printed_text += \"\\n            \".join(s.split(\"\\n\"))\n",
    "    printed_text += '''\n",
    "\\end{longtable}\n",
    "\\clearpage\n",
    "\n",
    "'''\n",
    "    printed_text += '''\n",
    "\\subsubsection{Respect}\n",
    "\\\\begin{longtable}[h]{\n",
    "        p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\n",
    "        p{\\dimexpr 0.16\\linewidth-2\\\\tabcolsep}\n",
    "        p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "        p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "        p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    }\n",
    "        \\hline\n",
    "\n",
    "        Lexical Features & Very respect & Respect & Normal &  Not respect\\\\\\\\\n",
    "        \\hline\n",
    "        \\endfirsthead\n",
    "        \n",
    "        \\endhead\n",
    "            '''\n",
    "    \n",
    "    s = print_shap(t2, auth_print_labels)\n",
    "    printed_text += \"\\n            \".join(s.split(\"\\n\"))\n",
    "    printed_text += '''\n",
    "\\end{longtable}\n",
    "\\clearpage\n",
    "\n",
    "'''\n",
    "\n",
    "#     break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0788d23-625f-4e05-9f29-23c3aad4a7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\subsection{Setting 1: Private Conversations with Self-Reported Labels}\n",
      "\\subsubsection{Closeness}\n",
      "\\begin{longtable}[h]{\n",
      "        p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    }\n",
      "        \\hline\n",
      "\n",
      "        Lexical Features & Close & Know each other & Don't know each other &  Don't like each other\\\\\n",
      "        \\hline\n",
      "        \\endfirsthead\n",
      "        \n",
      "        \\endhead\n",
      "            All words & 21.619 & 29.173 & 54.089 & - \\\\\n",
      "            Average per token & 0.730 & 1.012 & 1.635 & - \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Linguistic Complexity}} \\\\\n",
      "            Code-switching & 20.744 & 19.394 & 40.397 & - \\\\\n",
      "            Long words & 5.305 & 8.495 & 8.675 & - \\\\\n",
      "            Dictionary words & 12.981 & 18.050 & 25.701 & - \\\\\n",
      "            Transliteration & 1.638 & 2.458 & 2.063 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Pronoun}} \\\\\n",
      "            All pronoun & 3.860 & 6.729 & 3.946 & - \\\\\n",
      "            >> 1st person pronoun & 3.436 & 5.483 & 3.528 & - \\\\\n",
      "            >> 2nd person pronoun & 3.477 & 5.943 & 3.555 & - \\\\\n",
      "            >> 3rd person pronoun & 2.674 & 4.533 & 2.845 & - \\\\\n",
      "            >> Pronoun in non-standard spelling & 2.803 & 4.154 & 1.744 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "            All particles & 3.719 & 7.714 & 6.732 & - \\\\\n",
      "            >> Socially-related particles & 2.736 & 8.189 & 5.943 & - \\\\\n",
      "            >> Non-socially-related particles & 3.286 & 4.362 & 3.446 & - \\\\\n",
      "            >> Particle in non-standard spelling & 2.394 & 3.552 & 2.146 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Sentiment-related}} \\\\\n",
      "            Sentiment words & 3.434 & 4.682 & 3.933 & - \\\\\n",
      "            >> Positive words & 2.856 & 4.422 & 3.663 & - \\\\\n",
      "            >> Negative words & 2.686 & 3.163 & 2.223 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Spelling variation}} \\\\\n",
      "            Spelling variation & 5.936 & 10.804 & 10.452 & - \\\\\n",
      "            >> Common misspelt words & 2.065 & 3.054 & 2.593 & - \\\\\n",
      "            >> Morphophonemic variation & 4.942 & 10.048 & 8.389 & - \\\\\n",
      "            >> Simplified variation & 3.735 & 4.704 & 5.488 & - \\\\\n",
      "            >> Repeated characters & 1.616 & 3.032 & 2.264 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Other Common Internet Lexicons}} \\\\\n",
      "            Abbreviation & 1.954 & 2.894 & 2.572 & - \\\\\n",
      "            Swear words & 3.461 & 3.751 & 3.066 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \n",
      "\\end{longtable}\n",
      "\\clearpage\n",
      "\n",
      "\n",
      "\\subsubsection{Respect}\n",
      "\\begin{longtable}[h]{\n",
      "        p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "        p{\\dimexpr 0.16\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    }\n",
      "        \\hline\n",
      "\n",
      "        Lexical Features & Very respect & Respect & Normal &  Not respect\\\\\n",
      "        \\hline\n",
      "        \\endfirsthead\n",
      "        \n",
      "        \\endhead\n",
      "            All words & 48.083 & 37.905 & 40.737 & - \\\\\n",
      "            Average per token & 1.535 & 1.074 & 1.085 & - \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Linguistic Complexity}} \\\\\n",
      "            Code-switching & 34.511 & 24.551 & 32.089 & - \\\\\n",
      "            Long words & 9.813 & 11.065 & 8.895 & - \\\\\n",
      "            Dictionary words & 24.383 & 19.129 & 23.844 & - \\\\\n",
      "            Transliteration & 2.695 & 2.428 & 2.451 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Pronoun}} \\\\\n",
      "            All pronoun & 6.132 & 6.921 & 8.282 & - \\\\\n",
      "            >> 1st person pronoun & 4.945 & 6.251 & 7.050 & - \\\\\n",
      "            >> 2nd person pronoun & 6.341 & 6.332 & 7.844 & - \\\\\n",
      "            >> 3rd person pronoun & 5.114 & 4.489 & 5.703 & - \\\\\n",
      "            >> Pronoun in non-standard spelling & 3.814 & 7.026 & 4.356 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "            All particles & 10.162 & 8.157 & 7.902 & - \\\\\n",
      "            >> Socially-related particles & 9.344 & 7.110 & 7.086 & - \\\\\n",
      "            >> Non-socially-related particles & 6.166 & 6.236 & 6.193 & - \\\\\n",
      "            >> Particle in non-standard spelling & 5.658 & 4.204 & 5.466 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Sentiment-related}} \\\\\n",
      "            Sentiment words & 4.568 & 5.014 & 5.681 & - \\\\\n",
      "            >> Positive words & 4.084 & 4.804 & 5.190 & - \\\\\n",
      "            >> Negative words & 3.413 & 3.264 & 4.222 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Spelling variation}} \\\\\n",
      "            Spelling variation & 11.436 & 11.467 & 13.496 & - \\\\\n",
      "            >> Common misspelt words & 4.156 & 3.545 & 4.121 & - \\\\\n",
      "            >> Morphophonemic variation & 10.060 & 10.722 & 12.121 & - \\\\\n",
      "            >> Simplified variation & 7.008 & 6.911 & 7.207 & - \\\\\n",
      "            >> Repeated characters & 4.286 & 4.134 & 4.088 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Other Common Internet Lexicons}} \\\\\n",
      "            Abbreviation & 5.728 & 4.642 & 5.060 & - \\\\\n",
      "            Swear words & 3.398 & 3.024 & 3.362 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \n",
      "\\end{longtable}\n",
      "\\clearpage\n",
      "\n",
      "\\subsection{Setting 2: Public Conversations with Labels from 3rd Party }\n",
      "\\subsubsection{Closeness}\n",
      "\\begin{longtable}[h]{\n",
      "        p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    }\n",
      "        \\hline\n",
      "\n",
      "        Lexical Features & Close & Know each other & Don't know each other &  Don't like each other\\\\\n",
      "        \\hline\n",
      "        \\endfirsthead\n",
      "        \n",
      "        \\endhead\n",
      "            All words & 58.069 & 27.968 & 9.821 & - \\\\\n",
      "            Average per token & 5.761 & 2.606 & 1.012 & - \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Linguistic Complexity}} \\\\\n",
      "            Code-switching & 61.465 & 27.174 & 10.129 & - \\\\\n",
      "            Long words & 12.522 & 7.481 & 5.319 & - \\\\\n",
      "            Dictionary words & 40.351 & 20.309 & 8.225 & - \\\\\n",
      "            Transliteration & 6.110 & 5.812 & 3.508 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Pronoun}} \\\\\n",
      "            All pronoun & 20.108 & 5.321 & 3.298 & - \\\\\n",
      "            >> 1st person pronoun & 16.569 & 4.707 & 3.108 & - \\\\\n",
      "            >> 2nd person pronoun & 20.697 & 4.674 & 3.004 & - \\\\\n",
      "            >> 3rd person pronoun & 4.468 & 4.316 & 2.520 & - \\\\\n",
      "            >> Pronoun in non-standard spelling & 19.610 & 3.767 & 2.308 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "            All particles & 8.952 & 5.728 & 2.857 & - \\\\\n",
      "            >> Socially-related particles & 8.567 & 6.263 & 2.768 & - \\\\\n",
      "            >> Non-socially-related particles & 8.307 & 3.415 & 2.490 & - \\\\\n",
      "            >> Particle in non-standard spelling & 3.688 & 7.535 & 2.870 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Sentiment-related}} \\\\\n",
      "            Sentiment words & 9.495 & 5.483 & 3.472 & - \\\\\n",
      "            >> Positive words & 5.282 & 3.868 & 2.731 & - \\\\\n",
      "            >> Negative words & 10.593 & 5.193 & 3.214 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Spelling variation}} \\\\\n",
      "            Spelling variation & 19.679 & 9.658 & 4.864 & - \\\\\n",
      "            >> Common misspelt words & 12.901 & 1.406 & 2.206 & - \\\\\n",
      "            >> Morphophonemic variation & 17.239 & 7.640 & 4.251 & - \\\\\n",
      "            >> Simplified variation & 12.297 & 6.872 & 3.582 & - \\\\\n",
      "            >> Repeated characters & 4.619 & 4.223 & 2.709 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Other Common Internet Lexicons}} \\\\\n",
      "            Abbreviation & 2.212 & 1.992 & 2.298 & - \\\\\n",
      "            Swear words & 13.869 & 0.000 & 3.854 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \n",
      "\\end{longtable}\n",
      "\\clearpage\n",
      "\n",
      "\n",
      "\\subsubsection{Respect}\n",
      "\\begin{longtable}[h]{\n",
      "        p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "        p{\\dimexpr 0.16\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    }\n",
      "        \\hline\n",
      "\n",
      "        Lexical Features & Very respect & Respect & Normal &  Not respect\\\\\n",
      "        \\hline\n",
      "        \\endfirsthead\n",
      "        \n",
      "        \\endhead\n",
      "            All words & - & 33.525 & 8.328 & 28.413 \\\\\n",
      "            Average per token & - & 3.118 & 0.975 & 2.148 \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Linguistic Complexity}} \\\\\n",
      "            Code-switching & - & 32.519 & 8.752 & 30.223 \\\\\n",
      "            Long words & - & 12.015 & 4.523 & 7.780 \\\\\n",
      "            Dictionary words & - & 16.128 & 6.631 & 19.468 \\\\\n",
      "            Transliteration & - & 2.108 & 2.569 & 1.413 \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Pronoun}} \\\\\n",
      "            All pronoun & - & 3.126 & 2.783 & 6.719 \\\\\n",
      "            >> 1st person pronoun & - & 2.551 & 2.532 & 3.935 \\\\\n",
      "            >> 2nd person pronoun & - & 3.002 & 2.598 & 6.877 \\\\\n",
      "            >> 3rd person pronoun & - & 3.303 & 2.486 & 3.901 \\\\\n",
      "            >> Pronoun in non-standard spelling & - & 3.417 & 2.488 & 4.624 \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "            All particles & - & 4.060 & 2.642 & 3.036 \\\\\n",
      "            >> Socially-related particles & - & 4.077 & 2.856 & 2.523 \\\\\n",
      "            >> Non-socially-related particles & - & 2.709 & 1.953 & 2.780 \\\\\n",
      "            >> Particle in non-standard spelling & - & 1.000 & 2.016 & 3.256 \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Sentiment-related}} \\\\\n",
      "            Sentiment words & - & 7.290 & 3.782 & 5.531 \\\\\n",
      "            >> Positive words & - & 7.069 & 3.363 & 2.934 \\\\\n",
      "            >> Negative words & - & 3.643 & 3.192 & 5.462 \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Spelling variation}} \\\\\n",
      "            Spelling variation & - & 8.505 & 3.949 & 6.473 \\\\\n",
      "            >> Common misspelt words & - & 3.692 & 2.297 & 4.319 \\\\\n",
      "            >> Morphophonemic variation & - & 7.571 & 3.307 & 4.922 \\\\\n",
      "            >> Simplified variation & - & 4.627 & 2.894 & 4.622 \\\\\n",
      "            >> Repeated characters & - & 2.537 & 1.707 & 2.045 \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Other Common Internet Lexicons}} \\\\\n",
      "            Abbreviation & - & 2.650 & 3.331 & 1.174 \\\\\n",
      "            Swear words & - & 4.205 & 4.567 & 8.326 \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \n",
      "\\end{longtable}\n",
      "\\clearpage\n",
      "\n",
      "\\subsection{Setting 3: Private Conversations with Labels from 3rd Party }\n",
      "\\subsubsection{Closeness}\n",
      "\\begin{longtable}[h]{\n",
      "        p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    }\n",
      "        \\hline\n",
      "\n",
      "        Lexical Features & Close & Know each other & Don't know each other &  Don't like each other\\\\\n",
      "        \\hline\n",
      "        \\endfirsthead\n",
      "        \n",
      "        \\endhead\n",
      "            All words & 23.068 & 32.947 & 32.213 & - \\\\\n",
      "            Average per token & 0.942 & 1.207 & 2.398 & - \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Linguistic Complexity}} \\\\\n",
      "            Code-switching & 18.341 & 31.257 & 28.519 & - \\\\\n",
      "            Long words & 6.902 & 10.355 & 13.890 & - \\\\\n",
      "            Dictionary words & 13.650 & 19.927 & 20.051 & - \\\\\n",
      "            Transliteration & 2.094 & 3.152 & 3.441 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Pronoun}} \\\\\n",
      "            All pronoun & 6.862 & 5.145 & 3.940 & - \\\\\n",
      "            >> 1st person pronoun & 5.381 & 4.086 & 2.330 & - \\\\\n",
      "            >> 2nd person pronoun & 5.402 & 4.482 & 4.098 & - \\\\\n",
      "            >> 3rd person pronoun & 3.879 & 3.686 & 4.269 & - \\\\\n",
      "            >> Pronoun in non-standard spelling & 4.032 & 3.668 & 1.143 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "            All particles & 4.861 & 7.755 & 9.359 & - \\\\\n",
      "            >> Socially-related particles & 5.842 & 7.538 & 9.038 & - \\\\\n",
      "            >> Non-socially-related particles & 3.876 & 5.037 & 3.585 & - \\\\\n",
      "            >> Particle in non-standard spelling & 2.788 & 3.267 & 3.004 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Sentiment-related}} \\\\\n",
      "            Sentiment words & 4.204 & 5.715 & 3.781 & - \\\\\n",
      "            >> Positive words & 3.339 & 4.874 & 3.168 & - \\\\\n",
      "            >> Negative words & 3.499 & 4.420 & 3.491 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Spelling variation}} \\\\\n",
      "            Spelling variation & 7.993 & 9.377 & 5.573 & - \\\\\n",
      "            >> Common misspelt words & 4.013 & 4.056 & 0.923 & - \\\\\n",
      "            >> Morphophonemic variation & 6.990 & 7.591 & 3.986 & - \\\\\n",
      "            >> Simplified variation & 4.712 & 6.480 & 6.019 & - \\\\\n",
      "            >> Repeated characters & 3.445 & 3.625 & 4.988 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Other Common Internet Lexicons}} \\\\\n",
      "            Abbreviation & 2.513 & 4.559 & 2.605 & - \\\\\n",
      "            Swear words & 2.562 & 7.043 & 0.000 & - \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \n",
      "\\end{longtable}\n",
      "\\clearpage\n",
      "\n",
      "\n",
      "\\subsubsection{Respect}\n",
      "\\begin{longtable}[h]{\n",
      "        p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "        p{\\dimexpr 0.16\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "        p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    }\n",
      "        \\hline\n",
      "\n",
      "        Lexical Features & Very respect & Respect & Normal &  Not respect\\\\\n",
      "        \\hline\n",
      "        \\endfirsthead\n",
      "        \n",
      "        \\endhead\n",
      "            All words & - & 16.482 & 6.764 & 22.434 \\\\\n",
      "            Average per token & - & 2.216 & 0.416 & 0.595 \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Linguistic Complexity}} \\\\\n",
      "            Code-switching & - & 16.486 & 5.915 & 20.997 \\\\\n",
      "            Long words & - & 7.598 & 2.638 & 2.249 \\\\\n",
      "            Dictionary words & - & 11.302 & 4.798 & 17.183 \\\\\n",
      "            Transliteration & - & 1.299 & 0.548 & 0.811 \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Pronoun}} \\\\\n",
      "            All pronoun & - & 1.856 & 2.975 & 11.791 \\\\\n",
      "            >> 1st person pronoun & - & 1.029 & 1.917 & 5.519 \\\\\n",
      "            >> 2nd person pronoun & - & 1.916 & 2.473 & 9.151 \\\\\n",
      "            >> 3rd person pronoun & - & 1.884 & 1.033 & 0.988 \\\\\n",
      "            >> Pronoun in non-standard spelling & - & 0.355 & 1.698 & 3.565 \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "            All particles & - & 3.764 & 1.774 & 2.084 \\\\\n",
      "            >> Socially-related particles & - & 3.988 & 1.777 & 1.737 \\\\\n",
      "            >> Non-socially-related particles & - & 1.153 & 1.176 & 1.907 \\\\\n",
      "            >> Particle in non-standard spelling & - & 0.909 & 0.930 & 1.240 \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Sentiment-related}} \\\\\n",
      "            Sentiment words & - & 2.204 & 1.259 & 1.989 \\\\\n",
      "            >> Positive words & - & 2.042 & 1.105 & 1.117 \\\\\n",
      "            >> Negative words & - & 1.122 & 0.940 & 2.194 \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Spelling variation}} \\\\\n",
      "            Spelling variation & - & 5.576 & 2.441 & 6.341 \\\\\n",
      "            >> Common misspelt words & - & 0.489 & 0.881 & 1.758 \\\\\n",
      "            >> Morphophonemic variation & - & 5.530 & 2.191 & 5.460 \\\\\n",
      "            >> Simplified variation & - & 1.396 & 1.263 & 2.545 \\\\\n",
      "            >> Repeated characters & - & 0.910 & 0.723 & 0.972 \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \\multicolumn{5}{l}{\\textit{Other Common Internet Lexicons}} \\\\\n",
      "            Abbreviation & - & 1.742 & 1.055 & 0.537 \\\\\n",
      "            Swear words & - & 0.099 & 0.922 & 2.651 \\\\\n",
      "            &  & &  & \\\\\n",
      "            \\hline\n",
      "            \n",
      "\\end{longtable}\n",
      "\\clearpage\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f8f48647-ce76-4955-9dc0-6c376dac2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"particles\": \"All particles\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53fcfb6-0782-4111-9441-b7af0893c875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff3d2a-777c-493f-a16d-e80547f6a974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
