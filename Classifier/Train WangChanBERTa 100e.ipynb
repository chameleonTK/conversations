{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee748ab1-ddbf-45ee-ad21-9011cdffb4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import get_task1_conver, get_task2_conver, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc7808dd-31f7-422c-9626-47a3d2647577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7d2ed16-a74e-403f-b754-c6bc208b65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_task1_conver(\"../Task1//annotated_conersations.jsonl\", \"closeness\", skips = [\"4. Don't like each other\"], only_user=False)\n",
    "# # print(df[0][\"text\"][0])\n",
    "# pd.concat(df).groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e0fdc65-bee0-48df-9ce1-38db99cb8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_task2_conver(\"../Task2/annotated/annotated.jsonl\", \"closeness\", skips = [], only_user=False)\n",
    "# # print(df[0][\"text\"][0])\n",
    "# pd.concat(df).groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "045bb11d-dcae-4ac1-ad23-7458fcfe2885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_task1_conver(\"../Task3/annotated/annotated.jsonl\", \"closeness\", skips = [], only_user=False)\n",
    "# # print(df[0][\"text\"][0])\n",
    "# pd.concat(df).groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0003391-29d3-4de6-a36e-4a3846047fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils import load_jsonl, dump_jsonl, set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a16a7f-c577-4736-b400-73983925692c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb03998c-5faa-42e0-96b5-2d609f1f5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import wandb\n",
    "# from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "# from pythainlp.tokenize import word_tokenize\n",
    "import torch\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import DataCollatorWithPadding\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad407677-6b14-4fc3-86a6-4a5c7da4c90d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f343df2c-a90d-405b-ae84-207c74e0a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "import torch.nn as nn\n",
    "import os, shutil\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def run_exp(out_dir, df, report=\"none\", regressor_configs=None):\n",
    "\n",
    "    set_random_seed()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # device = torch.device(\"cpu\")\n",
    "    print(\"START\")\n",
    "    print(\"step 1: load data\")\n",
    "    train, val, test = df\n",
    "    \n",
    "#     train = train.head(100)\n",
    "#     val = val.head(100)\n",
    "#     test = test.head(100)\n",
    "\n",
    "    print(\"step 2: load tokenizer\")\n",
    "    model_name = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    num_added_toks = tokenizer.add_special_tokens({\"additional_special_tokens\": [\"usr\", \"sys\", \"rep\"]})\n",
    "\n",
    "    print(\"step 3: init data\")\n",
    "    ds = DatasetDict()\n",
    "    ds['train'] = Dataset.from_pandas(train)\n",
    "    ds['val'] = Dataset.from_pandas(val)\n",
    "    ds['test'] = Dataset.from_pandas(test)\n",
    "\n",
    "    if regressor_configs is None:\n",
    "        labels = train[\"label\"].unique()\n",
    "        num_labels = len(labels)\n",
    "        print(labels)\n",
    "    \n",
    "        class_weights = compute_class_weight(\"balanced\", classes=labels, y=train[\"label\"].values)\n",
    "        class_weights = torch.tensor(class_weights).float().to(device)\n",
    "\n",
    "        id2label = {i:l for i, l in enumerate(labels)}\n",
    "        label2id = {l:i for i, l in enumerate(labels)}\n",
    "\n",
    "        def word_tokenize(d, tokenizer=None, label2id=None, max_length=256):\n",
    "            texts = [preprocess(t) for t in d[\"text\"]]\n",
    "    #         print(texts)\n",
    "            tokens = tokenizer(texts, truncation=True, max_length=max_length)\n",
    "            num = [len(t) for t in tokens[\"input_ids\"]]\n",
    "    #         print(num)\n",
    "    #         print(\"AVG\", len(num), sum(num)/len(num))\n",
    "            tokens[\"label\"] = [label2id[label] for label in d[\"label\"]]\n",
    "            return tokens\n",
    "    else:\n",
    "#         labels = train[\"label\"].unique()\n",
    "        num_labels = 1\n",
    "\n",
    "        id2label = {1: regressor_configs[\"label\"]}\n",
    "        label2id = [regressor_configs[\"not_label\"], regressor_configs[\"label\"]]\n",
    "\n",
    "        def word_tokenize(d, tokenizer=None, label2id=None, max_length=256):\n",
    "            texts = [preprocess(t) for t in d[\"text\"]]\n",
    "    #         print(texts)\n",
    "            tokens = tokenizer(texts, truncation=True, max_length=max_length)\n",
    "            num = [len(t) for t in tokens[\"input_ids\"]]\n",
    "    #         print(num)\n",
    "    #         print(\"AVG\", len(num), sum(num)/len(num))\n",
    "            tokens[\"label\"] = [regressor_configs[\"label_fn\"](label) for label in d[\"label\"]]\n",
    "            return tokens\n",
    "        \n",
    "        \n",
    "        \n",
    "    tokenized_ds = ds.map(word_tokenize, batched=True, fn_kwargs={\"tokenizer\":tokenizer, \"label2id\": label2id, \"max_length\":max_length})\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    print(\"step 4: load model\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, id2label=id2label, label2id=label2id);\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model = model.to(device)\n",
    "\n",
    "    if regressor_configs is None:\n",
    "        metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "        def compute_metrics(eval_pred):\n",
    "            predictions, labels = eval_pred\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "            return metrics.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    else:\n",
    "        label_fn = regressor_configs[\"label_fn\"]\n",
    "        def compute_metrics(eval_pred):           \n",
    "            predictions, actual = eval_pred\n",
    "            predictions = predictions.reshape(-1)\n",
    "            \n",
    "            predicted_labels = [label_fn(p) for p in predictions]\n",
    "            actual_labels = [label_fn(p) for p in actual]\n",
    "            p, r, f1, _ = precision_recall_fscore_support(actual_labels, predicted_labels, average='macro')\n",
    "            \n",
    "            return {\n",
    "                \"r2_score\": r2_score(actual, predictions),\n",
    "                \"mean_squared_error\": np.sqrt(mean_squared_error(actual, predictions)),\n",
    "                \"accuracy\": accuracy_score(actual_labels, predicted_labels),\n",
    "                \"f1\": f1,\n",
    "                \"precision\": p,\n",
    "                \"recall\": r,\n",
    "            }\n",
    "\n",
    "\n",
    "    print(\"step 5: fine-tune\")\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=out_dir,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        report_to=report,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        push_to_hub=False,\n",
    "        run_name=out_dir,\n",
    "    )\n",
    "    \n",
    "    if regressor_configs is None:\n",
    "        class CustomTrainer(Trainer):\n",
    "            def compute_loss(self, model, inputs, return_outputs=False):\n",
    "                labels = inputs.get(\"labels\")\n",
    "                # forward pass\n",
    "                outputs = model(**inputs)\n",
    "\n",
    "                logits = outputs.get(\"logits\")\n",
    "\n",
    "                loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "                loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "                return (loss, outputs) if return_outputs else loss\n",
    "    else:\n",
    "        CustomTrainer = Trainer\n",
    "        \n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_ds[\"train\"],\n",
    "        eval_dataset=tokenized_ds[\"val\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,   \n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    best_ckpt_path = trainer.state.best_model_checkpoint\n",
    "    print(best_ckpt_path)\n",
    "\n",
    "    modle_out_path = out_dir+\"/best_model\"\n",
    "    if os.path.exists(modle_out_path):\n",
    "        shutil.rmtree(modle_out_path)\n",
    "        \n",
    "    os.rename(best_ckpt_path, modle_out_path)\n",
    "    best_ckpt_path = modle_out_path\n",
    "    \n",
    "    print(\"step 6: evaluate\")\n",
    "    e = trainer.evaluate(tokenized_ds[\"test\"])\n",
    "    print(e)\n",
    "\n",
    "    print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e6d6ae-c79f-4ec2-b912-8440b1a5ec65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1c3b6-9d95-4a3c-9a77-b35b7d268b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6de0fefe-0d41-4e0e-94e8-d23cb2591f71",
   "metadata": {},
   "source": [
    "## Task1: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c7fb066-1968-43e1-8f28-e5d8f592e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = \"none\"\n",
    "batch_size = 16\n",
    "max_length = 128\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2724398-dbfb-4630-a9cd-84ec8fabc07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# stream = os.popen('nohup python3 run_train_task_classifier.py > train2.out &')\n",
    "# output = stream.read()\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc5524-69ab-4661-9dd8-2ceda81651bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59404733-41e6-4b1d-a275-8622006a5e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1234 records from ../Task1/annotated_conersations.jsonl\n",
      "N 1096 60 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Close</th>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Know each other</th>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Don't know each other</th>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text\n",
       "label                         \n",
       "1. Close                   551\n",
       "2. Know each other         230\n",
       "3. Don't know each other   435"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task1_conver(\"../Task1/annotated_conersations.jsonl\", \"closeness\", skips = [\"4. Don't like each other\"], only_user=True)\n",
    "# df = (df[0].head(), df[1].head(), df[2].head())\n",
    "# print(df[0][\"text\"][0])\n",
    "pd.concat(df).groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d129a6c4-925e-4ecb-ba32-69a97d06fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[0][\"label\"].value_counts().loc[['1. Close', '2. Know each other', \"3. Don't know each other\"]].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbebd375-7ed0-4ef9-b2c2-0f736a9f3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[1][\"label\"].value_counts().loc[['1. Close', '2. Know each other', \"3. Don't know each other\"]].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10942d27-e92a-4d8d-8f60-1dd9e2c942d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[2][\"label\"].value_counts().loc[['1. Close', '2. Know each other', \"3. Don't know each other\"]].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefac027-73fc-4994-8ec5-5e39566ca94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c6094e0-3054-4f53-9135-01f0359861a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def closeness_label_fn(label):\n",
    "#     if label == '1. Close':\n",
    "#         return 1\n",
    "#     elif label =='2. Know each other':\n",
    "#         return 0.5\n",
    "#     elif label == \"3. Don't know each other\":\n",
    "#         return 0\n",
    "#     elif type(label)==str:\n",
    "#         assert(False)\n",
    "    \n",
    "#     # [0, 0.33) =>\n",
    "#     # [0.33, 0.66) =>\n",
    "#     # [0.66, 1] =>\n",
    "    \n",
    "#     if label > 0.66:\n",
    "#         return '1. Close'\n",
    "#     elif label > 0.33:\n",
    "#         return '2. Know each other'\n",
    "#     else:\n",
    "#         return \"3. Don't know each other\"\n",
    "    \n",
    "# run_exp(\"./Regressors/task1_clse_usr100e\", df, report=report, regressor_configs={\n",
    "#     \"label\": \"close\",\n",
    "#     \"not_label\": \"not_close\",\n",
    "#     \"label_fn\": closeness_label_fn,\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2522b5e-0d0a-4515-a821-3dbb003248c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_exp(\"./Models/task1_clse_usr100e\", df, report=report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cd88ae-64b2-4aff-a3b9-ce0ec483f346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf6a91-aca3-4e82-b7b4-85093fc3af53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e987fb4-dddc-4f9c-8dc5-5745d7c8fb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d026221-27c1-48f4-b01e-a9c59ef53ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1234 records from ../Task1/annotated_conersations.jsonl\n",
      "N 1098 61 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0. Very respect</th>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1. Respect</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Normal</th>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text\n",
       "label                \n",
       "0. Very respect   248\n",
       "1. Respect        289\n",
       "2. Normal         683"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task1_conver(\"../Task1/annotated_conersations.jsonl\", \"authority\", skips = [\"3. Not respect\"], only_user=True)\n",
    "# print(df[0][\"text\"][0])\n",
    "pd.concat(df).groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36e197ad-c191-4d84-af20-c227dbebc211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1. Respect', '2. Normal', '0. Very respect'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0][\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a7682dd-2bd9-46d6-a430-9a97b7ef0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[0][\"label\"].value_counts().loc[[\"0. Very respect\", \"1. Respect\", \"2. Normal\"]].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "761434c4-a8bc-4c3f-8d1c-d07f7d55debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[1][\"label\"].value_counts().loc[[\"0. Very respect\", \"1. Respect\", \"2. Normal\"]].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3dad68c6-253e-4183-95d3-a59945938689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[2][\"label\"].value_counts().loc[[\"0. Very respect\", \"1. Respect\", \"2. Normal\"]].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b76142-2f18-4a53-905e-b6f2bdf1e5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6aa0dd0a-99a3-481e-8ea4-4ced21a3d033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "step 1: load data\n",
      "step 2: load tokenizer\n",
      "step 3: init data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23ad0ea2b3f486e9ce18cde2e010165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce897908bc9f4bc6b388285621c09662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6872ef0889a43259adfc2bf82341394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4: load model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/imtk/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1098\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6900\n",
      "  Number of trainable parameters = 105247489\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5: fine-tune\n",
      "['labels']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6900' max='6900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6900/6900 56:39, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.174809</td>\n",
       "      <td>-0.120523</td>\n",
       "      <td>0.418101</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.224638</td>\n",
       "      <td>0.178161</td>\n",
       "      <td>0.303922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.172884</td>\n",
       "      <td>-0.108184</td>\n",
       "      <td>0.415793</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.227106</td>\n",
       "      <td>0.181287</td>\n",
       "      <td>0.303922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.153108</td>\n",
       "      <td>0.018577</td>\n",
       "      <td>0.391291</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.355571</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.403268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.150741</td>\n",
       "      <td>0.033749</td>\n",
       "      <td>0.388254</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.369243</td>\n",
       "      <td>0.455922</td>\n",
       "      <td>0.417647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.136468</td>\n",
       "      <td>0.125240</td>\n",
       "      <td>0.369416</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.390296</td>\n",
       "      <td>0.488733</td>\n",
       "      <td>0.408824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.135456</td>\n",
       "      <td>0.131728</td>\n",
       "      <td>0.368043</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.319048</td>\n",
       "      <td>0.292963</td>\n",
       "      <td>0.358824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.142805</td>\n",
       "      <td>0.084620</td>\n",
       "      <td>0.377896</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.409457</td>\n",
       "      <td>0.533251</td>\n",
       "      <td>0.393137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.148909</td>\n",
       "      <td>0.045498</td>\n",
       "      <td>0.385887</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.399441</td>\n",
       "      <td>0.650999</td>\n",
       "      <td>0.418627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.139410</td>\n",
       "      <td>0.106385</td>\n",
       "      <td>0.373376</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.478658</td>\n",
       "      <td>0.575054</td>\n",
       "      <td>0.462745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.169991</td>\n",
       "      <td>-0.089638</td>\n",
       "      <td>0.412299</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.394053</td>\n",
       "      <td>0.669872</td>\n",
       "      <td>0.417974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.156001</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.394970</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.454823</td>\n",
       "      <td>0.459477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.165966</td>\n",
       "      <td>-0.063840</td>\n",
       "      <td>0.407389</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.410874</td>\n",
       "      <td>0.672233</td>\n",
       "      <td>0.430392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.128932</td>\n",
       "      <td>0.173546</td>\n",
       "      <td>0.359071</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.484283</td>\n",
       "      <td>0.541423</td>\n",
       "      <td>0.467320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.172159</td>\n",
       "      <td>-0.103539</td>\n",
       "      <td>0.414921</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.377201</td>\n",
       "      <td>0.635127</td>\n",
       "      <td>0.398366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.149609</td>\n",
       "      <td>0.041010</td>\n",
       "      <td>0.386793</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.538366</td>\n",
       "      <td>0.592240</td>\n",
       "      <td>0.536601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.154554</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.393133</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.412654</td>\n",
       "      <td>0.472934</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.162455</td>\n",
       "      <td>-0.041338</td>\n",
       "      <td>0.403058</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.487592</td>\n",
       "      <td>0.664502</td>\n",
       "      <td>0.468954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.151562</td>\n",
       "      <td>0.028490</td>\n",
       "      <td>0.389310</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.433987</td>\n",
       "      <td>0.439760</td>\n",
       "      <td>0.433660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.140622</td>\n",
       "      <td>0.098614</td>\n",
       "      <td>0.374996</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.553563</td>\n",
       "      <td>0.639526</td>\n",
       "      <td>0.546405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.160142</td>\n",
       "      <td>-0.026507</td>\n",
       "      <td>0.400177</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.429865</td>\n",
       "      <td>0.474811</td>\n",
       "      <td>0.437582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.153355</td>\n",
       "      <td>0.016996</td>\n",
       "      <td>0.391606</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.517991</td>\n",
       "      <td>0.687963</td>\n",
       "      <td>0.503595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.155041</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.393753</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.524427</td>\n",
       "      <td>0.623476</td>\n",
       "      <td>0.513399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.155130</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.393865</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.505068</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.493791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.156673</td>\n",
       "      <td>-0.004270</td>\n",
       "      <td>0.395819</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.437254</td>\n",
       "      <td>0.486772</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.145483</td>\n",
       "      <td>0.067453</td>\n",
       "      <td>0.381423</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.420107</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>0.410131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.150422</td>\n",
       "      <td>0.035797</td>\n",
       "      <td>0.387843</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.545660</td>\n",
       "      <td>0.649225</td>\n",
       "      <td>0.533007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.177508</td>\n",
       "      <td>-0.137824</td>\n",
       "      <td>0.421317</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.433175</td>\n",
       "      <td>0.667484</td>\n",
       "      <td>0.435948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.144712</td>\n",
       "      <td>0.072399</td>\n",
       "      <td>0.380410</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.545503</td>\n",
       "      <td>0.711404</td>\n",
       "      <td>0.538235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.141084</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.375612</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.399148</td>\n",
       "      <td>0.450486</td>\n",
       "      <td>0.393137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.154974</td>\n",
       "      <td>0.006618</td>\n",
       "      <td>0.393667</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.481962</td>\n",
       "      <td>0.588114</td>\n",
       "      <td>0.483007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.150769</td>\n",
       "      <td>0.033571</td>\n",
       "      <td>0.388290</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.526455</td>\n",
       "      <td>0.694737</td>\n",
       "      <td>0.516013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.150632</td>\n",
       "      <td>0.034452</td>\n",
       "      <td>0.388113</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.447477</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.437908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.145714</td>\n",
       "      <td>0.065976</td>\n",
       "      <td>0.381725</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.400851</td>\n",
       "      <td>0.447464</td>\n",
       "      <td>0.390523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.146829</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.383183</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.435186</td>\n",
       "      <td>0.459148</td>\n",
       "      <td>0.429739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.153251</td>\n",
       "      <td>0.017663</td>\n",
       "      <td>0.391473</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.499973</td>\n",
       "      <td>0.671296</td>\n",
       "      <td>0.483987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.147212</td>\n",
       "      <td>0.056370</td>\n",
       "      <td>0.383683</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.548629</td>\n",
       "      <td>0.721447</td>\n",
       "      <td>0.533007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.145438</td>\n",
       "      <td>0.067744</td>\n",
       "      <td>0.381363</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.410952</td>\n",
       "      <td>0.457880</td>\n",
       "      <td>0.400327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.144191</td>\n",
       "      <td>0.075739</td>\n",
       "      <td>0.379724</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.438125</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.432353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.155212</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.393970</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.537179</td>\n",
       "      <td>0.656456</td>\n",
       "      <td>0.520588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.147566</td>\n",
       "      <td>0.054103</td>\n",
       "      <td>0.384143</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.519872</td>\n",
       "      <td>0.633399</td>\n",
       "      <td>0.508170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.144356</td>\n",
       "      <td>0.074678</td>\n",
       "      <td>0.379942</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.401709</td>\n",
       "      <td>0.451165</td>\n",
       "      <td>0.390523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.146754</td>\n",
       "      <td>0.059307</td>\n",
       "      <td>0.383085</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.472719</td>\n",
       "      <td>0.575798</td>\n",
       "      <td>0.475817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.154017</td>\n",
       "      <td>0.012753</td>\n",
       "      <td>0.392450</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.530752</td>\n",
       "      <td>0.601515</td>\n",
       "      <td>0.520588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.153812</td>\n",
       "      <td>0.014065</td>\n",
       "      <td>0.392189</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.460642</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.451961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.149051</td>\n",
       "      <td>0.044582</td>\n",
       "      <td>0.386072</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.482790</td>\n",
       "      <td>0.432353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.151595</td>\n",
       "      <td>0.028277</td>\n",
       "      <td>0.389352</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.725968</td>\n",
       "      <td>0.545425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.148773</td>\n",
       "      <td>0.046364</td>\n",
       "      <td>0.385711</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.473304</td>\n",
       "      <td>0.580362</td>\n",
       "      <td>0.473203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.136355</td>\n",
       "      <td>0.125966</td>\n",
       "      <td>0.369263</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.489076</td>\n",
       "      <td>0.548148</td>\n",
       "      <td>0.483987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.136621</td>\n",
       "      <td>0.124262</td>\n",
       "      <td>0.369622</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.512719</td>\n",
       "      <td>0.613492</td>\n",
       "      <td>0.500980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.144866</td>\n",
       "      <td>0.071407</td>\n",
       "      <td>0.380613</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.561626</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.540196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.145951</td>\n",
       "      <td>0.064457</td>\n",
       "      <td>0.382035</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.468758</td>\n",
       "      <td>0.530623</td>\n",
       "      <td>0.459150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.143412</td>\n",
       "      <td>0.080731</td>\n",
       "      <td>0.378698</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.479600</td>\n",
       "      <td>0.539181</td>\n",
       "      <td>0.471569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.139565</td>\n",
       "      <td>0.105389</td>\n",
       "      <td>0.373584</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.534942</td>\n",
       "      <td>0.635714</td>\n",
       "      <td>0.523203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.139918</td>\n",
       "      <td>0.103128</td>\n",
       "      <td>0.374056</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.524427</td>\n",
       "      <td>0.623476</td>\n",
       "      <td>0.513399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.144182</td>\n",
       "      <td>0.075795</td>\n",
       "      <td>0.379713</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.508758</td>\n",
       "      <td>0.569106</td>\n",
       "      <td>0.500980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.145871</td>\n",
       "      <td>0.064967</td>\n",
       "      <td>0.381931</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.541535</td>\n",
       "      <td>0.618855</td>\n",
       "      <td>0.530392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.145081</td>\n",
       "      <td>0.070034</td>\n",
       "      <td>0.380895</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.559762</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.545425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.146397</td>\n",
       "      <td>0.061594</td>\n",
       "      <td>0.382619</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.459257</td>\n",
       "      <td>0.520261</td>\n",
       "      <td>0.449346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.153602</td>\n",
       "      <td>0.015415</td>\n",
       "      <td>0.391920</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.565060</td>\n",
       "      <td>0.780045</td>\n",
       "      <td>0.540196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.138807</td>\n",
       "      <td>0.110246</td>\n",
       "      <td>0.372569</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.479600</td>\n",
       "      <td>0.539181</td>\n",
       "      <td>0.471569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.145190</td>\n",
       "      <td>0.069331</td>\n",
       "      <td>0.381039</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.499869</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.491176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.144006</td>\n",
       "      <td>0.076921</td>\n",
       "      <td>0.379482</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.493736</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.483987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.149668</td>\n",
       "      <td>0.040626</td>\n",
       "      <td>0.386870</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.565060</td>\n",
       "      <td>0.780045</td>\n",
       "      <td>0.540196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.144844</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>0.380583</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.493736</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.483987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.135326</td>\n",
       "      <td>0.132560</td>\n",
       "      <td>0.367867</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.502996</td>\n",
       "      <td>0.600877</td>\n",
       "      <td>0.493791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.142171</td>\n",
       "      <td>0.088688</td>\n",
       "      <td>0.377055</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.524427</td>\n",
       "      <td>0.623476</td>\n",
       "      <td>0.513399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.148396</td>\n",
       "      <td>0.048781</td>\n",
       "      <td>0.385222</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.545513</td>\n",
       "      <td>0.663702</td>\n",
       "      <td>0.530392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.140906</td>\n",
       "      <td>0.096795</td>\n",
       "      <td>0.375374</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.489923</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.481373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.138728</td>\n",
       "      <td>0.110753</td>\n",
       "      <td>0.372462</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.509964</td>\n",
       "      <td>0.573016</td>\n",
       "      <td>0.500980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.144072</td>\n",
       "      <td>0.076503</td>\n",
       "      <td>0.379568</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.499869</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.491176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.104622</td>\n",
       "      <td>0.373744</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.524267</td>\n",
       "      <td>0.631119</td>\n",
       "      <td>0.510784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.138671</td>\n",
       "      <td>0.111118</td>\n",
       "      <td>0.372386</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.502921</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>0.491176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.142706</td>\n",
       "      <td>0.085255</td>\n",
       "      <td>0.377765</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.474314</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.466340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.144007</td>\n",
       "      <td>0.076919</td>\n",
       "      <td>0.379482</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.513477</td>\n",
       "      <td>0.636525</td>\n",
       "      <td>0.498366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.145033</td>\n",
       "      <td>0.070340</td>\n",
       "      <td>0.380832</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.511538</td>\n",
       "      <td>0.626153</td>\n",
       "      <td>0.498366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.141877</td>\n",
       "      <td>0.090569</td>\n",
       "      <td>0.376666</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.501621</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.488562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.138230</td>\n",
       "      <td>0.113949</td>\n",
       "      <td>0.371793</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.507456</td>\n",
       "      <td>0.581145</td>\n",
       "      <td>0.498366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.136503</td>\n",
       "      <td>0.125018</td>\n",
       "      <td>0.369463</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.509964</td>\n",
       "      <td>0.573016</td>\n",
       "      <td>0.500980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.139118</td>\n",
       "      <td>0.108256</td>\n",
       "      <td>0.372985</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.534752</td>\n",
       "      <td>0.646296</td>\n",
       "      <td>0.520588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.141537</td>\n",
       "      <td>0.092751</td>\n",
       "      <td>0.376214</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.499869</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.491176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.139168</td>\n",
       "      <td>0.107931</td>\n",
       "      <td>0.373053</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.468758</td>\n",
       "      <td>0.530623</td>\n",
       "      <td>0.459150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.140635</td>\n",
       "      <td>0.098532</td>\n",
       "      <td>0.375013</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.532182</td>\n",
       "      <td>0.664352</td>\n",
       "      <td>0.517974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.069640</td>\n",
       "      <td>0.380975</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.532182</td>\n",
       "      <td>0.664352</td>\n",
       "      <td>0.517974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.137720</td>\n",
       "      <td>0.117219</td>\n",
       "      <td>0.371106</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.509964</td>\n",
       "      <td>0.573016</td>\n",
       "      <td>0.500980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.136670</td>\n",
       "      <td>0.123948</td>\n",
       "      <td>0.369689</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.503947</td>\n",
       "      <td>0.605556</td>\n",
       "      <td>0.491176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.136346</td>\n",
       "      <td>0.126022</td>\n",
       "      <td>0.369251</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.489222</td>\n",
       "      <td>0.548416</td>\n",
       "      <td>0.481373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.136992</td>\n",
       "      <td>0.121882</td>\n",
       "      <td>0.370124</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.479600</td>\n",
       "      <td>0.539181</td>\n",
       "      <td>0.471569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.109011</td>\n",
       "      <td>0.372827</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.501621</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.488562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.138789</td>\n",
       "      <td>0.110361</td>\n",
       "      <td>0.372545</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.491911</td>\n",
       "      <td>0.597902</td>\n",
       "      <td>0.478758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.137508</td>\n",
       "      <td>0.118576</td>\n",
       "      <td>0.370820</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.511538</td>\n",
       "      <td>0.626153</td>\n",
       "      <td>0.498366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.137971</td>\n",
       "      <td>0.115607</td>\n",
       "      <td>0.371445</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.487777</td>\n",
       "      <td>0.553011</td>\n",
       "      <td>0.478758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.138476</td>\n",
       "      <td>0.112369</td>\n",
       "      <td>0.372124</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.501621</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.488562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.136794</td>\n",
       "      <td>0.123154</td>\n",
       "      <td>0.369856</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.491911</td>\n",
       "      <td>0.597902</td>\n",
       "      <td>0.478758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.137890</td>\n",
       "      <td>0.116127</td>\n",
       "      <td>0.371335</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.473376</td>\n",
       "      <td>0.543434</td>\n",
       "      <td>0.466340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.137260</td>\n",
       "      <td>0.120167</td>\n",
       "      <td>0.370486</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.464276</td>\n",
       "      <td>0.530808</td>\n",
       "      <td>0.456536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.138905</td>\n",
       "      <td>0.109617</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.501621</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.488562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.138513</td>\n",
       "      <td>0.112135</td>\n",
       "      <td>0.372173</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.473376</td>\n",
       "      <td>0.543434</td>\n",
       "      <td>0.466340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.137352</td>\n",
       "      <td>0.119573</td>\n",
       "      <td>0.370611</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.497514</td>\n",
       "      <td>0.566162</td>\n",
       "      <td>0.488562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.137481</td>\n",
       "      <td>0.118747</td>\n",
       "      <td>0.370784</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.501621</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.488562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.137794</td>\n",
       "      <td>0.116743</td>\n",
       "      <td>0.371206</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.511538</td>\n",
       "      <td>0.626153</td>\n",
       "      <td>0.498366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "/home/imtk/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-69\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-69/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-69/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-69/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-69/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "/home/imtk/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-138\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-138/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-138/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-138/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-138/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-207\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-207/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-207/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-207/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-207/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-69] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-276\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-276/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-276/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-276/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-276/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-138] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-345\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-345/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-345/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-345/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-345/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-207] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "/home/imtk/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-414\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-414/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-414/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-414/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-414/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-276] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-483\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-483/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-483/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-483/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-483/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-345] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-552\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-552/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-552/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-552/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-552/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-414] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-621\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-621/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-621/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-621/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-621/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-483] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-690\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-690/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-690/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-690/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-690/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-552] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-759\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-759/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-759/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-759/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-759/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-690] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-828\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-828/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-828/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-828/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-828/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-759] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-897\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-897/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-897/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-897/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-897/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-621] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-966\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-966/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-966/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-966/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-966/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-828] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1035\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1035/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1035/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1035/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1035/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-897] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1104\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1104/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1104/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1104/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1104/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-966] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1173\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1173/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1173/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1173/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1173/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1104] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1242\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1242/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1242/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1242/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1242/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1173] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1311\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1311/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1311/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1311/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1311/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1035] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1380\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1380/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1380/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1380/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1380/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1242] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1449\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1449/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1449/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1449/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1449/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1380] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1518\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1518/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1518/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1518/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1518/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1449] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1587\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1587/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1587/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1587/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1587/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1518] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1656\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1656/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1656/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1656/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1656/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1587] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1725\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1725/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1725/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1725/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1725/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1656] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1794\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1794/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1794/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1794/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1794/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1725] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1863\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1863/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1863/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1863/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1863/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1794] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-1932\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-1932/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-1932/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-1932/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-1932/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1863] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2001\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2001/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2001/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2001/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2001/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1932] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2070\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2070/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2070/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2070/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2070/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2001] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2139\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2139/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2139/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2139/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2139/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2070] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2208\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2208/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2208/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2208/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2208/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2139] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2277\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2277/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2277/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2277/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2277/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2208] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2346\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2346/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2277] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2415\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2415/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2415/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2415/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2415/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2346] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2484\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2484/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2484/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2484/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2484/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2415] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2553\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2553/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2553/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2553/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2553/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2484] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2622\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2622/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2622/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2622/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2622/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2553] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2691\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2691/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2691/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2691/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2691/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2622] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2760\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2760/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2760/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2760/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2760/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2691] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2829\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2829/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2829/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2829/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2829/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2760] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2898\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2898/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2898/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2898/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2898/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2829] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-2967\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-2967/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-2967/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-2967/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-2967/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2898] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3036\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3036/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3036/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3036/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3036/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-2967] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3105\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3105/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3105/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3105/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3105/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3036] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3174\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3174/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3174/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3174/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3174/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-1311] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3243\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3243/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3243/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3243/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3243/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3105] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3312\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3312/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3312/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3312/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3312/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3243] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3381\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3381/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3381/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3381/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3381/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3312] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3450\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3450/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3450/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3450/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3450/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3174] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3519\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3519/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3519/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3519/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3519/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3381] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3588\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3588/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3588/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3588/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3588/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3519] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3657\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3657/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3657/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3657/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3657/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3588] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3726\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3726/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3726/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3726/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3726/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3657] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3795\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3795/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3795/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3795/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3795/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3726] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3864\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3864/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3864/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3864/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3864/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3795] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-3933\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-3933/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-3933/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-3933/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-3933/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3864] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4002\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4002/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4002/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4002/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4002/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3933] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4071\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4071/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4071/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4071/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4071/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-3450] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4140\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4140/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4140/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4140/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4140/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4002] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4209\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4209/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4209/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4209/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4209/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4140] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4278\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4278/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4278/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4278/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4278/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4209] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4347\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4347/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4347/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4347/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4347/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4278] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4416\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4416/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4416/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4416/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4416/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4347] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4485\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4485/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4485/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4485/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4485/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4416] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4554\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4554/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4554/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4554/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4554/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4485] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4623\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4623/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4623/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4623/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4623/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4554] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4692\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4692/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4623] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4761\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4761/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4761/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4761/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4761/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4692] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4830\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4830/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4830/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4830/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4830/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4761] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4899\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4899/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4899/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4899/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4899/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4830] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-4968\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-4968/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-4968/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-4968/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-4968/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4899] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5037\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5037/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5037/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5037/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5037/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-4968] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5106\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5106/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5106/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5106/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5106/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5037] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5175\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5175/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5175/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5175/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5175/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5106] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5244\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5244/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5244/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5244/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5244/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5175] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5313\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5313/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5313/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5313/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5313/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5244] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5382\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5382/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5382/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5382/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5382/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5313] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5451\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5451/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5451/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5451/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5451/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5382] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5520\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5520/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5520/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5520/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5520/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5451] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5589\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5589/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5589/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5589/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5589/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5520] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5658\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5658/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5658/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5658/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5658/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5589] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5727\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5727/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5727/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5727/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5727/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5658] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5796\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5796/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5796/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5796/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5796/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5727] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5865\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5865/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5865/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5865/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5865/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5796] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-5934\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-5934/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-5934/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-5934/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-5934/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5865] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6003\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6003/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6003/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6003/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6003/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-5934] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6072\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6072/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6072/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6072/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6072/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6003] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6141\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6141/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6141/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6141/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6141/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6072] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6210\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6210/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6210/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6210/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6210/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6141] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6279\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6279/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6279/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6279/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6279/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6210] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6348\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6348/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6348/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6348/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6348/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6279] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6417\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6417/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6417/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6417/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6417/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6348] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6486\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6486/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6486/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6486/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6486/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6417] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6555\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6555/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6555/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6555/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6555/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6486] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6624\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6624/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6624/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6624/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6624/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6555] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6693\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6693/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6693/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6693/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6693/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6624] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6762\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6762/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6762/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6762/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6762/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6693] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6831\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6831/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6831/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6831/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6831/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6762] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Regressors/task1_auth_usr100e/checkpoint-6900\n",
      "Configuration saved in ./Regressors/task1_auth_usr100e/checkpoint-6900/config.json\n",
      "Model weights saved in ./Regressors/task1_auth_usr100e/checkpoint-6900/pytorch_model.bin\n",
      "tokenizer config file saved in ./Regressors/task1_auth_usr100e/checkpoint-6900/tokenizer_config.json\n",
      "Special tokens file saved in ./Regressors/task1_auth_usr100e/checkpoint-6900/special_tokens_map.json\n",
      "Deleting older checkpoint [Regressors/task1_auth_usr100e/checkpoint-6831] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Regressors/task1_auth_usr100e/checkpoint-4071 (score: 0.5650602409638554).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Regressors/task1_auth_usr100e/checkpoint-4071\n",
      "step 6: evaluate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17200611531734467, 'eval_r2_score': 0.006928068459504999, 'eval_mean_squared_error': 0.41473624110221863, 'eval_accuracy': 0.5409836065573771, 'eval_f1': 0.4314514151174768, 'eval_precision': 0.5452380952380952, 'eval_recall': 0.43273809523809526, 'eval_runtime': 0.7107, 'eval_samples_per_second': 85.831, 'eval_steps_per_second': 5.628, 'epoch': 100.0}\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def authority_label_fn(label):\n",
    "    if label == '0. Very respect':\n",
    "        return 1\n",
    "    elif label =='1. Respect':\n",
    "        return 0.5\n",
    "    elif label == \"2. Normal\":\n",
    "        return 0\n",
    "    elif type(label)==str:\n",
    "        assert(False)\n",
    "    \n",
    "    # [0, 0.33) =>\n",
    "    # [0.33, 0.66) =>\n",
    "    # [0.66, 1] =>\n",
    "    \n",
    "    if label > 0.66:\n",
    "        return '0. Very respect'\n",
    "    elif label > 0.33:\n",
    "        return '1. Respect'\n",
    "    else:\n",
    "        return \"2. Normal\"\n",
    "    \n",
    "run_exp(\"./Regressors/task1_auth_usr100e\", df, report=report, regressor_configs={\n",
    "    \"label\": \"respect\",\n",
    "    \"not_label\": \"not_respect\",\n",
    "    \"label_fn\": authority_label_fn,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "215bff50-4304-4106-bbf1-4633c5e6e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_exp(\"./Models/task1_auth_usr100e\", df, report=report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe5ee6-da8d-446e-a14f-85ff9c617546",
   "metadata": {},
   "source": [
    "## Task2: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e2228a1-c5f6-4220-92aa-406e3f3108d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2486 records from ../Task2/annotated/annotated.jsonl\n",
      "N 1495 186 186\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Close</th>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Know each other</th>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Don't know each other</th>\n",
       "      <td>1487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text\n",
       "label                         \n",
       "1. Close                   222\n",
       "2. Know each other         158\n",
       "3. Don't know each other  1487"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task2_conver(\"../Task2/annotated/annotated.jsonl\", \"closeness\", skips = [\"4. Don't like each other\"], only_user=True)\n",
    "# print(df[0][\"text\"][0])\n",
    "pd.concat(df).groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c64d0c5f-c012-481f-b316-1c6b30130b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'closeness_label_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_63917/787948039.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"close\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"not_label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"not_close\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m\"label_fn\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcloseness_label_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'closeness_label_fn' is not defined"
     ]
    }
   ],
   "source": [
    "run_exp(\"./Regressors/task2_clse_usr100e\", df, report=report, regressor_configs={\n",
    "    \"label\": \"close\",\n",
    "    \"not_label\": \"not_close\",\n",
    "    \"label_fn\": closeness_label_fn,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13018546-bee3-4d66-af36-8c4c58753157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_exp(\"./Models/task2_clse_usr100e\", df, report=report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0df34-b578-4f83-989a-1d09d96c9e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1981804-f588-4959-aa36-f849f011cec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4aec330-7005-4c77-b427-1489374cc63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2486 records from ../Task2/annotated/annotated.jsonl\n",
      "N 1876 234 234\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Respect</th>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Normal</th>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Not respect</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text\n",
       "label               \n",
       "1. Respect       319\n",
       "2. Normal       1661\n",
       "3. Not respect   364"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task2_conver(\"../Task2/annotated/annotated.jsonl\", \"authority\", skips = [], only_user=True)\n",
    "# print(df[0][\"text\"][0])\n",
    "pd.concat(df).groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "132ac526-14cb-4357-851a-478903395257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def authority2_label_fn(label):\n",
    "#     if label == '1. Respect':\n",
    "#         return 1\n",
    "#     elif label =='2. Normal':\n",
    "#         return 0.5\n",
    "#     elif label == \"3. Not respect\":\n",
    "#         return 0\n",
    "#     elif type(label)==str:\n",
    "#         assert(False)\n",
    "    \n",
    "#     if label > 0.66:\n",
    "#         return '1. Respect'\n",
    "#     elif label > 0.33:\n",
    "#         return '2. Normal'\n",
    "#     else:\n",
    "#         return \"3. Not respect\"\n",
    "\n",
    "# run_exp(\"./Regressors/task2_auth_usr100e\", df, report=report, regressor_configs={\n",
    "#     \"label\": \"respect\",\n",
    "#     \"not_label\": \"not_respect\",\n",
    "#     \"label_fn\": authority2_label_fn,\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48bb4fb1-6c65-4272-aee6-82c45ff31f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_exp(\"./Models/task2_auth_usr100e\", df, report=report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cbe21a-0a9e-4b20-86b9-72067c928ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89a668-3680-4d2d-82ac-4b705dac628a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccd70a91-a596-4118-834c-ed6567ac8c53",
   "metadata": {},
   "source": [
    "## Task3: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c1a0dbb-4004-44de-ac45-5085086dbd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1221 records from ../Task3/annotated/annotated.jsonl\n",
      "N 1090 60 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Close</th>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Know each other</th>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Don't know each other</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text\n",
       "label                         \n",
       "1. Close                   462\n",
       "2. Know each other         696\n",
       "3. Don't know each other    52"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task1_conver(\"../Task3/annotated/annotated.jsonl\", \"closeness\", skips = [\"4. Don't like each other\"], only_user=True)\n",
    "# print(df[0][\"text\"][0])\n",
    "pd.concat(df).groupby(\"label\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edb5a5c8-9b01-452d-863b-66be4c056b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_exp(\"./Regressors/task3_clse_usr100e\", df, report=report, regressor_configs={\n",
    "#     \"label\": \"close\",\n",
    "#     \"not_label\": \"not_close\",\n",
    "#     \"label_fn\": closeness_label_fn,\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "680181f6-7abf-426c-9f1c-8795b4494894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_exp(\"./Models/task3_clse_usr100e\", df, report=report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808bccbc-f452-4de2-9156-3635717dc5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "675c4a41-36fd-406e-bca1-826c580d6c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_task1_conver(\"../Task3/annotated/annotated.jsonl\", \"authority\", skips = [], only_user=True)\n",
    "# # print(df[0][\"text\"][0])\n",
    "# pd.concat(df).groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b9708a6-d184-457b-8845-e40f34e7c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_exp(\"./Regressors/task3_auth_usr100e\", df, report=report, regressor_configs={\n",
    "#     \"label\": \"respect\",\n",
    "#     \"not_label\": \"not_respect\",\n",
    "#     \"label_fn\": authority2_label_fn,\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d687341-a269-4413-aedb-ea2ac53c81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_exp(\"./Models/task3_auth_usr\", df, report=report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd757fd8-3c63-4cdf-b054-7d3138fd757b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DOOOOOM'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"DOOOOOM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24f0ed3-3d91-40b3-9fb4-f91711d89210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c985948-e47f-445c-aa70-755816e2feaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
