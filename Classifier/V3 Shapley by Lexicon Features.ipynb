{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"0p-UJGeQI6Oo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523694933,"user_tz":-60,"elapsed":17852,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"61dcd9b7-79af-450c-d78e-41626c796ec0"},"id":"0p-UJGeQI6Oo","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/TalkLikeMom/src/Classifier"],"metadata":{"id":"DKlsKFflI8XV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714523696114,"user_tz":-60,"elapsed":1185,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"7d422f76-9426-4ef3-9e1a-7625ef686f71"},"id":"DKlsKFflI8XV","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/PHD/TalkLikeMom/src/Classifier\n"]}]},{"cell_type":"code","source":["# !pip install -q transformers pythainlp datasets evaluate sentencepiece\n","# # !pip install -q accelerate -U\n","# !pip install -q transformers[torch]\n","# !pip install -q shap nlp"],"metadata":{"id":"Rzh9mZJSI8aP"},"id":"Rzh9mZJSI8aP","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install spacy-alignments"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"opbc8JtUsisz","executionInfo":{"status":"ok","timestamp":1714525901861,"user_tz":-60,"elapsed":10402,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"f3bf8b5a-0158-44b0-ffdb-ed25e1a91d05"},"id":"opbc8JtUsisz","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting spacy-alignments\n","  Downloading spacy_alignments-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/314.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/314.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m307.2/314.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.0/314.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: spacy-alignments\n","Successfully installed spacy-alignments-0.9.1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"h9dOZzf8tSOe"},"id":"h9dOZzf8tSOe","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","sys.path.append('.')"],"metadata":{"id":"lI5ahDR-I8d-"},"id":"lI5ahDR-I8d-","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"826189f6-f662-4078-b677-686f7866488f","metadata":{"id":"826189f6-f662-4078-b677-686f7866488f"},"outputs":[],"source":["from data_loader import get_task1_conver, get_task2_conver\n","from utils import dump_jsonl, load_jsonl\n","\n","\n","import pickle\n","\n","def load_shap_values(filepath):\n","  with open(filepath, 'rb') as fin:\n","    obj = pickle.load(fin)\n","  return obj\n","\n","def save_shap_values(filepath, obj):\n","  with open(filepath, 'wb') as fin:\n","    pickle.dump(obj, fin)"]},{"cell_type":"code","execution_count":null,"id":"eae1169a-3167-4ba9-b958-f9135805f162","metadata":{"id":"eae1169a-3167-4ba9-b958-f9135805f162"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"666cb3a3-2ec9-4842-870a-b89b96f75e1c","metadata":{"id":"666cb3a3-2ec9-4842-870a-b89b96f75e1c"},"outputs":[],"source":["# from transformers import AutoTokenizer\n","# model_name = \"airesearch/wangchanberta-base-att-spm-uncased\"\n","# tokenizer = AutoTokenizer.from_pretrained(model_name)\n","# num_added_toks = tokenizer.add_special_tokens({\"additional_special_tokens\": [\"usr\", \"sys\", \"rep\"]})"]},{"cell_type":"code","execution_count":null,"id":"eca7cec2-f5eb-4a72-9cb0-b6d88e97707e","metadata":{"id":"eca7cec2-f5eb-4a72-9cb0-b6d88e97707e"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"lEUl0XWhl4Zk"},"id":"lEUl0XWhl4Zk","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Performance"],"metadata":{"id":"N2o3VFKXl48e"},"id":"N2o3VFKXl48e"},{"cell_type":"code","source":["import json\n","import numpy as np\n","\n","def load_json(filename):\n","  with open(filename) as fin:\n","    content = json.load(fin)\n","\n","  return content\n","\n","for m in [\"wc\", \"py\", \"xl\"]:\n","  for task in [\"clse\", \"auth\"]:\n","    for setting in [\"task1\", \"task2\", \"task3\"]:\n","      values = []\n","      k = \"eval_f1\"\n","      taskName = f\"{m}_{setting}_{task}\"\n","      for idx in range(5):\n","        folderName = f\"Regressors/{taskName}_usr{idx}/eval.json\"\n","        evalResults = load_json(folderName)\n","\n","        # Remove cases where the model loss is out-of-control\n","        if abs(evalResults[\"val\"][k] - evalResults[\"test\"][k]) > 0.155:\n","          continue\n","        values.append(evalResults[\"test\"][k])\n","\n","      avg = np.mean(values)\n","      std = np.std(values)\n","      print(taskName, f\"{avg:.3f}±{std:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boa5b0Gll4cc","executionInfo":{"status":"ok","timestamp":1714524970807,"user_tz":-60,"elapsed":994,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"b4df7068-a6a5-4f3c-ad13-e6913fcb847b"},"id":"boa5b0Gll4cc","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["wc_task1_clse 0.657±0.072\n","wc_task2_clse 0.490±0.048\n","wc_task3_clse 0.639±0.058\n","wc_task1_auth 0.313±0.056\n","wc_task2_auth 0.748±0.051\n","wc_task3_auth 0.761±0.029\n","py_task1_clse 0.666±0.016\n","py_task2_clse 0.496±0.009\n","py_task3_clse 0.657±0.013\n","py_task1_auth 0.431±0.044\n","py_task2_auth 0.750±0.017\n","py_task3_auth 0.712±0.000\n","xl_task1_clse 0.604±0.053\n","xl_task2_clse 0.420±0.086\n","xl_task3_clse 0.498±0.043\n","xl_task1_auth 0.200±0.064\n","xl_task2_auth 0.675±0.089\n","xl_task3_auth 0.432±0.071\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_RbpEx5Wl4gG"},"id":"_RbpEx5Wl4gG","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ERkkLmUulP_Y"},"id":"ERkkLmUulP_Y","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"53dd5afe-b3b9-484e-8628-c9d0c60c3122","metadata":{"id":"53dd5afe-b3b9-484e-8628-c9d0c60c3122"},"source":["## Load Lexicons"]},{"cell_type":"code","execution_count":null,"id":"f52407bf-66ad-4a78-b7ff-cecd72d64d15","metadata":{"id":"f52407bf-66ad-4a78-b7ff-cecd72d64d15"},"outputs":[],"source":["from pythainlp.tokenize import word_tokenize\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"id":"345c8438-4810-453d-8e69-a7c2504e5f2b","metadata":{"id":"345c8438-4810-453d-8e69-a7c2504e5f2b"},"outputs":[],"source":["import json\n","with open(\"../words.json\", encoding=\"utf-8\") as fin:\n","    raw = json.load(fin)\n","    thaidict_royal = set()\n","    for k in raw:\n","        thaidict_royal.update(raw[k])"]},{"cell_type":"code","execution_count":null,"id":"07775b4b-a694-471c-9e00-07157af10be6","metadata":{"id":"07775b4b-a694-471c-9e00-07157af10be6","outputId":"91ef160b-2589-471e-eec5-796356fab022","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714525339541,"user_tz":-60,"elapsed":250,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 25603 records from ../lexicons.jsonl\n"]}],"source":["lexicons_arr = load_jsonl(\"../lexicons.jsonl\")"]},{"cell_type":"code","execution_count":null,"id":"99344938-fa6d-48cf-97e2-04aa8353adbf","metadata":{"id":"99344938-fa6d-48cf-97e2-04aa8353adbf"},"outputs":[],"source":["from collections import defaultdict\n","tags = set()\n","lexicons = {}\n","lexicons_keys = defaultdict(list)\n","\n","for key, values  in lexicons_arr:\n","    if len(key) <= 1:\n","        continue\n","\n","    key = key.lower()\n","    if key.endswith(\"rep\"):\n","        key = key.replace(\"rep\", \"\")\n","\n","    w = word_tokenize(key)\n","\n","    lexicons_keys[w[0]].append(key)\n","\n","    tag = [t for t in values[\"tags\"] if not t.startswith(\"cat:\")]\n","    lexicons[key] = tag\n","    tags.update(tag)"]},{"cell_type":"code","execution_count":null,"id":"ad5b26e3-65f2-4adf-8901-dd81f83d7dae","metadata":{"id":"ad5b26e3-65f2-4adf-8901-dd81f83d7dae"},"outputs":[],"source":["# cc = 0\n","# for k in lexicons:\n","#     for t in lexicons[k]:\n","#         if t==\"transliterated\":\n","#             cc += 1\n","# cc"]},{"cell_type":"code","execution_count":null,"id":"25524732-2d62-4a46-b49a-e7dded1affbb","metadata":{"id":"25524732-2d62-4a46-b49a-e7dded1affbb"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"cd74d9f2-c5cc-4c07-9b55-618539ecca31","metadata":{"id":"cd74d9f2-c5cc-4c07-9b55-618539ecca31"},"outputs":[],"source":["metric_names = {\n","    \"Reference\" : {\n","#         \"all\": \"All words\",\n","        \"pertoken\": \"Average per token\"\n","    },\n","#     \"Linguistic Complexity\" : {\n","#         \"nunique\": \"Vocabulary size\",\n","#         \"nthai\": \"Thai words\",\n","#         \"nnotthai\": \"Non-Thai words\",\n","#         \"nlongword\": \"Long words\",\n","#         \"ndict\": \"Dictionary words\",\n","#         \"transliterated\": \"Transliteration\",\n","#     },\n","    \"Pronoun\": {\n","        \"pronoun\": \"All pronoun\",\n","        \"pronoun_1st\": \">> 1st person pronoun\",\n","        \"pronoun_2nd\": \">> 2nd person pronoun\",\n","        \"pronoun_3rd\": \">> 3rd person pronoun\",\n","        \"pronoun_singular\": \">> Singular pronoun\",\n","        \"pronoun_plural\": \">> Plural pronoun\",\n","        \"pronoun_misspelling\": \">> Pronoun in non-standard spelling\",\n","    },\n","\n","    \"Sentence-ending Particles\": {\n","        \"particles\": \"All particles\",\n","        \"particles_SARP\": \">> Socially-related particles\",\n","        \"particles_notSARP\": \">> Non-socially-related particles\",\n","        \"particles_misspelling\": \">> Particle in non-standard spelling\",\n","    },\n","\n","#     \"Sentiment-related\": {\n","#         \"sentiment\": \"Sentiment words\",\n","#         \"sentiment_positive\": \">> Positive words\",\n","#         \"sentiment_negative\": \">> Negative words\",\n","#     },\n","\n","    \"Spelling Variation\": {\n","        \"misspelling\": \"All spelling variation\",\n","        \"misspelling_common\": \">> Common misspelt words\",\n","        \"misspelling_intention\": \">> Morphophonemic variation\",\n","        \"misspelling_shorten\": \">> Simplified variation\",\n","        \"nrepeat\": \">> Repeated characters\",\n","#         \"nemoji\": \">> Emoji\",\n","#         \"abbr\": \"Abbreviation\",\n","#         \"slang\": \"Slang\",\n","#         \"swear\": \"Swear words\"\n","    }\n","}"]},{"cell_type":"code","source":[],"metadata":{"id":"3fzmhLFIx4ma"},"id":"3fzmhLFIx4ma","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lqDN59B-lrWc"},"id":"lqDN59B-lrWc","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"55GIxpNelrZh"},"id":"55GIxpNelrZh","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kb3YsfRPlrcZ"},"id":"kb3YsfRPlrcZ","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"77DYIu3ClrfR"},"id":"77DYIu3ClrfR","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load SHAP Values"],"metadata":{"id":"WKJdIkk1lzQ7"},"id":"WKJdIkk1lzQ7"},{"cell_type":"code","source":["from collections import defaultdict\n","from itertools import groupby\n","from data_loader import preprocess\n","\n","import spacy_alignments as tokenizations\n","\n","\n","def get_shap_lexicons(df, raw_shap_values):\n","    shap_lexicons = {\"overall\": []}\n","    label_values = set(df[\"label\"])\n","\n","\n","\n","    # _tmp = raw_shap_values[:, :]\n","    shap_data = raw_shap_values.data\n","    shap_values = raw_shap_values.values\n","\n","    for _, label in enumerate(label_values):\n","        feats = []\n","        for idx, (l, t) in enumerate(zip(df[\"label\"], df[\"text\"])):\n","            if l!=label:\n","                continue\n","\n","            words = word_tokenize(preprocess(t))\n","            words = [w.strip() for w in words if len(w.strip())>0]\n","\n","            shap_tokens = [(w.strip(), v) for w,v in zip(shap_data[idx], shap_values[idx]) if len(w.strip())>0]\n","            tokens = [t for t, _ in shap_tokens]\n","            values = [v for _, v in shap_tokens]\n","\n","            w2t, t2w = tokenizations.get_alignments(words, tokens)\n","            # shap_tokens = map_token_2_words(words, shap_tokens, debug=False)\n","            newwords = []\n","            newvalues = []\n","            for widx, word in enumerate(w2t):\n","              w = \"\"\n","              v = 0\n","              for tidx in word:\n","                w += tokens[tidx]\n","                v += values[tidx]\n","              newwords.append(w)\n","              newvalues.append(v)\n","\n","            feats.append((newwords, newvalues))\n","        shap_lexicons[label] = feats\n","        shap_lexicons[\"overall\"] += feats\n","\n","    return shap_lexicons\n","\n","def is_target_lexicons(token):\n","  token = token.lower()\n","  if token==\"rep\":\n","      return True\n","\n","  if token in lexicons_keys:\n","      for l in lexicons_keys[token]:\n","          if not token.startswith(l):\n","              continue\n","\n","          return True\n","  return False\n","\n","def get_shap_by_lexicons(shap_path, fn_abs=False):\n","    shap_values = load_shap_values(shap_path)\n","\n","    shap_lexicons = get_shap_lexicons(shap_values[\"inputs\"], shap_values[\"values\"])\n","    lexicons = {}\n","    for label in shap_lexicons:\n","\n","      shapley_values = defaultdict(list)\n","      for words, shap in shap_lexicons[label]:\n","        for w, s in zip(words, shap):\n","          shapley_values[w].append(s)\n","\n","\n","      feature_names = []\n","      avg_shape_values = []\n","      for w in shapley_values:\n","        if not is_target_lexicons(w):\n","          continue\n","\n","        feature_names.append(w)\n","\n","        if fn_abs:\n","            s = np.mean(np.abs(shapley_values[w]))\n","        else:\n","            s = np.mean((shapley_values[w]))\n","\n","        avg_shape_values.append(s)\n","\n","      sorted_shap_values = sorted(zip(avg_shape_values, feature_names), key=lambda pair: -pair[0])\n","      lexicons[label] = {x.lower():v for v, x in sorted_shap_values}\n","\n","    return lexicons\n","\n","\n"],"metadata":{"id":"9gsQSN9WLc0t"},"id":"9gsQSN9WLc0t","execution_count":null,"outputs":[]},{"cell_type":"code","source":["lexicons[\"rep\"] = [\"misspelling\"]\n","\n","def get_lexicons_by_feat(shap_lexicons):\n","  shap_lexicons_by_feat = {}\n","  for label in shap_lexicons:\n","    feats = [\"pronoun\", \"particles\", \"misspelling\"]\n","    shap_lexicons_by_feat[label] = {}\n","    for f in feats:\n","      shap_lexicons_by_feat[label][f] = {}\n","      for w in shap_lexicons[label]:\n","        tags = lexicons[w]\n","\n","        if f in lexicons[w]:\n","          shap_lexicons_by_feat[label][f][w] = shap_lexicons[label][w]\n","  return shap_lexicons_by_feat"],"metadata":{"id":"RgqCXFxmZ1o8"},"id":"RgqCXFxmZ1o8","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv ShapleyValues/xl_task2_clas_usr.pkl ShapleyValues/xl_task2_clse_usr.pkl"],"metadata":{"id":"vmLnXzs1xBSY"},"id":"vmLnXzs1xBSY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["fn_abs = True\n","suffix = \"abs\" if fn_abs else ''\n","\n","for m in [\"wc\", \"py\", \"xl\"]:\n","  for task in [\"clse\", \"auth\"]:\n","    for setting in [\"task1\", \"task2\", \"task3\"]:\n","      values = []\n","      k = \"eval_f1\"\n","      taskName = f\"{m}_{setting}_{task}\"\n","      print(f\"runing... {taskName}\")\n","      shap_lexicons = get_shap_by_lexicons(f\"./ShapleyValues/{taskName}_usr.pkl\", fn_abs)\n","      shap_lexicons_by_feat = get_lexicons_by_feat(shap_lexicons)\n","\n","      dump_jsonl(f\"Lexicons/{taskName}_{suffix}.jsonl\", [shap_lexicons, shap_lexicons_by_feat])"],"metadata":{"id":"mmdw7ljvLdJe","executionInfo":{"status":"ok","timestamp":1714526976442,"user_tz":-60,"elapsed":55445,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8c35b0ae-5c91-4390-abb9-9f523d52420a"},"id":"mmdw7ljvLdJe","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["runing... wc_task1_clse\n","Wrote 2 records to Lexicons/wc_task1_clse_abs.jsonl\n","runing... wc_task2_clse\n","Wrote 2 records to Lexicons/wc_task2_clse_abs.jsonl\n","runing... wc_task3_clse\n","Wrote 2 records to Lexicons/wc_task3_clse_abs.jsonl\n","runing... wc_task1_auth\n","Wrote 2 records to Lexicons/wc_task1_auth_abs.jsonl\n","runing... wc_task2_auth\n","Wrote 2 records to Lexicons/wc_task2_auth_abs.jsonl\n","runing... wc_task3_auth\n","Wrote 2 records to Lexicons/wc_task3_auth_abs.jsonl\n","runing... py_task1_clse\n","Wrote 2 records to Lexicons/py_task1_clse_abs.jsonl\n","runing... py_task2_clse\n","Wrote 2 records to Lexicons/py_task2_clse_abs.jsonl\n","runing... py_task3_clse\n","Wrote 2 records to Lexicons/py_task3_clse_abs.jsonl\n","runing... py_task1_auth\n","Wrote 2 records to Lexicons/py_task1_auth_abs.jsonl\n","runing... py_task2_auth\n","Wrote 2 records to Lexicons/py_task2_auth_abs.jsonl\n","runing... py_task3_auth\n","Wrote 2 records to Lexicons/py_task3_auth_abs.jsonl\n","runing... xl_task1_clse\n","Wrote 2 records to Lexicons/xl_task1_clse_abs.jsonl\n","runing... xl_task2_clse\n","Wrote 2 records to Lexicons/xl_task2_clse_abs.jsonl\n","runing... xl_task3_clse\n","Wrote 2 records to Lexicons/xl_task3_clse_abs.jsonl\n","runing... xl_task1_auth\n","Wrote 2 records to Lexicons/xl_task1_auth_abs.jsonl\n","runing... xl_task2_auth\n","Wrote 2 records to Lexicons/xl_task2_auth_abs.jsonl\n","runing... xl_task3_auth\n","Wrote 2 records to Lexicons/xl_task3_auth_abs.jsonl\n"]}]},{"cell_type":"markdown","source":["## Print outputs"],"metadata":{"id":"iR5xAS8o0udZ"},"id":"iR5xAS8o0udZ"},{"cell_type":"code","source":["from pythainlp.util import countthai\n","import re\n","# import emoji\n","\n","def get_lexicon_feats(token, ref_text):\n","    feats = [\"all\"]\n","\n","    if token==\"rep\":\n","        feats.append(\"nrepeat\")\n","\n","    if token in lexicons_keys:\n","        for l in lexicons_keys[token]:\n","            if not ref_text.startswith(l):\n","                continue\n","\n","            feats.extend(lexicons[l])\n","\n","    if token in thaidict_royal:\n","        feats.append(\"ndict\")\n","\n","    if len(token) > 7:\n","        feats.append(\"nlongword\")\n","\n","    if countthai(token) < 50:\n","        nt = re.sub(r'\\W+', '', token)\n","        if token not in [\"usr\", \"sys\", \"rep\"] and len(nt) > 0 and not nt.isnumeric():\n","            feats.append(\"nnotthai\")\n","    else:\n","        feats.append(\"nthai\")\n","\n","    if \"particles\" in feats and \"particles_SARP\" not in feats:\n","        feats.append(\"particles_notSARP\")\n","\n","    # if emoji.emoji_count(token) > 0:\n","    #     feats.append(\"nemoji\")\n","\n","    return feats\n","\n","\n","def get_shap_feats(shap_lexicons):\n","    output = {}\n","    for label in shap_lexicons:\n","        all_shap_feats = []\n","        for tokens, values in shap_lexicons[label]:\n","            # shap_feats is per conversation\n","            shap_feats = defaultdict(list)\n","            for tidx, (t, v) in enumerate(zip(tokens, values)):\n","                feats = get_lexicon_feats(t, \"\".join(tokens[tidx:]))\n","\n","                for f in feats:\n","                    shap_feats[f].append(v)\n","\n","#             shap_feats[\"pertoken\"] = sum(values)/len(values)\n","            shap_feats[\"pertoken\"] = values\n","            all_shap_feats.append(shap_feats)\n","\n","        mean_shap_feats = {}\n","        for g in metric_names:\n","            for m in metric_names[g]:\n","                values_each_token = []\n","                values_each_conv = []\n","\n","                for feats in all_shap_feats:\n","                    if m in feats:\n","                        values_each_token += feats[m]\n","\n","                        absum = np.sum(np.abs(np.array(feats[m])))\n","                        values_each_conv += [absum]\n","                        #values.append(feats[m])\n","\n","                if len(values_each_token)==0:\n","                    mean_shap_feats[m] = (0, 0, 0, 0)\n","                    continue\n","\n","                values = np.array(values_each_token)\n","                pertoken = np.mean(np.abs(np.array(values)))\n","\n","\n","                perconv = np.mean(np.array(values_each_conv))\n","\n","                mean_shap_feats[m] = (pertoken, len(values_each_token), perconv, len(values_each_conv))\n","        output[label] = mean_shap_feats\n","\n","    return output\n","\n","def run_lexicons(shap_path):\n","    shap_values = load_shap_values(shap_path)\n","\n","    shap_lexicons = get_shap_lexicons(shap_values[\"inputs\"], shap_values[\"values\"])\n","    shap_feats = get_shap_feats(shap_lexicons)\n","\n","    return shap_feats\n","\n"],"metadata":{"id":"P1aLdUs804pf"},"id":"P1aLdUs804pf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def outputs_to_dict(outputs):\n","    coefs = {}\n","    all_coefs = {}\n","\n","    for s in outputs:\n","        for feat in outputs[s]:\n","            if feat not in coefs:\n","                coefs[feat] = (0, 0)\n","\n","            if feat not in all_coefs:\n","                all_coefs[feat] = (0, 0)\n","\n","            # pertoken coefs\n","            val1, n1, _, _ = outputs[s][feat]\n","            val2, n2 = coefs[feat]\n","\n","            if n1+n2 == 0:\n","                coefs[feat] = (0, 0)\n","            else:\n","                val = (val1*n1 + val2*n2)*1.0/(n1+n2)\n","                n = n1 + n2\n","                coefs[feat] = (val, n)\n","\n","            # perconv coefs\n","            _, _, val1, n1 = outputs[s][feat]\n","            val2, n2 = all_coefs[feat]\n","\n","            if n1+n2 == 0:\n","                all_coefs[feat] = (0, 0)\n","            else:\n","                val = (val1*n1 + val2*n2)*1.0/(n1+n2)\n","                n = n1 + n2\n","                all_coefs[feat] = (val, n)\n","\n","    return coefs, all_coefs\n","\n"],"metadata":{"id":"-ACLMQOU0pCA"},"id":"-ACLMQOU0pCA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_tables(shap_feats):\n","    printed_text = \"\"\n","    printed_text += \"\\subsection{Closeness}\"+\"\\n\"\n","    outputs = [\n","        outputs_to_dict(shap_feats[1]),\n","        outputs_to_dict(shap_feats[3]),\n","        outputs_to_dict(shap_feats[5])\n","    ]\n","\n","    printed_text += \"\\\\begin{longtable}[h]{\"+\"\\n\"\n","    printed_text += \"    p{\\dimexpr 0.40\\\\linewidth-2\\\\tabcolsep}|c|c|c|c|c|c|\"+\"\\n\"\n","    printed_text += \"}\"+\"\\n\"\n","    printed_text += \"    \\hline\"+\"\\n\"\n","    printed_text += \"    Lexical Features & \" + \"\\n\"\n","    printed_text += \"    \\\\multicolumn{2}{|c|}{Setting 1} & \" + \"\\n\"\n","    printed_text += \"    \\\\multicolumn{2}{|c|}{Setting 2} & \" + \"\\n\"\n","    printed_text += \"    \\\\multicolumn{2}{|c|}{Setting 3} \\\\\\\\\" + \"\\n\"\n","    printed_text += \"    \\\\cline{2-7}\" + \"\\n\"\n","    printed_text += \"    & \" + \"\\n\"\n","    printed_text += \"    Per \\\\newline token & Total & \" + \"\\n\"\n","    printed_text += \"    Per \\\\newline token & Total & \" + \"\\n\"\n","    printed_text += \"    Per \\\\newline token & Total \\\\\\\\\" + \"\\n\"\n","\n","    printed_text += \"    \\hline\"+\"\\n\"\n","    #     printed_text += \"    \\endfirsthead\"+\"\\n\"\n","    #     printed_text += \"\"+\"\\n\"\n","    printed_text += \"    \\endhead\"+\"\\n\"\n","    printed_text += \"\"+\"\\n\"\n","\n","    # for sec, results in zip(sections, outputs):\n","    for g in metric_names:\n","        if g in [\"Conversational Statistics\"]:\n","            continue\n","\n","        printed_text += \"    \\multicolumn{7}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n","        printed_text += \"    \\hline\"+\"\\n\"\n","\n","        for m in metric_names[g]:\n","            s = f\"        {metric_names[g][m]} \"\n","            for out, all_out in outputs:\n","                if m not in out:\n","                    s += f\"& - \"\n","                else:\n","                    val, n = out[m]\n","                    all_val, _ = all_out[m]\n","                    ref, _ = out[\"pertoken\"]\n","\n","                    if (val - ref) > 0.1*ref:\n","                        s += \"& \\cellcolor{gray!25} \"+f\"{val*100:.2f}\"+\" & \\cellcolor{gray!25} \"+f\"{all_val*100:.2f}\"\n","                    else:\n","                        s += f\"& {val*100:.2f} & {all_val*100:.2f}\"\n","\n","            s += \"\\\\\\\\\"\n","            # print(s)\n","            printed_text += s+\"\\n\"\n","\n","\n","        printed_text += \"        & & & & & &\\\\\\\\\"+\"\\n\"\n","        printed_text += \"    \\hline\"+\"\\n\"\n","        printed_text += \"\"+\"\\n\"\n","\n","    printed_text += \"\\label{closeness_wangchanberta_shapley_value}\"+\"\\n\"\n","    printed_text += \"\\end{longtable}\"+\"\\n\"\n","    printed_text += \"\\clearpage\"+\"\\n\"\n","\n","    printed_text += \"\\subsection{Respect}\"+\"\\n\"\n","\n","    outputs = [\n","        outputs_to_dict(shap_feats[2]),\n","        outputs_to_dict(shap_feats[4]),\n","        outputs_to_dict(shap_feats[6])\n","    ]\n","\n","    printed_text += \"\\\\begin{longtable}[h]{\"+\"\\n\"\n","    printed_text += \"    p{\\dimexpr 0.40\\\\linewidth-2\\\\tabcolsep}|c|c|c|c|c|c|\"+\"\\n\"\n","    printed_text += \"}\"+\"\\n\"\n","    printed_text += \"    \\hline\"+\"\\n\"\n","    printed_text += \"    Lexical Features & \" + \"\\n\"\n","    printed_text += \"    \\\\multicolumn{2}{|c|}{Setting 1} & \" + \"\\n\"\n","    printed_text += \"    \\\\multicolumn{2}{|c|}{Setting 2} & \" + \"\\n\"\n","    printed_text += \"    \\\\multicolumn{2}{|c|}{Setting 3} \\\\\\\\\" + \"\\n\"\n","    printed_text += \"    \\\\cline{2-7}\" + \"\\n\"\n","    printed_text += \"    & \" + \"\\n\"\n","    printed_text += \"    Per \\\\newline token & Total & \" + \"\\n\"\n","    printed_text += \"    Per \\\\newline token & Total & \" + \"\\n\"\n","    printed_text += \"    Per \\\\newline token & Total \\\\\\\\\" + \"\\n\"\n","\n","    printed_text += \"    \\hline\"+\"\\n\"\n","    #     printed_text += \"    \\endfirsthead\"+\"\\n\"\n","    #     printed_text += \"\"+\"\\n\"\n","    printed_text += \"    \\endhead\"+\"\\n\"\n","    printed_text += \"\"+\"\\n\"\n","\n","    # for sec, results in zip(sections, outputs):\n","    for g in metric_names:\n","        if g in [\"Conversational Statistics\"]:\n","            continue\n","\n","        printed_text += \"    \\multicolumn{7}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n","        printed_text += \"    \\hline\"+\"\\n\"\n","\n","        for m in metric_names[g]:\n","            s = f\"        {metric_names[g][m]} \"\n","            for out, all_out in outputs:\n","                if m not in out:\n","                    s += f\"& - \"\n","                else:\n","                    val, n = out[m]\n","                    all_val, _ = all_out[m]\n","                    ref, _ = out[\"pertoken\"]\n","\n","                    if (val - ref) > 0.1*ref:\n","                        s += \"& \\cellcolor{gray!25} \"+f\"{val*100:.2f}\"+\" & \\cellcolor{gray!25} \"+f\"{all_val*100:.2f}\"\n","                    else:\n","                        s += f\"& {val*100:.2f} & {all_val*100:.2f}\"\n","\n","            s += \"\\\\\\\\\"\n","            # print(s)\n","            printed_text += s+\"\\n\"\n","\n","\n","        printed_text += \"        & & & & & &\\\\\\\\\"+\"\\n\"\n","        printed_text += \"    \\hline\"+\"\\n\"\n","        printed_text += \"\"+\"\\n\"\n","    printed_text += \"\\label{respect_wangchanberta_shapley_value}\"+\"\\n\"\n","    printed_text += \"\\end{longtable}\"+\"\\n\"\n","\n","    return printed_text"],"metadata":{"id":"xAibmEddQp-Q"},"id":"xAibmEddQp-Q","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-O-ma7Fn52Gr"},"id":"-O-ma7Fn52Gr","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qv6iJzdv6uD-"},"id":"qv6iJzdv6uD-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# shap_feats1 = run_lexicons(f\"./ShapleyValuesV3/task1_clse_regressor.pkl\")\n","# shap_feats2 = run_lexicons(f\"./ShapleyValuesV3/task1_auth_regressor.pkl\")\n","# shap_feats3 = run_lexicons(f\"./ShapleyValuesV3/task2_clse_regressor.pkl\")\n","# shap_feats4 = run_lexicons(f\"./ShapleyValuesV3/task2_auth_regressor.pkl\")\n","# shap_feats5 = run_lexicons(f\"./ShapleyValuesV3/task3_clse_regressor.pkl\")\n","# shap_feats6 = run_lexicons(f\"./ShapleyValuesV3/task3_auth_regressor.pkl\")"],"metadata":{"id":"o4WMXjXC6wOm"},"id":"o4WMXjXC6wOm","execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls ShapleyValues"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T8KZA_L5zN75","executionInfo":{"status":"ok","timestamp":1714527466280,"user_tz":-60,"elapsed":289,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"8bb077d8-ccdd-493c-a3e2-0b8112e7a450"},"id":"T8KZA_L5zN75","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["py_task1_auth_usr.pkl  py_task3_clse_usr.pkl  wc_task3_auth_usr.pkl  xl_task2_clse_usr.pkl\n","py_task1_clse_usr.pkl  wc_task1_auth_usr.pkl  wc_task3_clse_usr.pkl  xl_task3_auth_usr.pkl\n","py_task2_auth_usr.pkl  wc_task1_clse_usr.pkl  xl_task1_auth_usr.pkl  xl_task3_clse_usr.pkl\n","py_task2_clse_usr.pkl  wc_task2_auth_usr.pkl  xl_task1_clse_usr.pkl\n","py_task3_auth_usr.pkl  wc_task2_clse_usr.pkl  xl_task2_auth_usr.pkl\n"]}]},{"cell_type":"code","source":["fn_abs = True\n","suffix = \"abs\" if fn_abs else ''\n","\n","printed_texts = []\n","for m in [\"wc\", \"py\", \"xl\"]:\n","  shap_feats = {}\n","  idx = 1\n","  for setting in [\"task1\", \"task2\", \"task3\"]:\n","    for task in [\"clse\", \"auth\"]:\n","      taskName = f\"{m}_{setting}_{task}\"\n","      print(f\"runing... {taskName}\")\n","      shap_feats[idx] = run_lexicons(f\"./ShapleyValues/{taskName}_usr.pkl\")\n","      idx += 1\n","\n","  t = print_tables(shap_feats)\n","  printed_texts.append(t)\n","  print(\"Loaded\", m)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dDaLtWNryLvc","executionInfo":{"status":"ok","timestamp":1714527681730,"user_tz":-60,"elapsed":96109,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"c8f5d132-4a52-41bf-bdc5-34bf3ac20f9c"},"id":"dDaLtWNryLvc","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["runing... wc_task1_clse\n","runing... wc_task1_auth\n","runing... wc_task2_clse\n","runing... wc_task2_auth\n","runing... wc_task3_clse\n","runing... wc_task3_auth\n","Loaded wc\n","runing... py_task1_clse\n","runing... py_task1_auth\n","runing... py_task2_clse\n","runing... py_task2_auth\n","runing... py_task3_clse\n","runing... py_task3_auth\n","Loaded py\n","runing... xl_task1_clse\n","runing... xl_task1_auth\n","runing... xl_task2_clse\n","runing... xl_task2_auth\n","runing... xl_task3_clse\n","runing... xl_task3_auth\n","Loaded xl\n"]}]},{"cell_type":"code","source":["print(\"wc\", printed_texts[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l30gXRMvyLyC","executionInfo":{"status":"ok","timestamp":1714527682473,"user_tz":-60,"elapsed":29,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"b414db3d-0483-47ed-ac4c-c0fb33aace9c"},"id":"l30gXRMvyLyC","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["wc \\subsection{Closeness}\n","\\begin{longtable}[h]{\n","    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|c|c|c|c|c|c|\n","}\n","    \\hline\n","    Lexical Features & \n","    \\multicolumn{2}{|c|}{Setting 1} & \n","    \\multicolumn{2}{|c|}{Setting 2} & \n","    \\multicolumn{2}{|c|}{Setting 3} \\\\\n","    \\cline{2-7}\n","    & \n","    Per \\newline token & Total & \n","    Per \\newline token & Total & \n","    Per \\newline token & Total \\\\\n","    \\hline\n","    \\endhead\n","\n","    \\multicolumn{7}{l}{\\textit{Reference}} \\\\\n","    \\hline\n","        Average per token & 1.34 & 156.00& 2.91 & 105.40& 1.17 & 135.70\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Pronoun}} \\\\\n","    \\hline\n","        All pronoun & \\cellcolor{gray!25} 1.51 & \\cellcolor{gray!25} 5.42& \\cellcolor{gray!25} 3.68 & \\cellcolor{gray!25} 7.72& \\cellcolor{gray!25} 1.92 & \\cellcolor{gray!25} 6.78\\\\\n","        >> 1st person pronoun & \\cellcolor{gray!25} 1.61 & \\cellcolor{gray!25} 3.69& \\cellcolor{gray!25} 4.51 & \\cellcolor{gray!25} 6.76& \\cellcolor{gray!25} 1.67 & \\cellcolor{gray!25} 3.77\\\\\n","        >> 2nd person pronoun & \\cellcolor{gray!25} 1.91 & \\cellcolor{gray!25} 4.83& \\cellcolor{gray!25} 3.76 & \\cellcolor{gray!25} 6.66& \\cellcolor{gray!25} 2.41 & \\cellcolor{gray!25} 6.05\\\\\n","        >> 3rd person pronoun & 0.94 & 1.74& 2.21 & 3.57& \\cellcolor{gray!25} 1.87 & \\cellcolor{gray!25} 3.44\\\\\n","        >> Singular pronoun & \\cellcolor{gray!25} 1.52 & \\cellcolor{gray!25} 5.42& \\cellcolor{gray!25} 3.72 & \\cellcolor{gray!25} 7.73& \\cellcolor{gray!25} 1.92 & \\cellcolor{gray!25} 6.77\\\\\n","        >> Plural pronoun & 0.46 & 0.46& 1.32 & 1.76& 0.24 & 0.24\\\\\n","        >> Pronoun in non-standard spelling & 0.90 & 1.92& \\cellcolor{gray!25} 6.02 & \\cellcolor{gray!25} 7.91& \\cellcolor{gray!25} 1.72 & \\cellcolor{gray!25} 3.43\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Sentence-ending Particles}} \\\\\n","    \\hline\n","        All particles & \\cellcolor{gray!25} 2.87 & \\cellcolor{gray!25} 14.46& \\cellcolor{gray!25} 3.30 & \\cellcolor{gray!25} 5.99& \\cellcolor{gray!25} 1.51 & \\cellcolor{gray!25} 7.64\\\\\n","        >> Socially-related particles & \\cellcolor{gray!25} 5.24 & \\cellcolor{gray!25} 16.26& \\cellcolor{gray!25} 3.43 & \\cellcolor{gray!25} 4.91& \\cellcolor{gray!25} 2.58 & \\cellcolor{gray!25} 8.02\\\\\n","        >> Non-socially-related particles & 1.43 & 5.00& \\cellcolor{gray!25} 3.21 & \\cellcolor{gray!25} 5.03& 0.86 & 3.03\\\\\n","        >> Particle in non-standard spelling & \\cellcolor{gray!25} 1.98 & \\cellcolor{gray!25} 2.77& \\cellcolor{gray!25} 7.20 & \\cellcolor{gray!25} 7.94& 1.08 & 1.51\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Spelling Variation}} \\\\\n","    \\hline\n","        All spelling variation & 1.39 & 18.25& \\cellcolor{gray!25} 3.36 & \\cellcolor{gray!25} 14.89& 1.08 & 14.23\\\\\n","        >> Common misspelt words & 1.09 & 1.69& 3.14 & 4.33& 1.22 & 1.89\\\\\n","        >> Morphophonemic variation & \\cellcolor{gray!25} 1.64 & \\cellcolor{gray!25} 13.66& \\cellcolor{gray!25} 4.21 & \\cellcolor{gray!25} 11.83& 1.19 & 9.90\\\\\n","        >> Simplified variation & 1.08 & 7.00& 2.69 & 7.98& 0.87 & 5.67\\\\\n","        >> Repeated characters & 0.64 & 1.37& \\cellcolor{gray!25} 3.39 & \\cellcolor{gray!25} 4.44& 0.41 & 0.88\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","\\label{closeness_wangchanberta_shapley_value}\n","\\end{longtable}\n","\\clearpage\n","\\subsection{Respect}\n","\\begin{longtable}[h]{\n","    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|c|c|c|c|c|c|\n","}\n","    \\hline\n","    Lexical Features & \n","    \\multicolumn{2}{|c|}{Setting 1} & \n","    \\multicolumn{2}{|c|}{Setting 2} & \n","    \\multicolumn{2}{|c|}{Setting 3} \\\\\n","    \\cline{2-7}\n","    & \n","    Per \\newline token & Total & \n","    Per \\newline token & Total & \n","    Per \\newline token & Total \\\\\n","    \\hline\n","    \\endhead\n","\n","    \\multicolumn{7}{l}{\\textit{Reference}} \\\\\n","    \\hline\n","        Average per token & 1.49 & 173.20& 2.16 & 80.16& 0.46 & 53.21\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Pronoun}} \\\\\n","    \\hline\n","        All pronoun & \\cellcolor{gray!25} 3.57 & \\cellcolor{gray!25} 12.84& \\cellcolor{gray!25} 2.64 & \\cellcolor{gray!25} 6.11& \\cellcolor{gray!25} 1.11 & \\cellcolor{gray!25} 4.06\\\\\n","        >> 1st person pronoun & \\cellcolor{gray!25} 3.76 & \\cellcolor{gray!25} 8.59& 1.86 & 2.92& \\cellcolor{gray!25} 1.24 & \\cellcolor{gray!25} 2.89\\\\\n","        >> 2nd person pronoun & \\cellcolor{gray!25} 4.17 & \\cellcolor{gray!25} 10.54& \\cellcolor{gray!25} 3.25 & \\cellcolor{gray!25} 6.05& \\cellcolor{gray!25} 1.00 & \\cellcolor{gray!25} 2.57\\\\\n","        >> 3rd person pronoun & \\cellcolor{gray!25} 3.28 & \\cellcolor{gray!25} 6.10& 1.92 & 3.43& 0.44 & 0.82\\\\\n","        >> Singular pronoun & \\cellcolor{gray!25} 3.59 & \\cellcolor{gray!25} 12.85& \\cellcolor{gray!25} 2.66 & \\cellcolor{gray!25} 6.11& \\cellcolor{gray!25} 1.11 & \\cellcolor{gray!25} 4.06\\\\\n","        >> Plural pronoun & 0.55 & 0.55& 1.09 & 1.34& 0.22 & 0.22\\\\\n","        >> Pronoun in non-standard spelling & \\cellcolor{gray!25} 3.62 & \\cellcolor{gray!25} 7.52& 2.00 & 2.89& \\cellcolor{gray!25} 1.07 & \\cellcolor{gray!25} 2.39\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Sentence-ending Particles}} \\\\\n","    \\hline\n","        All particles & 1.53 & 7.77& 2.26 & 4.35& 0.49 & 2.47\\\\\n","        >> Socially-related particles & \\cellcolor{gray!25} 2.02 & \\cellcolor{gray!25} 6.27& \\cellcolor{gray!25} 3.16 & \\cellcolor{gray!25} 4.58& \\cellcolor{gray!25} 0.69 & \\cellcolor{gray!25} 2.14\\\\\n","        >> Non-socially-related particles & 1.24 & 4.35& 1.67 & 2.86& 0.37 & 1.29\\\\\n","        >> Particle in non-standard spelling & \\cellcolor{gray!25} 1.79 & \\cellcolor{gray!25} 2.52& \\cellcolor{gray!25} 2.45 & \\cellcolor{gray!25} 2.87& 0.39 & 0.55\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Spelling Variation}} \\\\\n","    \\hline\n","        All spelling variation & \\cellcolor{gray!25} 1.91 & \\cellcolor{gray!25} 25.11& 1.93 & 8.86& 0.46 & 6.01\\\\\n","        >> Common misspelt words & 1.53 & 2.37& 2.26 & 3.12& 0.49 & 0.76\\\\\n","        >> Morphophonemic variation & \\cellcolor{gray!25} 2.29 & \\cellcolor{gray!25} 19.08& 2.16 & 6.40& \\cellcolor{gray!25} 0.51 & \\cellcolor{gray!25} 4.27\\\\\n","        >> Simplified variation & 1.45 & 9.36& 1.64 & 5.07& 0.38 & 2.44\\\\\n","        >> Repeated characters & 0.66 & 1.42& 1.28 & 1.69& 0.18 & 0.39\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","\\label{respect_wangchanberta_shapley_value}\n","\\end{longtable}\n","\n"]}]},{"cell_type":"code","source":["print(\"py\", printed_texts[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ui6IVlUXyL1c","executionInfo":{"status":"ok","timestamp":1714527682473,"user_tz":-60,"elapsed":26,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"0d519548-50ff-49d3-ec4d-6feeba082477"},"id":"Ui6IVlUXyL1c","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["py \\subsection{Closeness}\n","\\begin{longtable}[h]{\n","    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|c|c|c|c|c|c|\n","}\n","    \\hline\n","    Lexical Features & \n","    \\multicolumn{2}{|c|}{Setting 1} & \n","    \\multicolumn{2}{|c|}{Setting 2} & \n","    \\multicolumn{2}{|c|}{Setting 3} \\\\\n","    \\cline{2-7}\n","    & \n","    Per \\newline token & Total & \n","    Per \\newline token & Total & \n","    Per \\newline token & Total \\\\\n","    \\hline\n","    \\endhead\n","\n","    \\multicolumn{7}{l}{\\textit{Reference}} \\\\\n","    \\hline\n","        Average per token & 1.08 & 125.36& 4.07 & 147.01& 0.85 & 97.91\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Pronoun}} \\\\\n","    \\hline\n","        All pronoun & 1.13 & 4.05& \\cellcolor{gray!25} 4.52 & \\cellcolor{gray!25} 9.47& \\cellcolor{gray!25} 1.60 & \\cellcolor{gray!25} 5.65\\\\\n","        >> 1st person pronoun & \\cellcolor{gray!25} 1.25 & \\cellcolor{gray!25} 2.85& \\cellcolor{gray!25} 5.15 & \\cellcolor{gray!25} 7.73& \\cellcolor{gray!25} 1.14 & \\cellcolor{gray!25} 2.56\\\\\n","        >> 2nd person pronoun & \\cellcolor{gray!25} 1.30 & \\cellcolor{gray!25} 3.29& 4.33 & 7.68& \\cellcolor{gray!25} 2.04 & \\cellcolor{gray!25} 5.11\\\\\n","        >> 3rd person pronoun & 0.71 & 1.31& 3.47 & 5.61& \\cellcolor{gray!25} 1.71 & \\cellcolor{gray!25} 3.14\\\\\n","        >> Singular pronoun & 1.13 & 4.04& \\cellcolor{gray!25} 4.52 & \\cellcolor{gray!25} 9.40& \\cellcolor{gray!25} 1.60 & \\cellcolor{gray!25} 5.65\\\\\n","        >> Plural pronoun & 1.07 & 1.07& 4.30 & 5.73& 0.49 & 0.49\\\\\n","        >> Pronoun in non-standard spelling & 0.74 & 1.58& \\cellcolor{gray!25} 7.62 & \\cellcolor{gray!25} 10.02& \\cellcolor{gray!25} 1.23 & \\cellcolor{gray!25} 2.44\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Sentence-ending Particles}} \\\\\n","    \\hline\n","        All particles & \\cellcolor{gray!25} 1.75 & \\cellcolor{gray!25} 8.81& 4.16 & 7.54& 0.93 & 4.68\\\\\n","        >> Socially-related particles & \\cellcolor{gray!25} 3.24 & \\cellcolor{gray!25} 10.03& \\cellcolor{gray!25} 5.08 & \\cellcolor{gray!25} 7.27& \\cellcolor{gray!25} 1.31 & \\cellcolor{gray!25} 4.08\\\\\n","        >> Non-socially-related particles & 0.85 & 2.97& 3.47 & 5.45& 0.69 & 2.43\\\\\n","        >> Particle in non-standard spelling & \\cellcolor{gray!25} 1.33 & \\cellcolor{gray!25} 1.86& \\cellcolor{gray!25} 7.63 & \\cellcolor{gray!25} 8.41& \\cellcolor{gray!25} 1.11 & \\cellcolor{gray!25} 1.56\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Spelling Variation}} \\\\\n","    \\hline\n","        All spelling variation & 1.10 & 14.48& 4.39 & 19.46& 0.86 & 11.28\\\\\n","        >> Common misspelt words & 0.83 & 1.29& 3.80 & 5.24& 0.80 & 1.24\\\\\n","        >> Morphophonemic variation & \\cellcolor{gray!25} 1.26 & \\cellcolor{gray!25} 10.49& \\cellcolor{gray!25} 5.37 & \\cellcolor{gray!25} 15.10& \\cellcolor{gray!25} 0.95 & \\cellcolor{gray!25} 7.91\\\\\n","        >> Simplified variation & 0.90 & 5.81& 3.63 & 10.79& 0.74 & 4.77\\\\\n","        >> Repeated characters & 0.85 & 1.82& 3.41 & 4.47& 0.54 & 1.15\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","\\label{closeness_wangchanberta_shapley_value}\n","\\end{longtable}\n","\\clearpage\n","\\subsection{Respect}\n","\\begin{longtable}[h]{\n","    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|c|c|c|c|c|c|\n","}\n","    \\hline\n","    Lexical Features & \n","    \\multicolumn{2}{|c|}{Setting 1} & \n","    \\multicolumn{2}{|c|}{Setting 2} & \n","    \\multicolumn{2}{|c|}{Setting 3} \\\\\n","    \\cline{2-7}\n","    & \n","    Per \\newline token & Total & \n","    Per \\newline token & Total & \n","    Per \\newline token & Total \\\\\n","    \\hline\n","    \\endhead\n","\n","    \\multicolumn{7}{l}{\\textit{Reference}} \\\\\n","    \\hline\n","        Average per token & 1.24 & 143.37& 1.95 & 72.22& 0.75 & 86.78\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Pronoun}} \\\\\n","    \\hline\n","        All pronoun & \\cellcolor{gray!25} 1.88 & \\cellcolor{gray!25} 6.75& \\cellcolor{gray!25} 2.93 & \\cellcolor{gray!25} 6.77& \\cellcolor{gray!25} 1.71 & \\cellcolor{gray!25} 6.27\\\\\n","        >> 1st person pronoun & \\cellcolor{gray!25} 1.74 & \\cellcolor{gray!25} 3.98& 1.90 & 2.98& \\cellcolor{gray!25} 1.62 & \\cellcolor{gray!25} 3.78\\\\\n","        >> 2nd person pronoun & \\cellcolor{gray!25} 2.17 & \\cellcolor{gray!25} 5.48& \\cellcolor{gray!25} 4.04 & \\cellcolor{gray!25} 7.51& \\cellcolor{gray!25} 1.80 & \\cellcolor{gray!25} 4.60\\\\\n","        >> 3rd person pronoun & \\cellcolor{gray!25} 1.88 & \\cellcolor{gray!25} 3.49& 1.95 & 3.48& 0.78 & 1.44\\\\\n","        >> Singular pronoun & \\cellcolor{gray!25} 1.88 & \\cellcolor{gray!25} 6.74& \\cellcolor{gray!25} 2.95 & \\cellcolor{gray!25} 6.78& \\cellcolor{gray!25} 1.72 & \\cellcolor{gray!25} 6.27\\\\\n","        >> Plural pronoun & 1.14 & 1.14& 1.09 & 1.34& 0.26 & 0.26\\\\\n","        >> Pronoun in non-standard spelling & \\cellcolor{gray!25} 1.81 & \\cellcolor{gray!25} 3.77& \\cellcolor{gray!25} 2.88 & \\cellcolor{gray!25} 4.15& \\cellcolor{gray!25} 1.73 & \\cellcolor{gray!25} 3.86\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Sentence-ending Particles}} \\\\\n","    \\hline\n","        All particles & 1.16 & 5.89& 1.87 & 3.60& 0.65 & 3.27\\\\\n","        >> Socially-related particles & 1.35 & 4.19& \\cellcolor{gray!25} 2.85 & \\cellcolor{gray!25} 4.12& 0.74 & 2.29\\\\\n","        >> Non-socially-related particles & 1.05 & 3.69& 1.23 & 2.11& 0.60 & 2.09\\\\\n","        >> Particle in non-standard spelling & \\cellcolor{gray!25} 1.54 & \\cellcolor{gray!25} 2.16& \\cellcolor{gray!25} 2.14 & \\cellcolor{gray!25} 2.52& \\cellcolor{gray!25} 0.98 & \\cellcolor{gray!25} 1.37\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Spelling Variation}} \\\\\n","    \\hline\n","        All spelling variation & \\cellcolor{gray!25} 1.39 & \\cellcolor{gray!25} 18.31& 1.71 & 7.84& 0.77 & 10.10\\\\\n","        >> Common misspelt words & \\cellcolor{gray!25} 1.37 & \\cellcolor{gray!25} 2.13& 1.74 & 2.40& \\cellcolor{gray!25} 0.88 & \\cellcolor{gray!25} 1.36\\\\\n","        >> Morphophonemic variation & \\cellcolor{gray!25} 1.52 & \\cellcolor{gray!25} 12.68& 1.90 & 5.62& \\cellcolor{gray!25} 0.86 & \\cellcolor{gray!25} 7.16\\\\\n","        >> Simplified variation & 1.21 & 7.84& 1.45 & 4.50& 0.65 & 4.19\\\\\n","        >> Repeated characters & 0.92 & 1.97& 0.72 & 0.95& \\cellcolor{gray!25} 0.88 & \\cellcolor{gray!25} 1.88\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","\\label{respect_wangchanberta_shapley_value}\n","\\end{longtable}\n","\n"]}]},{"cell_type":"code","source":["print(\"xl\", printed_texts[2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IMfqoWxAz0EO","executionInfo":{"status":"ok","timestamp":1714527682474,"user_tz":-60,"elapsed":17,"user":{"displayName":"Pakawat Nakwijit","userId":"14261168557301921642"}},"outputId":"9c2fe7d2-d91e-4690-c003-b988225e24b0"},"id":"IMfqoWxAz0EO","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["xl \\subsection{Closeness}\n","\\begin{longtable}[h]{\n","    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|c|c|c|c|c|c|\n","}\n","    \\hline\n","    Lexical Features & \n","    \\multicolumn{2}{|c|}{Setting 1} & \n","    \\multicolumn{2}{|c|}{Setting 2} & \n","    \\multicolumn{2}{|c|}{Setting 3} \\\\\n","    \\cline{2-7}\n","    & \n","    Per \\newline token & Total & \n","    Per \\newline token & Total & \n","    Per \\newline token & Total \\\\\n","    \\hline\n","    \\endhead\n","\n","    \\multicolumn{7}{l}{\\textit{Reference}} \\\\\n","    \\hline\n","        Average per token & 1.07 & 123.94& 1.80 & 65.14& 0.58 & 67.67\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Pronoun}} \\\\\n","    \\hline\n","        All pronoun & 0.80 & 3.64& 1.29 & 3.46& 0.25 & 1.13\\\\\n","        >> 1st person pronoun & 0.78 & 2.14& 1.21 & 2.20& 0.23 & 0.63\\\\\n","        >> 2nd person pronoun & 0.87 & 2.78& 1.23 & 2.67& 0.28 & 0.88\\\\\n","        >> 3rd person pronoun & 0.49 & 1.02& 1.02 & 1.92& 0.20 & 0.41\\\\\n","        >> Singular pronoun & 0.80 & 3.63& 1.27 & 3.37& 0.25 & 1.13\\\\\n","        >> Plural pronoun & 0.23 & 0.23& \\cellcolor{gray!25} 2.33 & \\cellcolor{gray!25} 3.00& 0.11 & 0.11\\\\\n","        >> Pronoun in non-standard spelling & 0.47 & 0.96& 1.33 & 2.01& 0.23 & 0.45\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Sentence-ending Particles}} \\\\\n","    \\hline\n","        All particles & \\cellcolor{gray!25} 2.98 & \\cellcolor{gray!25} 22.07& 1.86 & 4.27& \\cellcolor{gray!25} 3.39 & \\cellcolor{gray!25} 25.04\\\\\n","        >> Socially-related particles & \\cellcolor{gray!25} 7.11 & \\cellcolor{gray!25} 29.19& \\cellcolor{gray!25} 2.68 & \\cellcolor{gray!25} 4.40& \\cellcolor{gray!25} 8.35 & \\cellcolor{gray!25} 34.35\\\\\n","        >> Non-socially-related particles & 0.60 & 2.98& 1.29 & 2.29& 0.51 & 2.53\\\\\n","        >> Particle in non-standard spelling & 0.85 & 1.43& \\cellcolor{gray!25} 2.44 & \\cellcolor{gray!25} 2.81& \\cellcolor{gray!25} 0.92 & \\cellcolor{gray!25} 1.54\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Spelling Variation}} \\\\\n","    \\hline\n","        All spelling variation & \\cellcolor{gray!25} 1.27 & \\cellcolor{gray!25} 23.45& 1.65 & 9.98& 0.55 & 10.13\\\\\n","        >> Common misspelt words & 0.96 & 1.69& 1.50 & 2.19& 0.20 & 0.35\\\\\n","        >> Morphophonemic variation & \\cellcolor{gray!25} 1.70 & \\cellcolor{gray!25} 18.67& \\cellcolor{gray!25} 2.09 & \\cellcolor{gray!25} 7.44& \\cellcolor{gray!25} 0.79 & \\cellcolor{gray!25} 8.63\\\\\n","        >> Simplified variation & 0.68 & 6.22& 1.30 & 5.24& 0.24 & 2.21\\\\\n","        >> Repeated characters & 0.53 & 1.14& 1.50 & 1.97& 0.15 & 0.32\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","\\label{closeness_wangchanberta_shapley_value}\n","\\end{longtable}\n","\\clearpage\n","\\subsection{Respect}\n","\\begin{longtable}[h]{\n","    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|c|c|c|c|c|c|\n","}\n","    \\hline\n","    Lexical Features & \n","    \\multicolumn{2}{|c|}{Setting 1} & \n","    \\multicolumn{2}{|c|}{Setting 2} & \n","    \\multicolumn{2}{|c|}{Setting 3} \\\\\n","    \\cline{2-7}\n","    & \n","    Per \\newline token & Total & \n","    Per \\newline token & Total & \n","    Per \\newline token & Total \\\\\n","    \\hline\n","    \\endhead\n","\n","    \\multicolumn{7}{l}{\\textit{Reference}} \\\\\n","    \\hline\n","        Average per token & 0.22 & 25.50& 1.37 & 50.69& 0.30 & 34.33\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Pronoun}} \\\\\n","    \\hline\n","        All pronoun & 0.18 & 0.83& \\cellcolor{gray!25} 2.07 & \\cellcolor{gray!25} 6.11& 0.16 & 0.74\\\\\n","        >> 1st person pronoun & 0.15 & 0.43& \\cellcolor{gray!25} 1.68 & \\cellcolor{gray!25} 3.16& 0.16 & 0.46\\\\\n","        >> 2nd person pronoun & 0.20 & 0.64& \\cellcolor{gray!25} 2.72 & \\cellcolor{gray!25} 6.25& 0.17 & 0.56\\\\\n","        >> 3rd person pronoun & 0.16 & 0.33& 0.77 & 1.59& 0.14 & 0.30\\\\\n","        >> Singular pronoun & 0.18 & 0.83& \\cellcolor{gray!25} 2.10 & \\cellcolor{gray!25} 6.10& 0.16 & 0.74\\\\\n","        >> Plural pronoun & 0.15 & 0.15& 0.64 & 0.84& 0.08 & 0.08\\\\\n","        >> Pronoun in non-standard spelling & 0.17 & 0.34& 0.75 & 1.22& 0.12 & 0.26\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Sentence-ending Particles}} \\\\\n","    \\hline\n","        All particles & \\cellcolor{gray!25} 0.52 & \\cellcolor{gray!25} 3.86& 0.96 & 2.29& 0.21 & 1.53\\\\\n","        >> Socially-related particles & \\cellcolor{gray!25} 1.12 & \\cellcolor{gray!25} 4.61& 1.40 & 2.27& 0.24 & 1.00\\\\\n","        >> Non-socially-related particles & 0.17 & 0.86& 0.70 & 1.36& 0.19 & 0.92\\\\\n","        >> Particle in non-standard spelling & 0.19 & 0.31& 1.03 & 1.22& 0.20 & 0.34\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","    \\multicolumn{7}{l}{\\textit{Spelling Variation}} \\\\\n","    \\hline\n","        All spelling variation & 0.20 & 3.63& 0.91 & 5.80& 0.19 & 3.53\\\\\n","        >> Common misspelt words & 0.22 & 0.39& 1.01 & 1.45& 0.19 & 0.33\\\\\n","        >> Morphophonemic variation & 0.21 & 2.33& 1.04 & 3.91& 0.21 & 2.32\\\\\n","        >> Simplified variation & 0.19 & 1.75& 0.82 & 3.48& 0.18 & 1.64\\\\\n","        >> Repeated characters & 0.19 & 0.40& 0.28 & 0.37& 0.19 & 0.40\\\\\n","        & & & & & &\\\\\n","    \\hline\n","\n","\\label{respect_wangchanberta_shapley_value}\n","\\end{longtable}\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QpiRbmsfz2Zr"},"id":"QpiRbmsfz2Zr","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}