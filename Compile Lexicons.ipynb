{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78bf1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f66ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5522a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc033f24",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36e568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b39595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tags(lexicons, word, tags):\n",
    "    if word not in lexicons:\n",
    "        lexicons[word] = {\"tags\": set(), \"meta\": {}}\n",
    "        \n",
    "    lexicons[word][\"tags\"].update(tags)\n",
    "\n",
    "def add_meta(lexicons, word, meta):\n",
    "    if word not in lexicons:\n",
    "        lexicons[word] = {\"tags\": set(), \"meta\": {}}\n",
    "    \n",
    "    for k in meta:\n",
    "        lexicons[word][\"meta\"][k] = meta[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953f7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pronoun(lexicons):\n",
    "    df = pd.read_csv(\"./PrivateSpace/pronouns.csv\")\n",
    "    for idx, row in df.iterrows():\n",
    "        labels = [\"pronoun\"]\n",
    "        labels += [\"pronoun_\"+p for p in row[\"pronoun type\"].split(\"/\")]\n",
    "\n",
    "#         if not pd.isna(row[\"tags\"]):\n",
    "#             tags = row[\"tags\"].split(\",\")\n",
    "#             labels += tags\n",
    "\n",
    "        for w in row[\"word\"].split(\",\"):\n",
    "            w = w.strip()\n",
    "            add_tags(lexicons, w, labels)\n",
    "\n",
    "        if pd.isna(row[\"misspelt form\"]):\n",
    "            continue\n",
    "\n",
    "        labels.append(\"misspelling\")\n",
    "        labels.append(\"pronoun_misspelling\")\n",
    "        for w in row[\"misspelt form\"].split(\",\"):\n",
    "            w = w.strip()\n",
    "            add_tags(lexicons, w, labels)\n",
    "    return lexicons\n",
    "\n",
    "# lexicons = {}\n",
    "# add_pronoun(lexicons)\n",
    "# lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42262ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcea89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b12c157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_particles(lexicons):\n",
    "    df = pd.read_csv(\"./PrivateSpace/particles.csv\")\n",
    "    for idx, row in df.iterrows():\n",
    "        labels = [\"particles\"]\n",
    "\n",
    "        if not pd.isna(row[\"tags\"]):\n",
    "            labels.append(\"particles_\"+row[\"tags\"].strip())\n",
    "\n",
    "        for w in row[\"word\"].split(\",\"):\n",
    "            w = w.strip()\n",
    "            add_tags(lexicons, w, labels)\n",
    "\n",
    "        \n",
    "        if pd.isna(row[\"misspelt form\"]):\n",
    "            continue\n",
    "            \n",
    "        labels.append(\"particles_misspelling\")\n",
    "        labels.append(\"misspelling\")\n",
    "        for w in row[\"misspelt form\"].split(\",\"):\n",
    "            w = w.strip()\n",
    "            add_tags(lexicons, w, labels)\n",
    "    return lexicons\n",
    "\n",
    "# lexicons = {}\n",
    "# add_particles(lexicons)\n",
    "# lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9116c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0c6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_abbr(lexicons):\n",
    "    df = pd.read_csv(\"./PrivateSpace/thai-lm/abbr_lexiconthai.csv\")\n",
    "    for idx, row in df.iterrows():\n",
    "        w = row[\"อักษรย่อ\"]\n",
    "        add_tags(lexicons, w, [\"abbr\"])\n",
    "        add_meta(lexicons, w, {\n",
    "            \"full_word\": row[\"ชื่อเต็ม\"],\n",
    "            \"category\": row[\"แท็กหมวดหมู่\"].split(\"|\") \n",
    "        })\n",
    "\n",
    "    return lexicons\n",
    "\n",
    "# lexicons = {}\n",
    "# add_abbr(lexicons)\n",
    "# lexicons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37be3931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_swear(lexicons):\n",
    "    \n",
    "    df = pd.read_csv(\"./PrivateSpace/thai-lm/swear_lexiconthai.txt\", header=None)\n",
    "    for idx, row in df.iterrows():\n",
    "        add_tags(lexicons, row[0], [\"swear\"])\n",
    "    return lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d497b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transliterated(lexicons):\n",
    "    with open(\"./PrivateSpace/thai-lm/tubsub_ITdla.txt\", encoding=\"utf-8-sig\") as fin:\n",
    "        for line in fin:\n",
    "            w = line.strip()\n",
    "            if len(w)==0:\n",
    "                continue\n",
    "            add_tags(lexicons, w, [\"transliterated\"])   \n",
    "    \n",
    "    with open(\"./PrivateSpace/thai-lm/tubsub_englishonline.txt\", encoding=\"utf-8-sig\") as fin:\n",
    "        for line in fin:\n",
    "            sp = line.strip().split(\"=\")\n",
    "            if len(sp)!=2:\n",
    "                continue\n",
    "            \n",
    "            w = sp[1].strip()\n",
    "            add_tags(lexicons, w, [\"transliterated\"])\n",
    "            add_meta(lexicons, w, {\n",
    "                \"en\": sp[0].strip(),\n",
    "            })\n",
    "    \n",
    "    with open(\"./PrivateSpace/thai-lm/tubsub_khwamruphasathai.txt\", encoding=\"utf-8-sig\") as fin:\n",
    "        for line in fin:\n",
    "            words = line.strip().split(\" \")\n",
    "            for w in words:\n",
    "                w = w.strip()\n",
    "                add_tags(lexicons, w, [\"transliterated\"])\n",
    "    return lexicons\n",
    "\n",
    "lexicons = {}\n",
    "add_transliterated(lexicons);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe91e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a8f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fc7ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pythainlp import thai_consonants\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import time\n",
    "# from tqdm import tqdm\n",
    "# lexicons = []\n",
    "# for ch in tqdm(thai_consonants, total=len(thai_consonants)):\n",
    "#     resp = requests.get(\"https://www.wordyguru.com/a/คำไทยที่มักเขียนผิด/category/alphabet/\"+ch)\n",
    "#     soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    \n",
    "#     if resp.status_code!=200:\n",
    "#         print(\"ERROR\", ch)\n",
    "#         continue\n",
    "    \n",
    "    \n",
    "#     for div in soup.select(\"a.h3.item > div\"):#.find_all(\"a\", class_=\"h3 item\"):\n",
    "#         w = None\n",
    "#         c = None\n",
    "#         for ele in div.children:\n",
    "#             if ele.name==\"strong\":\n",
    "#                 c = ele.text.strip()\n",
    "#             elif ele.name is None and len(ele.text.strip())>0:\n",
    "#                 w = ele.text.strip()\n",
    "        \n",
    "#         if w is None or c is None:\n",
    "#             print(div)\n",
    "#             continue\n",
    "            \n",
    "#         lexicons.append({\n",
    "#             \"common_misp\": w,\n",
    "#             \"correct\": c\n",
    "#         })\n",
    "#     time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cbdb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d530c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(lexicons).to_csv(\"./PrivateSpace/wordyguru_common_misppelling.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84fb586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp = requests.get(\"https://slang.in.th/by-alphabet\")\n",
    "# soup = BeautifulSoup(resp.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19576a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_misspelling(lexicons):\n",
    "    with open(\"./PrivateSpace/thai-lm/vibut_selfadded.txt\", encoding=\"utf-8\") as fin:\n",
    "        for line in fin:\n",
    "            w = line.strip()\n",
    "            if len(w)==0:\n",
    "                continue\n",
    "            add_tags(lexicons, w, [\"misspelling\", \"misspelling_intention\", \"slang\"])   \n",
    "    \n",
    "    with open(\"./PrivateSpace/thai-lm/vibut_wiki_uncyclo.txt\", encoding=\"utf-8\") as fin:\n",
    "        for line in fin:\n",
    "            sp = line.strip().split(\"(\")\n",
    "            if len(sp)!=2:\n",
    "                print(sp)\n",
    "                continue\n",
    "            \n",
    "            corr = sp[1].replace(\")\", \"\").strip()\n",
    "            for w in sp[0].split(\",\"):\n",
    "                w = w.strip()\n",
    "                add_tags(lexicons, w, [\"misspelling\", \"misspelling_intention\", \"slang\"])\n",
    "                add_meta(lexicons, w, {\n",
    "                    \"correct\": corr,\n",
    "                })\n",
    "                \n",
    "    df = pd.read_csv(\"./PrivateSpace/thai-lm/wiki_frequent_wrong.csv\", sep ='\\t')\n",
    "    for idx, row in df.iterrows():\n",
    "        if pd.isna(row[\"มักเขียนผิดเป็น\"]):\n",
    "            continue\n",
    "            \n",
    "        words = row[\"มักเขียนผิดเป็น\"].split(\",\")\n",
    "        corr = row[\"คำที่เขียนถูก\"]\n",
    "        \n",
    "        for w in words:\n",
    "            w = w.strip()\n",
    "            add_tags(lexicons, w, [\"misspelling\", \"misspelling_common\"])\n",
    "            add_meta(lexicons, w, {\n",
    "                \"correct\": corr,\n",
    "            })\n",
    "    \n",
    "    df = pd.read_csv(\"./PrivateSpace/thai-lm/wiki_nongbot_replace.csv\", sep ='\\t', header=None)\n",
    "    for idx, row in df.iterrows():\n",
    "        words = row[0].split(\",\")\n",
    "        corr = row[1]\n",
    "        \n",
    "        for w in words:\n",
    "            w = w.strip()\n",
    "            add_tags(lexicons, w, [\"misspelling\", \"misspelling_common\"])\n",
    "            add_meta(lexicons, w, {\n",
    "                \"correct\": corr,\n",
    "            })\n",
    "\n",
    "    df = pd.read_csv(\"./PrivateSpace/wordyguru_common_misppelling.csv\")\n",
    "    for idx, row in df.iterrows():\n",
    "        words = row[\"common_misp\"].split(\",\")\n",
    "        corr = row[\"correct\"]\n",
    "        \n",
    "        for w in words:\n",
    "            w = w.strip()\n",
    "            add_tags(lexicons, w, [\"misspelling\", \"misspelling_common\"])\n",
    "            add_meta(lexicons, w, {\n",
    "                \"correct\": corr,\n",
    "            })\n",
    "    return lexicons\n",
    "\n",
    "# lexicons = {}\n",
    "# add_misspelling(lexicons);\n",
    "# lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2465251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519be067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff357771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f29548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pythainlp.util import countthai\n",
    "\n",
    "# lexicons = []\n",
    "# for div in soup.select(\".css-ewqnig a\"):\n",
    "#     s = div.text\n",
    "#     if \"คำที่พิมมั่วๆ\" in s:\n",
    "#         continue\n",
    "    \n",
    "#     if countthai(s) < 50:\n",
    "#         continue\n",
    "\n",
    "#     words = re.split('/|,', s)\n",
    "#     lexicons.extend([w.strip() for w in words])\n",
    "\n",
    "# pd.DataFrame(lexicons).to_csv(\"./PrivateSpace/slang_in_th.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb68160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_slang(lexicons):\n",
    "    df = pd.read_csv(\"./PrivateSpace/slang_in_th.csv\")\n",
    "    for idx, row in df.iterrows():\n",
    "        w = row[0].strip()\n",
    "        add_tags(lexicons, w, [\"slang\"])\n",
    "    return lexicons\n",
    "\n",
    "# lexicons = {}\n",
    "# add_slang(lexicons);\n",
    "# lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d0494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e094dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e7431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6206a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "473ff547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp = requests.get(\"http://www.thai-language.com/category\")\n",
    "# soup = BeautifulSoup(resp.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16cb8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category = []\n",
    "# for div in soup.select(\".cat-link\"):\n",
    "#     link = div.find(\"a\")\n",
    "    \n",
    "#     cat = link.text\n",
    "#     cid = link.attrs[\"href\"]\n",
    "\n",
    "#     parent_cat = None\n",
    "#     if div.parent.name !=\"input\":\n",
    "#         parent_cat = div.parent.attrs[\"id\"].replace(\"sk\", \"\")\n",
    "        \n",
    "#     category.append({\n",
    "#         \"category\": cat,\n",
    "#         \"cid\": cid,\n",
    "#         \"parent_cat\": parent_cat\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ad266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "060da48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_lexicons = []\n",
    "# for cat in tqdm(category, total=len(category)):\n",
    "#     visited = False\n",
    "#     for lex in all_lexicons:\n",
    "#         if lex[\"ref\"][\"cid\"]==cat[\"cid\"]:\n",
    "#             visited = True\n",
    "    \n",
    "#     if visited:\n",
    "#         continue\n",
    "\n",
    "#     resp = requests.get(\"http://www.thai-language.com\"+cat[\"cid\"])\n",
    "#     soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    \n",
    "#     if resp.status_code!=200:\n",
    "#         print(\"ERROR\", cat)\n",
    "#         continue\n",
    "        \n",
    "#     lexicons = {\n",
    "#         \"ref\": cat,\n",
    "#         \"category\": \"\",\n",
    "#         \"category_th\": \"\",\n",
    "#         \"words\": [],\n",
    "#         \"phrase\": []\n",
    "#     }\n",
    "\n",
    "#     for tableidx, table in enumerate(soup.select(\"#old-content > table\")):\n",
    "#         # Category Row\n",
    "#         if len(table.select(\".th2\")) !=0:\n",
    "#             cols = []\n",
    "#             for span in table.select(\"td span\"):\n",
    "#                 cols.append(span.text.strip())\n",
    "\n",
    "#             lexicons[\"category\"] = cols[1]\n",
    "#             lexicons[\"category_th\"] = cols[0]\n",
    "#             continue\n",
    "\n",
    "#         _tmp = list(table.children)\n",
    "#         for row in _tmp[0].children:\n",
    "\n",
    "#             # Word Row\n",
    "#             words_dom = row.findChildren(\"td\", {'class': 'th'}, recursive=False)\n",
    "#             if len(words_dom) !=0:\n",
    "#                 cols = []\n",
    "#                 for w_dom in row.select(\"td\"):\n",
    "#                     cols.append(w_dom.text.strip())\n",
    "\n",
    "#                 lexicons[\"words\"].append({\n",
    "#                     \"word\": cols[0],\n",
    "#                     \"meaning\": cols[2],\n",
    "#                     \"pronoun\": cols[1],\n",
    "#                 })\n",
    "#                 continue\n",
    "\n",
    "#             # Phrase\n",
    "#             words_dom = row.select(\"td > div.igt\")\n",
    "#             if len(words_dom) !=0:\n",
    "#                 cols = []\n",
    "#                 for w_dom in words_dom[0].children:\n",
    "#                     if len(w_dom.text.strip())==0:\n",
    "#                         continue\n",
    "\n",
    "#                     cols.append(w_dom.text)\n",
    "                \n",
    "#                 if len(cols)==2:\n",
    "#                     print(cols)\n",
    "#                     cols.append(\"\")\n",
    "#                 lexicons[\"phrase\"].append({\n",
    "#                     \"word\": cols[0],\n",
    "#                     \"meaning\": cols[2],\n",
    "#                     \"pronoun\": cols[1],\n",
    "#                 })\n",
    "\n",
    "#     all_lexicons.append(lexicons)\n",
    "# #     if len(all_lexicons)==2:\n",
    "# #         break\n",
    "#     time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eec44fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_lexicons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00591711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dump_jsonl, load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7e089aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump_jsonl(\"./PrivateSpace/word_category.jsonl\", all_lexicons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "294e4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.util import countthai\n",
    "\n",
    "def get_parents(df, category):\n",
    "    if category[\"ref\"][\"parent_cat\"] is None:\n",
    "        return []\n",
    "    \n",
    "    parents = []\n",
    "    for candidate in df:\n",
    "        if candidate[\"ref\"][\"cid\"]==\"/id/\"+category[\"ref\"][\"parent_cat\"]:\n",
    "            parents.append(candidate[\"ref\"][\"category\"])\n",
    "            parents += get_parents(df, candidate)\n",
    "    \n",
    "    return parents\n",
    "    \n",
    "def add_word_category(lexicons):\n",
    "    df = load_jsonl(\"./PrivateSpace/word_category.jsonl\")\n",
    "    for category in df:\n",
    "        parent_labels = get_parents(df, category)\n",
    "        label = [category[\"ref\"][\"category\"]] + parent_labels\n",
    "        \n",
    "        acc_label = []\n",
    "        acc = \"\"\n",
    "        for l in reversed(label):\n",
    "            if acc==\"\":\n",
    "                acc += l\n",
    "            else:\n",
    "                acc += \" >> \"+l\n",
    "            acc_label.append(acc)\n",
    "            \n",
    "#         print(acc_label)\n",
    "        for w in category[\"words\"]:\n",
    "            if countthai(w[\"word\"]) < 50:\n",
    "                continue\n",
    "\n",
    "            add_tags(lexicons, w[\"word\"].strip(), [\"cat:\"+l for l in acc_label])\n",
    "    return lexicons\n",
    "\n",
    "# lexicons = {}\n",
    "# add_word_category(lexicons);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ecf72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b09aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850d150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4af3321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.util import countthai\n",
    "\n",
    "def load_txt(in_path):\n",
    "    words = []\n",
    "    with open(in_path, encoding=\"utf-8-sig\") as fin:\n",
    "        for line in fin:\n",
    "            words.append(line.strip())\n",
    "    return words\n",
    "\n",
    "def add_sentiment(lexicons):\n",
    "    words_adj = load_txt(\"./PrivateSpace/lexicon-thai/sentiment/negative_adjectives.txt\")\n",
    "    words_new = load_txt(\"./PrivateSpace/lexicon-thai/sentiment/negative_new.txt\")\n",
    "    words_vrb = load_txt(\"./PrivateSpace/lexicon-thai/sentiment/negative_verbs.txt\")\n",
    "    \n",
    "    words = words_adj+words_new+words_vrb\n",
    "    for w in words:\n",
    "        add_tags(lexicons, w, [\"sentiment\", \"sentiment_negative\"])\n",
    "\n",
    "    words_adj = load_txt(\"./PrivateSpace/lexicon-thai/sentiment/positive__adjectives.txt\")\n",
    "    words_new = load_txt(\"./PrivateSpace/lexicon-thai/sentiment/positive_new.txt\")\n",
    "    words_vrb = load_txt(\"./PrivateSpace/lexicon-thai/sentiment/positive__verbs.txt\")\n",
    "    \n",
    "    words = words_adj+words_new+words_vrb\n",
    "    for w in words:\n",
    "        add_tags(lexicons, w, [\"sentiment\", \"sentiment_positive\"])\n",
    "    \n",
    "    return lexicons\n",
    "\n",
    "lexicons = {}\n",
    "add_sentiment(lexicons);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080dd368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e92abf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a23cac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./PrivateSpace/th-misspelling-correction/MisspellingIntention/annotated/all.jsonl\n"
     ]
    }
   ],
   "source": [
    "ls ./PrivateSpace/th-misspelling-correction/MisspellingIntention/annotated/all.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eafdbce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19402 records from ./PrivateSpace/th-misspelling-correction/MisspellingIntention/annotated/all.jsonl\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def rm_reptitive(text):\n",
    "    s = \"\"\n",
    "    groups = groupby(text)\n",
    "    for label, group in groups:\n",
    "        g = list(group)\n",
    "        if len(g) >= 3:\n",
    "            s += f\"{label*3}REP\"\n",
    "        else:\n",
    "            s += \"\".join(g)\n",
    "    return s\n",
    "\n",
    "# print(rm_reptitive(\"HELLOO OOOO\"))\n",
    "def add_mispelling_intention(lexicons):\n",
    "    data = load_jsonl(\"./PrivateSpace/th-misspelling-correction/MisspellingIntention/annotated/all.jsonl\")\n",
    "    for row in data:\n",
    "        w = rm_reptitive(row[\"misp\"])\n",
    "        corr = row[\"corr\"]\n",
    "        \n",
    "        if len(w)<3:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        if row[\"label\"]==\"unintentional\":\n",
    "            continue\n",
    "            add_tags(lexicons, w, [\"misspelling\"])\n",
    "            add_meta(lexicons, w, {\"correct\": corr})\n",
    "        elif row[\"label\"]==\"with_semantics\":\n",
    "            add_tags(lexicons, w, [\"misspelling\", \"misspelling_intention\"])\n",
    "            add_meta(lexicons, w, {\"correct\": corr})\n",
    "        elif row[\"label\"]==\"abbr\":\n",
    "            add_tags(lexicons, w, [\"misspelling\", \"misspelling_shorten\"])\n",
    "            add_meta(lexicons, w, {\"correct\": corr})\n",
    "        elif row[\"label\"]==\"transliteration\":\n",
    "            continue\n",
    "        elif row[\"label\"]==\"not_sure\":\n",
    "            continue\n",
    "        else:\n",
    "            print(row[\"label\"])\n",
    "            break\n",
    "    return lexicons\n",
    "\n",
    "lexicons = {}\n",
    "add_mispelling_intention(lexicons);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9564f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504124c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5d9c91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 508 records from ./PrivateSpace/word_category.jsonl\n",
      "Loaded 19402 records from ./PrivateSpace/th-misspelling-correction/MisspellingIntention/annotated/all.jsonl\n"
     ]
    }
   ],
   "source": [
    "lexicons = {}\n",
    "add_sentiment(lexicons)\n",
    "add_word_category(lexicons)\n",
    "add_slang(lexicons)\n",
    "add_misspelling(lexicons)\n",
    "add_transliterated(lexicons)\n",
    "add_abbr(lexicons)\n",
    "add_pronoun(lexicons)\n",
    "add_particles(lexicons)\n",
    "add_swear(lexicons);\n",
    "add_mispelling_intention(lexicons);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "776571d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25573"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicons.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7952ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in lexicons:\n",
    "    lexicons[k][\"tags\"] = list(lexicons[k][\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "54f93442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 25573 records to lexicons.jsonl\n"
     ]
    }
   ],
   "source": [
    "dump_jsonl(\"lexicons.jsonl\", [(k, v) for k, v in lexicons.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a477c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4c140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
