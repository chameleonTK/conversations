{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1877f9b4",
   "metadata": {},
   "source": [
    "## Load Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93deeee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "from utils import load_jsonl, dump_jsonl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87c53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f99623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task1_conver(in_dir, col_label, skips=[]):\n",
    "    conversations = load_jsonl(f\"{in_dir}\")\n",
    "    \n",
    "    \n",
    "    def to_message_str(messages, users):\n",
    "        s = []\n",
    "        u = []\n",
    "        for m in messages:\n",
    "            if users[m['user_id']] == \"SYS\":\n",
    "                s.append(m['text'])\n",
    "            else:\n",
    "                u.append(m['text'])\n",
    "                \n",
    "        return s, u\n",
    "        \n",
    "    newdata = []\n",
    "    for row in conversations:\n",
    "        row[\"messages\"].sort(key=lambda x: x[\"date_created\"], reverse=False)\n",
    "        \n",
    "        users = {}\n",
    "        for m in row[\"messages\"]:\n",
    "            if m[\"user_id\"] not in users:\n",
    "#                 username = \"USR\"+str(len(users)+1) if len(users.keys())==0 else \"SYS\"\n",
    "                username = \"USR\" if len(users.keys())==0 else \"SYS\"\n",
    "                users[m[\"user_id\"]] = username\n",
    "                \n",
    "#         if len(users)>2:\n",
    "#             print(\"More than 1 users\", len(users))\n",
    "        \n",
    "        \n",
    "        messages = row[\"messages\"]\n",
    "        chunk_size = 100\n",
    "        for i in range(0, len(messages), chunk_size):\n",
    "            sub_messages = messages[i:i+chunk_size]\n",
    "            s, u = to_message_str(sub_messages, users)\n",
    "            \n",
    "            if pd.isna(row[col_label]):\n",
    "                continue\n",
    "            \n",
    "            if row[col_label] in skips:\n",
    "                continue\n",
    "                \n",
    "            label = row[col_label]\n",
    "                \n",
    "            newdata.append({\n",
    "                \"user\": u,\n",
    "                \"sys\": s,\n",
    "                \"label\": label,\n",
    "                \"nturn\": len(sub_messages)\n",
    "            })\n",
    "        \n",
    "#     n_val = int(len(newdata)*0.05)\n",
    "#     n_test = n_val\n",
    "    \n",
    "#     test = newdata[0:n_test]\n",
    "#     val = newdata[n_test:n_test+n_val]\n",
    "#     train = newdata[n_test+n_val:]\n",
    "    \n",
    "    return pd.DataFrame(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92feb049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1234 records from ./Task1/annotated_conersations.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[‡∏î‡∏µ‡πÜ‡∏ß‡∏≤‡∏¢, ‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏µ‡πâ, ‡∏£‡∏ß‡∏¢‡πÜ ‡πÄ‡∏Æ‡∏á‡πÜ , ‡πÄ‡∏´‡∏°...</td>\n",
       "      <td>[‡∏ß‡πà‡∏≤‡πÑ‡∏á‡∏õ‡∏£‡∏≤‡∏á, ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á ‡∏ô‡∏≠‡∏ô‡∏ï‡∏∑‡πà‡∏ô ‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á ‡∏ä...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå‡∏Å‡∏±‡∏ô, ‡∏õ‡∏Å‡∏Ö‡∏¥‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ...</td>\n",
       "      <td>[‡πÇ‡∏≠‡πÄ‡∏Ñ‡∏Ñ‡πà‡∏∞, ‡∏ó‡∏µ‡πà‡∏ö‡πâ‡∏≤‡∏ô‡∏Ñ‡πà‡∏∞, ‡∏î‡∏π‡πÅ‡∏ó‡∏ö‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡πÄ‡∏•‡∏¢, ‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[‡πÄ‡∏ò‡∏≠, ‡∏™‡∏£‡∏∏‡∏õ ‡∏≠‡πâ‡∏ß‡∏ô‡∏à‡∏∞‡∏ã‡∏∑‡πâ‡∏≠‡∏£‡∏ñ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà, ‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡πâ‡∏ß‡∏ô‡∏î‡∏π‡∏£‡∏ñ...</td>\n",
       "      <td>[‡∏≠‡∏∞‡πÑ‡∏£‡∏´‡∏°‡∏π, ‡∏Å‡∏•‡∏≤‡∏á‡∏õ‡∏µ, ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏≠‡∏≤  ativ ‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏°‡πà, ‡∏ß‡πà‡∏≤‡∏à...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[‡∏°‡∏∂‡∏á, ‡πÅ‡∏°‡∏ß‡∏°‡∏∂‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏á‡∏Å‡∏±‡∏ô‡∏ö‡πâ‡∏≤‡∏á‡∏≠‡πà‡∏∞, ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Å‡∏µ‡πà‡∏ï‡∏±‡∏ß‡∏ô‡∏∞...</td>\n",
       "      <td>[‡∏ß‡πà‡∏≤, ‡πÄ‡∏î‡πá‡∏Å‡πÜ‡∏´‡∏£‡∏≠, ‡∏ã‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥‡πÄ‡∏•‡∏¢‡∏°‡∏∂‡∏á, 5‡∏ï‡∏±‡∏ß, ‡πÅ‡∏Ñ‡πà‡∏ö‡πâ‡∏≤‡∏ô‡∏Å‡∏π‡∏ô...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[‡∏≠‡πâ‡∏ß‡∏ô, ‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡πÅ‡∏°‡∏ß, ‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á, ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡∏ï‡∏≠‡∏ô‡∏ï‡∏±‡∏ß‡πÑ‡∏°‡πà...</td>\n",
       "      <td>[‡πÑ‡∏£‡∏´‡∏°‡∏π, ‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡∏ó‡∏≥‡πÑ‡∏°‡πÅ‡∏°‡∏ß, ‡∏à‡∏∞‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏´‡∏ô, ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [‡∏î‡∏µ‡πÜ‡∏ß‡∏≤‡∏¢, ‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏µ‡πâ, ‡∏£‡∏ß‡∏¢‡πÜ ‡πÄ‡∏Æ‡∏á‡πÜ , ‡πÄ‡∏´‡∏°...   \n",
       "1  [‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå‡∏Å‡∏±‡∏ô, ‡∏õ‡∏Å‡∏Ö‡∏¥‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ...   \n",
       "2  [‡πÄ‡∏ò‡∏≠, ‡∏™‡∏£‡∏∏‡∏õ ‡∏≠‡πâ‡∏ß‡∏ô‡∏à‡∏∞‡∏ã‡∏∑‡πâ‡∏≠‡∏£‡∏ñ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà, ‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡πâ‡∏ß‡∏ô‡∏î‡∏π‡∏£‡∏ñ...   \n",
       "3  [‡∏°‡∏∂‡∏á, ‡πÅ‡∏°‡∏ß‡∏°‡∏∂‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏á‡∏Å‡∏±‡∏ô‡∏ö‡πâ‡∏≤‡∏á‡∏≠‡πà‡∏∞, ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Å‡∏µ‡πà‡∏ï‡∏±‡∏ß‡∏ô‡∏∞...   \n",
       "4  [‡∏≠‡πâ‡∏ß‡∏ô, ‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡πÅ‡∏°‡∏ß, ‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á, ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡∏ï‡∏≠‡∏ô‡∏ï‡∏±‡∏ß‡πÑ‡∏°‡πà...   \n",
       "\n",
       "                                                 sys     label  nturn  \n",
       "0  [‡∏ß‡πà‡∏≤‡πÑ‡∏á‡∏õ‡∏£‡∏≤‡∏á, ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á ‡∏ô‡∏≠‡∏ô‡∏ï‡∏∑‡πà‡∏ô ‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á ‡∏ä...  1. Close     35  \n",
       "1  [‡πÇ‡∏≠‡πÄ‡∏Ñ‡∏Ñ‡πà‡∏∞, ‡∏ó‡∏µ‡πà‡∏ö‡πâ‡∏≤‡∏ô‡∏Ñ‡πà‡∏∞, ‡∏î‡∏π‡πÅ‡∏ó‡∏ö‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡πÄ‡∏•‡∏¢, ‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å...  1. Close     39  \n",
       "2  [‡∏≠‡∏∞‡πÑ‡∏£‡∏´‡∏°‡∏π, ‡∏Å‡∏•‡∏≤‡∏á‡∏õ‡∏µ, ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏≠‡∏≤  ativ ‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏°‡πà, ‡∏ß‡πà‡∏≤‡∏à...  1. Close     40  \n",
       "3  [‡∏ß‡πà‡∏≤, ‡πÄ‡∏î‡πá‡∏Å‡πÜ‡∏´‡∏£‡∏≠, ‡∏ã‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥‡πÄ‡∏•‡∏¢‡∏°‡∏∂‡∏á, 5‡∏ï‡∏±‡∏ß, ‡πÅ‡∏Ñ‡πà‡∏ö‡πâ‡∏≤‡∏ô‡∏Å‡∏π‡∏ô...  1. Close     35  \n",
       "4  [‡πÑ‡∏£‡∏´‡∏°‡∏π, ‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡∏ó‡∏≥‡πÑ‡∏°‡πÅ‡∏°‡∏ß, ‡∏à‡∏∞‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏´‡∏ô, ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ...  1. Close     39  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task1_conver(\"./Task1/annotated_conersations.jsonl\", \"closeness\", skips = [])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e31cf-71f1-4fdb-b865-2f8b37eca3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554617d6-e691-4d93-acd3-bd65c7e93cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Close</th>\n",
       "      <td>551</td>\n",
       "      <td>551</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Know each other</th>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Don't know each other</th>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. Don't like each other</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user  sys  nturn\n",
       "label                                     \n",
       "1. Close                   551  551    551\n",
       "2. Know each other         230  230    230\n",
       "3. Don't know each other   435  435    435\n",
       "4. Don't like each other     5    5      5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b648fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc25201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task2_conver(in_dir, col_label, skips=[]):\n",
    "    conversations = load_jsonl(f\"{in_dir}\")\n",
    "        \n",
    "    newdata = []\n",
    "    for row in conversations:\n",
    "        row[\"messages\"].sort(key=lambda x: x[\"created_at\"], reverse=False)\n",
    "        \n",
    "        users = {}\n",
    "        for m in row[\"messages\"]:\n",
    "            if m[\"user_id\"] not in users:\n",
    "#                 username = \"USR\"+str(len(users)+1) if len(users.keys())==0 else \"SYS\"\n",
    "                username = \"USR\" if len(users.keys())!=0 else \"SYS\"\n",
    "                users[m[\"user_id\"]] = username\n",
    "                \n",
    "        if len(users)>2:\n",
    "            print(\"More than 1 users\", len(users))\n",
    "        \n",
    "        \n",
    "        \n",
    "        messages = row[\"messages\"]\n",
    "        s = []\n",
    "        u = []\n",
    "        for m in messages:\n",
    "            text = m['text'].replace(\"[USR]\", \"\").replace(\"[URL]\", \"URL\")\n",
    "            if users[m['user_id']] == \"SYS\":\n",
    "                s.append(text)\n",
    "            else:\n",
    "                u.append(text)\n",
    "        \n",
    "        label = row[col_label]\n",
    "            \n",
    "        if pd.isna(label):\n",
    "            continue\n",
    "        \n",
    "        if label in skips:\n",
    "            continue\n",
    "                \n",
    "        newdata.append({\n",
    "            \"user\": u,\n",
    "            \"sys\": s,\n",
    "            \"label\": label,\n",
    "            \"nturn\": len(messages)\n",
    "        })\n",
    "                \n",
    "            \n",
    "    n_val = int(len(newdata)*0.1)\n",
    "    n_test = n_val\n",
    "    \n",
    "    test = newdata[0:n_test]\n",
    "    val = newdata[n_test:n_test+n_val]\n",
    "    train = newdata[n_test+n_val:]\n",
    "    \n",
    "    return pd.DataFrame(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b980cc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2463 records from ./Task2/annotated/annotated.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ ‡πÅ‡∏ï‡∏á‡πÇ‡∏° ‡∏ä‡∏ß‡∏ô‡πÅ‡∏ü‡∏ô‡πÑ‡∏õ‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Å‡∏£‡∏∞‡∏ï‡∏¥‡∏Å‡∏ä‡∏ß‡∏ô‡πÑ‡∏õ ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏´‡∏≤...</td>\n",
       "      <td>[‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô\\n‡∏á‡∏≤‡∏ô‡∏Ñ‡∏∑‡∏ô‡∏ô‡∏±‡πâ‡∏ô #‡∏Å‡∏£‡∏∞‡∏ï‡∏¥‡∏Å ‡∏ä‡∏ß‡∏ô‡πÅ‡∏ü‡∏ô‡∏û‡∏µ‡πà‡∏ï‡∏°.‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏ô...</td>\n",
       "      <td>3. Not respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[   ‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡πâ‡∏≤ ‡∏¢‡∏±‡∏¢‡∏ô‡πâ‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å‡∏Ç‡∏≠‡∏á‡∏û‡∏µ‡πà‡∏°‡∏¥‡∏ß‚òÄÔ∏èüåª\\n \\n#...</td>\n",
       "      <td>[‡πÄ‡∏ô‡∏∑‡πà‡∏¥‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ...‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏Ñ‡∏£‡∏ö‡∏£‡∏≠‡∏ö 3 ‡∏õ‡∏µ\\n‡∏°‡∏≤‡πÄ‡∏•‡πà‡∏ô...</td>\n",
       "      <td>1. Respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ ‡πÅ‡∏≠‡∏ö‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡πâ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏≠‡∏µ‡∏Å‡∏£‡∏≠‡∏ö]</td>\n",
       "      <td>[‡πÄ‡∏ò‡∏£‡∏î‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏°‡∏≤‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°‡∏õ‡∏µ54 ‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á‡∏°‡∏±‡∏ô‡∏≠‡∏≤‡∏à...</td>\n",
       "      <td>2. Normal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ ‡πÄ‡∏ô‡∏µ‡πà‡∏¢‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏π‡∏û‡∏π‡∏î URL]</td>\n",
       "      <td>[‡∏°‡∏≤‡∏î‡∏¥‡πâ‡∏ô‡∏Ñ‡∏ß‡∏¢‡πÑ‡∏£‡∏ä‡∏≠‡∏á‡∏°‡∏∂‡∏á\\n‡∏°‡∏∂‡∏á‡∏≠‡πà‡∏∞‡πÇ‡∏ä‡∏ß‡πå‡πÇ‡∏á‡πà‡πÑ‡∏≠‡πâ‡∏™‡∏±‡∏ï‡∏ß‡πå ‡πÄ‡∏™‡∏£‡πà...</td>\n",
       "      <td>3. Not respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ ‡∏™‡∏£‡∏∏‡∏õ‡∏õ‡∏ß‡∏¥‡∏ô‡∏ô‡∏µ‡πà‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏Ñ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏±‡πâ‡∏¢?,  ‡∏™‡∏£‡∏∏‡∏õ ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡πÇ‡∏°‡πÇ...</td>\n",
       "      <td>[‡πÅ‡∏ï‡πà‡∏õ‡∏ß‡∏¥‡∏ô‡∏Å‡∏±‡∏ö‡πÑ‡∏û‡∏£‡∏ß‡∏±‡∏•‡∏¢‡πå‡∏Å‡πá‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ô‡∏∞‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏à‡πâ‡πÄ‡∏Å‡∏•‡∏µ‡∏¢...</td>\n",
       "      <td>2. Normal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [ ‡πÅ‡∏ï‡∏á‡πÇ‡∏° ‡∏ä‡∏ß‡∏ô‡πÅ‡∏ü‡∏ô‡πÑ‡∏õ‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Å‡∏£‡∏∞‡∏ï‡∏¥‡∏Å‡∏ä‡∏ß‡∏ô‡πÑ‡∏õ ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏´‡∏≤...   \n",
       "1  [   ‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡πâ‡∏≤ ‡∏¢‡∏±‡∏¢‡∏ô‡πâ‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å‡∏Ç‡∏≠‡∏á‡∏û‡∏µ‡πà‡∏°‡∏¥‡∏ß‚òÄÔ∏èüåª\\n \\n#...   \n",
       "2              [ ‡πÅ‡∏≠‡∏ö‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡πâ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏≠‡∏µ‡∏Å‡∏£‡∏≠‡∏ö]   \n",
       "3                           [ ‡πÄ‡∏ô‡∏µ‡πà‡∏¢‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏π‡∏û‡∏π‡∏î URL]   \n",
       "4  [ ‡∏™‡∏£‡∏∏‡∏õ‡∏õ‡∏ß‡∏¥‡∏ô‡∏ô‡∏µ‡πà‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏Ñ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏±‡πâ‡∏¢?,  ‡∏™‡∏£‡∏∏‡∏õ ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡πÇ‡∏°‡πÇ...   \n",
       "\n",
       "                                                 sys           label  nturn  \n",
       "0  [‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô\\n‡∏á‡∏≤‡∏ô‡∏Ñ‡∏∑‡∏ô‡∏ô‡∏±‡πâ‡∏ô #‡∏Å‡∏£‡∏∞‡∏ï‡∏¥‡∏Å ‡∏ä‡∏ß‡∏ô‡πÅ‡∏ü‡∏ô‡∏û‡∏µ‡πà‡∏ï‡∏°.‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏ô...  3. Not respect      3  \n",
       "1  [‡πÄ‡∏ô‡∏∑‡πà‡∏¥‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ...‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏Ñ‡∏£‡∏ö‡∏£‡∏≠‡∏ö 3 ‡∏õ‡∏µ\\n‡∏°‡∏≤‡πÄ‡∏•‡πà‡∏ô...      1. Respect      3  \n",
       "2  [‡πÄ‡∏ò‡∏£‡∏î‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏°‡∏≤‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°‡∏õ‡∏µ54 ‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á‡∏°‡∏±‡∏ô‡∏≠‡∏≤‡∏à...       2. Normal      3  \n",
       "3  [‡∏°‡∏≤‡∏î‡∏¥‡πâ‡∏ô‡∏Ñ‡∏ß‡∏¢‡πÑ‡∏£‡∏ä‡∏≠‡∏á‡∏°‡∏∂‡∏á\\n‡∏°‡∏∂‡∏á‡∏≠‡πà‡∏∞‡πÇ‡∏ä‡∏ß‡πå‡πÇ‡∏á‡πà‡πÑ‡∏≠‡πâ‡∏™‡∏±‡∏ï‡∏ß‡πå ‡πÄ‡∏™‡∏£‡πà...  3. Not respect      3  \n",
       "4  [‡πÅ‡∏ï‡πà‡∏õ‡∏ß‡∏¥‡∏ô‡∏Å‡∏±‡∏ö‡πÑ‡∏û‡∏£‡∏ß‡∏±‡∏•‡∏¢‡πå‡∏Å‡πá‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ô‡∏∞‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏à‡πâ‡πÄ‡∏Å‡∏•‡∏µ‡∏¢...       2. Normal      5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task2_conver(\"./Task2/annotated/annotated.jsonl\", \"authority\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc1405-7676-4a1d-b2a7-894083116d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27de11af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Respect</th>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Normal</th>\n",
       "      <td>1403</td>\n",
       "      <td>1403</td>\n",
       "      <td>1403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Not respect</th>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user   sys  nturn\n",
       "label                            \n",
       "1. Respect       303   303    303\n",
       "2. Normal       1403  1403   1403\n",
       "3. Not respect   346   346    346"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27dfc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a566de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1221 records from ./Task3/annotated/annotated.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[‡∏î‡∏µ‡πÜ‡∏ß‡∏≤‡∏¢, ‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏µ‡πâ, ‡∏£‡∏ß‡∏¢‡πÜ ‡πÄ‡∏Æ‡∏á‡πÜ , ‡πÄ‡∏´‡∏°...</td>\n",
       "      <td>[‡∏ß‡πà‡∏≤‡πÑ‡∏á‡∏õ‡∏£‡∏≤‡∏á, ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á ‡∏ô‡∏≠‡∏ô‡∏ï‡∏∑‡πà‡∏ô ‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á ‡∏ä...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå‡∏Å‡∏±‡∏ô, ‡∏õ‡∏Å‡∏Ö‡∏¥‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ...</td>\n",
       "      <td>[‡πÇ‡∏≠‡πÄ‡∏Ñ‡∏Ñ‡πà‡∏∞, ‡∏ó‡∏µ‡πà‡∏ö‡πâ‡∏≤‡∏ô‡∏Ñ‡πà‡∏∞, ‡∏î‡∏π‡πÅ‡∏ó‡∏ö‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡πÄ‡∏•‡∏¢, ‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å...</td>\n",
       "      <td>2. Know each other</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[‡πÄ‡∏ò‡∏≠, ‡∏™‡∏£‡∏∏‡∏õ ‡∏≠‡πâ‡∏ß‡∏ô‡∏à‡∏∞‡∏ã‡∏∑‡πâ‡∏≠‡∏£‡∏ñ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà, ‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡πâ‡∏ß‡∏ô‡∏î‡∏π‡∏£‡∏ñ...</td>\n",
       "      <td>[‡∏≠‡∏∞‡πÑ‡∏£‡∏´‡∏°‡∏π, ‡∏Å‡∏•‡∏≤‡∏á‡∏õ‡∏µ, ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏≠‡∏≤  ativ ‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏°‡πà, ‡∏ß‡πà‡∏≤‡∏à...</td>\n",
       "      <td>2. Know each other</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[‡∏°‡∏∂‡∏á, ‡πÅ‡∏°‡∏ß‡∏°‡∏∂‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏á‡∏Å‡∏±‡∏ô‡∏ö‡πâ‡∏≤‡∏á‡∏≠‡πà‡∏∞, ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Å‡∏µ‡πà‡∏ï‡∏±‡∏ß‡∏ô‡∏∞...</td>\n",
       "      <td>[‡∏ß‡πà‡∏≤, ‡πÄ‡∏î‡πá‡∏Å‡πÜ‡∏´‡∏£‡∏≠, ‡∏ã‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥‡πÄ‡∏•‡∏¢‡∏°‡∏∂‡∏á, 5‡∏ï‡∏±‡∏ß, ‡πÅ‡∏Ñ‡πà‡∏ö‡πâ‡∏≤‡∏ô‡∏Å‡∏π‡∏ô...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[‡∏≠‡πâ‡∏ß‡∏ô, ‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡πÅ‡∏°‡∏ß, ‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á, ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡∏ï‡∏≠‡∏ô‡∏ï‡∏±‡∏ß‡πÑ‡∏°‡πà...</td>\n",
       "      <td>[‡πÑ‡∏£‡∏´‡∏°‡∏π, ‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡∏ó‡∏≥‡πÑ‡∏°‡πÅ‡∏°‡∏ß, ‡∏à‡∏∞‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏´‡∏ô, ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [‡∏î‡∏µ‡πÜ‡∏ß‡∏≤‡∏¢, ‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏µ‡πâ, ‡∏£‡∏ß‡∏¢‡πÜ ‡πÄ‡∏Æ‡∏á‡πÜ , ‡πÄ‡∏´‡∏°...   \n",
       "1  [‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå‡∏Å‡∏±‡∏ô, ‡∏õ‡∏Å‡∏Ö‡∏¥‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ...   \n",
       "2  [‡πÄ‡∏ò‡∏≠, ‡∏™‡∏£‡∏∏‡∏õ ‡∏≠‡πâ‡∏ß‡∏ô‡∏à‡∏∞‡∏ã‡∏∑‡πâ‡∏≠‡∏£‡∏ñ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà, ‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡πâ‡∏ß‡∏ô‡∏î‡∏π‡∏£‡∏ñ...   \n",
       "3  [‡∏°‡∏∂‡∏á, ‡πÅ‡∏°‡∏ß‡∏°‡∏∂‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏á‡∏Å‡∏±‡∏ô‡∏ö‡πâ‡∏≤‡∏á‡∏≠‡πà‡∏∞, ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Å‡∏µ‡πà‡∏ï‡∏±‡∏ß‡∏ô‡∏∞...   \n",
       "4  [‡∏≠‡πâ‡∏ß‡∏ô, ‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡πÅ‡∏°‡∏ß, ‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á, ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡∏ï‡∏≠‡∏ô‡∏ï‡∏±‡∏ß‡πÑ‡∏°‡πà...   \n",
       "\n",
       "                                                 sys               label  \\\n",
       "0  [‡∏ß‡πà‡∏≤‡πÑ‡∏á‡∏õ‡∏£‡∏≤‡∏á, ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á ‡∏ô‡∏≠‡∏ô‡∏ï‡∏∑‡πà‡∏ô ‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á ‡∏ä...            1. Close   \n",
       "1  [‡πÇ‡∏≠‡πÄ‡∏Ñ‡∏Ñ‡πà‡∏∞, ‡∏ó‡∏µ‡πà‡∏ö‡πâ‡∏≤‡∏ô‡∏Ñ‡πà‡∏∞, ‡∏î‡∏π‡πÅ‡∏ó‡∏ö‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡πÄ‡∏•‡∏¢, ‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å...  2. Know each other   \n",
       "2  [‡∏≠‡∏∞‡πÑ‡∏£‡∏´‡∏°‡∏π, ‡∏Å‡∏•‡∏≤‡∏á‡∏õ‡∏µ, ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏≠‡∏≤  ativ ‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏°‡πà, ‡∏ß‡πà‡∏≤‡∏à...  2. Know each other   \n",
       "3  [‡∏ß‡πà‡∏≤, ‡πÄ‡∏î‡πá‡∏Å‡πÜ‡∏´‡∏£‡∏≠, ‡∏ã‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥‡πÄ‡∏•‡∏¢‡∏°‡∏∂‡∏á, 5‡∏ï‡∏±‡∏ß, ‡πÅ‡∏Ñ‡πà‡∏ö‡πâ‡∏≤‡∏ô‡∏Å‡∏π‡∏ô...            1. Close   \n",
       "4  [‡πÑ‡∏£‡∏´‡∏°‡∏π, ‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡∏ó‡∏≥‡πÑ‡∏°‡πÅ‡∏°‡∏ß, ‡∏à‡∏∞‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏´‡∏ô, ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ...            1. Close   \n",
       "\n",
       "   nturn  \n",
       "0     35  \n",
       "1     39  \n",
       "2     40  \n",
       "3     35  \n",
       "4     39  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task1_conver(\"./Task3/annotated/annotated.jsonl\", \"closeness\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282e5a5b-4206-46bd-ae7f-604b8c24574a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Close</th>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Know each other</th>\n",
       "      <td>696</td>\n",
       "      <td>696</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Don't know each other</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. Don't like each other</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user  sys  nturn\n",
       "label                                     \n",
       "1. Close                   462  462    462\n",
       "2. Know each other         696  696    696\n",
       "3. Don't know each other    52   52     52\n",
       "4. Don't like each other    11   11     11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a42643-11c4-427c-b3c5-662a21a5af31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d21d30-3555-4593-919c-6f7581ac0a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8d78a46",
   "metadata": {},
   "source": [
    "## Load Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caafaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "755a8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./PrivateSpace/thai-dictionary/RoyalInstituteDictionary/words.json\", encoding=\"utf-8\") as fin:\n",
    "    raw = json.load(fin)\n",
    "    thaidict_royal = set()\n",
    "    for k in raw:\n",
    "        thaidict_royal.update(raw[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63a63c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25573 records from lexicons.jsonl\n"
     ]
    }
   ],
   "source": [
    "lexicons_arr = load_jsonl(\"lexicons.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bbccb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "tags = set()\n",
    "lexicons = {}\n",
    "lexicons_keys = defaultdict(list)\n",
    "\n",
    "for key, values  in lexicons_arr:\n",
    "    if len(key) <= 1:\n",
    "        continue\n",
    "        \n",
    "    key = key.lower()\n",
    "    if key.endswith(\"rep\"):\n",
    "        key = key.replace(\"rep\", \"\")\n",
    "        \n",
    "    w = word_tokenize(key)\n",
    "    \n",
    "    lexicons_keys[w[0]].append(key)\n",
    "    \n",
    "    tag = [t for t in values[\"tags\"] if not t.startswith(\"cat:\")]\n",
    "    lexicons[key] = tag\n",
    "    tags.update(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "320f0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.util import countthai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12380160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "388acee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "import emoji\n",
    "from pythainlp.util import countthai\n",
    "from tqdm import tqdm\n",
    "\n",
    "def rm_reptitive(text):\n",
    "    s = \"\"\n",
    "    groups = groupby(text)\n",
    "    for label, group in groups:\n",
    "        g = list(group)\n",
    "        if len(g) >= 3:\n",
    "            s += f\"{label*3} rep \"\n",
    "        else:\n",
    "            s += \"\".join(g)\n",
    "    return s\n",
    "\n",
    "def remove_space(sent):\n",
    "    newwords = []\n",
    "    for w in sent:\n",
    "        if len(w.strip())==0:\n",
    "            continue\n",
    "        newwords.append(w)\n",
    "    return newwords\n",
    "    \n",
    "def analyse_conv_per_person(texts):\n",
    "    \n",
    "    # Word Statistic\n",
    "    texts = [t.lower() for t in texts]\n",
    "    texts = [rm_reptitive(t) for t in texts]\n",
    "    words = [word_tokenize(t) for t in texts]\n",
    "    words = [remove_space(w) for w in words]\n",
    "    \n",
    "    nlongword = 0\n",
    "    ndict = 0\n",
    "    for sent in words:\n",
    "        ndict += sum([1 if w in thaidict_royal else 0 for w in sent])\n",
    "        nlongword += sum([1 if len(w) > 7 else 0 for w in sent])\n",
    "        nthai = sum([1 if countthai(w) > 50 else 0 for w in sent])\n",
    "        \n",
    "        \n",
    "    \n",
    "    uwords = set()\n",
    "    for sent in words:\n",
    "        uwords.update(sent)\n",
    "    \n",
    "    # Lexicon \n",
    "    lex = []\n",
    "    for sidx, sent in enumerate(words):\n",
    "        for widx, w in enumerate(sent):\n",
    "            if w not in lexicons_keys:\n",
    "                continue \n",
    "            \n",
    "            s = \"\".join(sent[widx:])\n",
    "            for l in lexicons_keys[w]:\n",
    "                if not s.startswith(l):\n",
    "                    continue\n",
    "\n",
    "                lex.extend(lexicons[l])\n",
    "#                 print(\">>\", w, l, lexicons[l])\n",
    "\n",
    "    lexcat = {}\n",
    "    for l in lex:\n",
    "        if l not in lexcat:\n",
    "            lexcat[l] = 0\n",
    "        lexcat[l] += 1\n",
    "    \n",
    "    # Stylistic words\n",
    "    nrepeat = 0\n",
    "    for sidx, sent in enumerate(words):\n",
    "        nrepeat += sum([1 if w==\"rep\" else 0 for w in sent])\n",
    "    \n",
    "    s = \" \".join(texts)\n",
    "    nemoji = emoji.emoji_count(s)\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"nsent\": len(texts),\n",
    "        \"nword\": sum([len(w) for w in words]),\n",
    "        \"ndict\": ndict,\n",
    "        \"nunique\": len(uwords),\n",
    "        \"nlongword\": nlongword,\n",
    "        \"nrepeat\": nrepeat,\n",
    "        \"nthai\": nthai,\n",
    "        \"nemoji\": nemoji,\n",
    "        **lexcat\n",
    "    }\n",
    "  \n",
    "\n",
    "\n",
    "def analyse_conversation(df):\n",
    "    metrics = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        ms = analyse_conv_per_person(row[\"sys\"])\n",
    "        mu = analyse_conv_per_person(row[\"user\"])\n",
    "        metrics.append((ms, mu))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "analyse_conv_per_person([\"‡πÄ‡∏°‡∏¥‡∏á‡∏á‡∏á‡∏á‡∏á‡∏á‡∏á‡∏°‡∏±‡∏ô‡πÇ‡∏á‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢‡∏¢\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28f22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e63519",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14df6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj_values(filepath, obj):\n",
    "  with open(filepath, 'wb') as fin:\n",
    "    pickle.dump(obj, fin)\n",
    "    \n",
    "def load_obj_values(filepath):\n",
    "  with open(filepath, 'rb') as fin:\n",
    "    obj = pickle.load(fin)\n",
    "  return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05a13ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_values = {\n",
    "    \"closeness\": [None, None, None],\n",
    "    \"authority\": [None, None, None],\n",
    "}\n",
    "\n",
    "analysis_labels = {\n",
    "    \"closeness\": [None, None, None],\n",
    "    \"authority\": [None, None, None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07ac4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_task1_conver(\"./Task1/annotated_conersations.jsonl\", \"closeness\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"closeness\"][0] = metrics\n",
    "# analysis_labels[\"closeness\"][0] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task2_conver(\"./Task2/annotated/annotated.jsonl\", \"closeness\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"closeness\"][1] = metrics\n",
    "# analysis_labels[\"closeness\"][1] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task1_conver(\"./Task3/annotated/annotated.jsonl\", \"closeness\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"closeness\"][2] = metrics\n",
    "# analysis_labels[\"closeness\"][2] = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe536b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_task1_conver(\"./Task1/annotated_conersations.jsonl\", \"authority\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"authority\"][0] = metrics\n",
    "# analysis_labels[\"authority\"][0] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task2_conver(\"./Task2/annotated/annotated.jsonl\", \"authority\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"authority\"][1] = metrics\n",
    "# analysis_labels[\"authority\"][1] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task1_conver(\"./Task3/annotated/annotated.jsonl\", \"authority\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"authority\"][2] = metrics\n",
    "# analysis_labels[\"authority\"][2] = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16fbe703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_obj_values(\"analysis_values.pkl\", analysis_values)\n",
    "# save_obj_values(\"analysis_labels.pkl\", analysis_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af1b2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_values = load_obj_values(\"analysis_values.pkl\")\n",
    "analysis_labels = load_obj_values(\"analysis_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d8bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff512b96",
   "metadata": {},
   "source": [
    "## Appendix C: Descriptive Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7098221",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = {\n",
    "    \"Word Statistics\" : {\n",
    "        \"nsent\": \"Number of utterance\",\n",
    "        \"nword\": \"Number of word\",\n",
    "    },\n",
    "    \"Lexicon Diversity\" : {\n",
    "        \"nunique\": \"Vocabulary size\",\n",
    "        \"nthai\": \"Thai words\",\n",
    "        \"nlongword\": \"Long words\",\n",
    "        \"ndict\": \"Dictionary words\"\n",
    "    },\n",
    "    \n",
    "    \"Function Words\": {\n",
    "\n",
    "        \"pronoun\": \"Pronoun\",\n",
    "        \"pronoun_1st\": \">> 1st person pronoun\",\n",
    "        \"pronoun_2nd\": \">> 2nd person pronoun\",\n",
    "        \"pronoun_3rd\": \">> 3rd person pronoun\",\n",
    "        \"pronoun_misspelling\": \">> Pronoun in non-standard spelling\",\n",
    "\n",
    "        \"particles\": \"Particles\",\n",
    "        \"particles_SARP\": \">> Socially-related particles\",\n",
    "        \"particles_notSARP\": \">> Non-socially-related particles\",\n",
    "        \"particles_misspelling\": \">> Particle in non-standard spelling\",\n",
    "    },\n",
    "    \n",
    "    \"Sentiment-related\": {\n",
    "    \n",
    "        \"sentiment\": \"Sentiment words\",\n",
    "        \"sentiment_positive\": \">> Positive words\",\n",
    "        \"sentiment_negative\": \">> Negative words\",\n",
    "    },\n",
    "    \n",
    "    \"Internet Lexicons\": {\n",
    "        \"misspelling\": \"Spelling variation\",\n",
    "        \"misspelling_common\": \">> Common misspelt words\",\n",
    "        \"misspelling_intention\": \">> Sematic variation\",\n",
    "        \"misspelling_shorten\": \">> Simplified variation\",\n",
    "        \"nrepeat\": \">> Repeated characters\",\n",
    "\n",
    "        \"abbr\": \"Abbreviation\",\n",
    "        \"slang\": \"Slang\",\n",
    "        \"swear\": \"Swear words\",\n",
    "        \"transliterated\": \"Transliteration\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaf894e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clse_print_labels = ['1. Close', '2. Know each other', \"3. Don't know each other\", \"4. Don't like each other\"]\n",
    "auth_print_labels = ['0. Very respect', '1. Respect', '2. Normal', '3. Not respect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ba33341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lexi_stat(analysis_values, analysis_labels, factor, setting, print_labels):\n",
    "    values = analysis_values[factor][setting]\n",
    "    labels = analysis_labels[factor][setting]\n",
    "    assert(len(values)==len(labels))\n",
    "    \n",
    "    printed_text = \"\"\n",
    "    rows = []\n",
    "    for (ms, mu), l in zip(values, labels):\n",
    "        for m in mu:\n",
    "            if m in [\"nsent\", \"nword\"]:\n",
    "                v = mu[m]\n",
    "            else:\n",
    "                v = mu[m]*100/mu[\"nword\"]\n",
    "                \n",
    "            rows.append({\n",
    "                \"label\": l,\n",
    "                \"metric\": m,\n",
    "                \"value\": v\n",
    "            })\n",
    "        \n",
    "        if \"particles_SARP\" in mu:\n",
    "            particles_notSARP = mu[\"particles\"] - mu[\"particles_SARP\"]\n",
    "            rows.append({\n",
    "                \"label\": l,\n",
    "                \"metric\": \"particles_notSARP\",\n",
    "                \"value\": particles_notSARP\n",
    "            })\n",
    "            \n",
    "    df = pd.DataFrame(rows).groupby([\"label\", \"metric\"]).mean().reset_index()\n",
    "    \n",
    "    for g in metric_names:\n",
    "        # print(\"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "        printed_text += \"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "        for m in metric_names[g]:\n",
    "            s = f\"{metric_names[g][m]} \"\n",
    "            for l in print_labels:\n",
    "                row = df[(df[\"label\"]==l) & (df[\"metric\"]==m)]\n",
    "#                 print(l, m)\n",
    "#                 print(df)\n",
    "                if len(row)!=0:\n",
    "                    s += f\"& {row['value'].values[0]:.2f} \"\n",
    "                else:\n",
    "                    s += f\"& - \"\n",
    "\n",
    "            s += \"\\\\\\\\\"\n",
    "            # print(s)\n",
    "            printed_text += \"    \"+s+\"\\n\"\n",
    "        \n",
    "        printed_text += \"    &  & &  & \\\\\\\\\"+\"\\n\"\n",
    "        printed_text += \"\\hline\"+\"\\n\"\n",
    "        \n",
    "        # print(\"&  & &  & \\\\\\\\\")\n",
    "        # print(\"\\hline\")\n",
    "    # print(printed_text)\n",
    "    return df, printed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e49d35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text1 = print_lexi_stat(analysis_values, analysis_labels, \"closeness\", 0, clse_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bd4031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text2 = print_lexi_stat(analysis_values, analysis_labels, \"authority\", 0, auth_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1066c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text3 = print_lexi_stat(analysis_values, analysis_labels, \"closeness\", 1, clse_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aec5617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text4 = print_lexi_stat(analysis_values, analysis_labels, \"authority\", 1, auth_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e702d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text5 = print_lexi_stat(analysis_values, analysis_labels, \"closeness\", 2, clse_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d6b6aed-8f23-44ec-8f65-8aa698cbabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(analysis_labels[\"authority\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81e5baab-871b-4647-a9cc-88819ca077c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text6 = print_lexi_stat(analysis_values, analysis_labels, \"authority\", 2, auth_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f05354e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\n",
    "    \"Setting 1: Private Conversations with Self-Reported Labels\",\n",
    "    \"Setting 2: Public Conversations with Labels from 3rd Party \",\n",
    "    \"Setting 3: Private Conversations with Labels from 3rd Party \",\n",
    "]\n",
    "\n",
    "table_contents = [\n",
    "    (printed_text1, printed_text2),\n",
    "    (printed_text3, printed_text4),\n",
    "    (printed_text5, printed_text6),\n",
    "]\n",
    "\n",
    "printed_text = \"\"\n",
    "for section, (t1, t2) in zip(sections, table_contents):\n",
    "    \n",
    "    printed_text += \"\\subsection{\"+section+\"}\"+\"\\n\\n\"\n",
    "    \n",
    "    printed_text += '''\\subsubsection{Closeness}\n",
    "\\\\begin{longtable}[h]{\n",
    "    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "}\n",
    "    \\hline\n",
    "\n",
    "    Linguistic Features & Close & Know each other & Don't know each other &  Don't like each other\\\\\\\\\n",
    "    \\hline\n",
    "    \\endfirsthead\n",
    "\n",
    "    \\endhead\n",
    "    '''\n",
    "    \n",
    "    printed_text += (\"\\n\"+t1).replace(\"\\n\", \"\\n    \")\n",
    "    printed_text += \"\\n\"\n",
    "    printed_text += \"\\end{longtable}\"\n",
    "    printed_text += \"\\n\\n\"\n",
    "\n",
    "    printed_text += '''\\clearpage\n",
    "\\subsubsection{Respect}\n",
    "\\\\begin{longtable}[h]{\n",
    "    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\n",
    "    p{\\dimexpr 0.16\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "}\n",
    "    \\hline\n",
    "\n",
    "    Linguistic Features & Very respect & Respect & Normal &  Not respect\\\\\\\\\n",
    "    \\hline\n",
    "    \\endfirsthead\n",
    "\n",
    "    \\endhead\n",
    "    '''\n",
    "    \n",
    "    printed_text += (\"\\n\"+t2).replace(\"\\n\", \"\\n    \")\n",
    "    printed_text += \"\\n\"\n",
    "    printed_text += \"\\end{longtable}\"\n",
    "    printed_text += \"\\n\\n\"\n",
    "    printed_text += \"\\clearpage\"\n",
    "    printed_text += \"\\n\\n\"\n",
    "    # break\n",
    "    \n",
    "# print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0566b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128a745-0d9e-4545-95f2-f2bbbe6df10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cad66f10",
   "metadata": {},
   "source": [
    "## Appendix D: Regression Analysis\n",
    "https://medium.com/@wyess/demystifying-statistical-analysis-3-the-one-way-anova-expressed-in-linear-regression-99269e84edd9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65d94022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def closeness_to_vec1(label):\n",
    "#     if label == \"1. Close\":\n",
    "#         return {\"x1\": 1, \"x2\": 0}\n",
    "#     elif label == \"2. Know each other\": ## Base category\n",
    "#         return {\"x1\": 0, \"x2\": 0}\n",
    "#     elif label == \"3. Don't know each other\": \n",
    "#         return {\"x1\": 0, \"x2\": 1}\n",
    "#     elif label == \"4. Don't like each other\":\n",
    "#         return None\n",
    "#     else:\n",
    "#         return None\n",
    "    \n",
    "# def authority_to_vec1(label):\n",
    "#     if label == '0. Very respect':\n",
    "#         return {\"x1\": 1, \"x2\": 0}\n",
    "#     elif label == '1. Respect': ## Base category\n",
    "#         return {\"x1\": 0, \"x2\": 0}\n",
    "#     elif label == '2. Normal':\n",
    "#         return {\"x1\": 0, \"x2\": 1}\n",
    "#     elif label == '3. Not respect':\n",
    "#         return None\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "def closeness_to_vec1(label):\n",
    "    if label == \"1. Close\":\n",
    "        return {\"x1\": 1, \"x2\": -1}\n",
    "    elif label == \"2. Know each other\":\n",
    "        return {\"x1\": 0, \"x2\": 2}\n",
    "    elif label == \"3. Don't know each other\": \n",
    "        return {\"x1\": -1, \"x2\": -1}\n",
    "    elif label == \"4. Don't like each other\":\n",
    "        return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def authority_to_vec1(label):\n",
    "    if label == '0. Very respect':\n",
    "        return {\"x1\": 1, \"x2\": -1}\n",
    "    elif label == '1. Respect': \n",
    "        return {\"x1\": 0, \"x2\": 2}\n",
    "    elif label == '2. Normal':\n",
    "        return {\"x1\": -1, \"x2\": -1}\n",
    "    elif label == '3. Not respect':\n",
    "        return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d08665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clse_coef_labels = [\"b\", \"a1\", \"a2\"]\n",
    "auth_coef_labels = [\"b\", 'a1', 'a2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85b93ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_features(analysis_values, analysis_labels, factor, setting, to_vec_func, skips=[]):\n",
    "    values = analysis_values[factor][setting]\n",
    "    labels = analysis_labels[factor][setting]\n",
    "    assert(len(values)==len(labels))\n",
    "    \n",
    "    rows = []\n",
    "    for (ms, mu), l in zip(values, labels):\n",
    "        if l in skips:\n",
    "            continue\n",
    "            \n",
    "        x = to_vec_func(l)\n",
    "        if x is None:\n",
    "            continue\n",
    "        \n",
    "        for m in mu:\n",
    "            if m in [\"nsent\", \"nword\"]:\n",
    "                v = mu[m]\n",
    "            else:\n",
    "                v = mu[m]*100/mu[\"nword\"]\n",
    "            \n",
    "            \n",
    "            rows.append({\n",
    "                \"metric\": m,\n",
    "                \"value\": v,\n",
    "                **x\n",
    "            })\n",
    "            \n",
    "        if \"particles_SARP\" in mu:\n",
    "            particles_notSARP = mu[\"particles\"] - mu[\"particles_SARP\"]\n",
    "            rows.append({\n",
    "                \"metric\": \"particles_notSARP\",\n",
    "                \"value\": particles_notSARP,\n",
    "                **x\n",
    "            })\n",
    "            \n",
    "    feats = pd.DataFrame(rows)  \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fceb9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "def print_anova_test(feats, n=3):\n",
    "    feat_names = feats[\"metric\"].unique()\n",
    "    \n",
    "    feat_important = []\n",
    "    for f in feat_names:\n",
    "        if \"cat:\" in f:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            d = feats[feats[\"metric\"]==f]\n",
    "        #     print(f, len(d))\n",
    "            x_columns = [f\"x{i+1}\" for i in range(n)]\n",
    "            X = d[x_columns]\n",
    "            X = sm.add_constant(X)\n",
    "            Y = d[\"value\"]\n",
    "            model = sm.OLS(Y,X)\n",
    "            results = model.fit()\n",
    "            \n",
    "            ncoef = n + 1\n",
    "            \n",
    "            t_test = results.t_test(np.identity(ncoef))\n",
    "            f_test = results.f_test(np.identity(ncoef))\n",
    "            o = {\"feat\": f, \"f_value\": f_test.pvalue}\n",
    "            for i in range(ncoef):\n",
    "                o[f\"coef{i}\"] = t_test.effect[i]\n",
    "                \n",
    "            for i in range(ncoef):\n",
    "                o[f\"pval{i}\"] = t_test.pvalue[i]\n",
    "                \n",
    "            feat_important.append(o)\n",
    "        except Exception as e:\n",
    "            print(\"error\", f, e)\n",
    "\n",
    "    outputs = pd.DataFrame(feat_important)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860eae70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b7e208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_weights(outputs, coef_labels, labels, base_category=None):\n",
    "    \n",
    "#     coefs = {}\n",
    "#     non_coefs = {}\n",
    "#     for i, label in enumerate(coef_labels):\n",
    "#         if i==0:\n",
    "#             continue\n",
    "            \n",
    "#         cond = outputs[f\"pval{i}\"] < 0.05\n",
    "#         for _, row in outputs[cond].sort_values(f\"coef{i}\", ascending=False).iterrows():\n",
    "#             coefs[(label, row[\"feat\"])] = row[f\"coef{i}\"]\n",
    "        \n",
    "#         cond = outputs[f\"pval{i}\"] >= 0.05\n",
    "#         for _, row in outputs[cond].iterrows():\n",
    "#             non_coefs[(label, row[\"feat\"])] = row[f\"coef{i}\"]\n",
    "\n",
    "# #     print(coefs)\n",
    "#     for g in metric_names:\n",
    "#         print(\"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "#         for m in metric_names[g]:\n",
    "#             s = f\"{metric_names[g][m]} \"\n",
    "#             for l in labels:\n",
    "#                 if l == base_category:\n",
    "#                     s += f\"& * \"\n",
    "#                 elif (l, m) in coefs:\n",
    "#                     val = coefs[(l, m)]\n",
    "#                     s += \"& \\cellcolor{gray!25} \"+f\"{val:.2f} \"\n",
    "#                 elif (l, m) in non_coefs:\n",
    "#                     val = non_coefs[(l, m)]\n",
    "#                     s += f\"& {val:.2f} \"\n",
    "#                 else:\n",
    "#                     s += f\"& - \"\n",
    "\n",
    "#             s += \"\\\\\\\\\"\n",
    "#             print(s)\n",
    "#         print(\"&  & &  & \\\\\\\\\")\n",
    "#         print(\"\\hline\")\n",
    "\n",
    "# # gray!25 < gray!50 < gray!80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "574751f3-cfd7-49fe-9bbd-bdfc44bf37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights(outputs):\n",
    "    \n",
    "    coefs = {}\n",
    "    coef_labels = [\"b\", \"a1\", \"a2\"]\n",
    "    for i, label in enumerate(coef_labels):\n",
    "        for _, row in outputs.iterrows():\n",
    "            coefs[(label, row[\"feat\"])] = (row[f\"coef{i}\"], row[f\"pval{i}\"])\n",
    "\n",
    "#     print(coefs)\n",
    "\n",
    "    printed_text = \"\"\n",
    "    for g in metric_names:\n",
    "        # print(\"\\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "        printed_text += \"\\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "        for m in metric_names[g]:\n",
    "            s = f\"{metric_names[g][m]} \"\n",
    "            for l in coef_labels:                    \n",
    "                val, pval = coefs[(l, m)]\n",
    "                if l==\"b\":\n",
    "                    s += f\"& {val:.2f} \"\n",
    "                elif pval < 0.05:\n",
    "                    s += \"& \\cellcolor{gray!25} \"+f\"{val:.2f} \"\n",
    "                else:\n",
    "                    s += f\"& {val:.2f} \"\n",
    "            s += \"\\\\\\\\\"\n",
    "            # print(s)\n",
    "            printed_text += s+\"\\n\"\n",
    "        printed_text += \"&  & &\\\\\\\\\" + \"\\n\"\n",
    "        printed_text += \"\\hline\" + \"\\n\"\n",
    "        # print(\"&  & &\\\\\\\\\")\n",
    "        # print(\"\\hline\")\n",
    "    return printed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123595e1-f763-455a-87a6-62bc1fc253fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f82a11-1c8c-45b6-8b02-1a05e1563a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11badd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 0, closeness_to_vec1, skips=[])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# print_weights(outputs, clse_coef_labels, clse_print_labels, \"2. Know each other\")\n",
    "printed_text1 = print_weights(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50750d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 0, authority_to_vec1, skips=[\"3. Not respect\"])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# print_weights(outputs, auth_coef_labels, auth_print_labels, \"1. Respect\")\n",
    "printed_text2 = print_weights(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366bdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a18a5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def closeness_to_vec2(label):\n",
    "#     if label == \"1. Close\":\n",
    "#         return {\"x1\": 1, \"x2\": 0}\n",
    "#     elif label == \"2. Know each other\": \n",
    "#         return {\"x1\": 1, \"x2\": 0}\n",
    "#     elif label == \"3. Don't know each other\": ## Base category\n",
    "#         return {\"x1\": 0, \"x2\": 0}\n",
    "#     elif label == \"4. Don't like each other\":\n",
    "#         return {\"x1\": 0, \"x2\": 1}\n",
    "#     else:\n",
    "#         return None\n",
    "    \n",
    "# def authority_to_vec2(label):\n",
    "#     if label == '0. Very respect':\n",
    "#         return None\n",
    "#     elif label == '1. Respect': \n",
    "#         return {\"x1\": 1, \"x2\": 0}\n",
    "#     elif label == '2. Normal': ## Base category\n",
    "#         return {\"x1\": 0, \"x2\": 0}\n",
    "#     elif label == '3. Not respect':\n",
    "#         return {\"x1\": 0, \"x2\": 1}\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "def closeness_to_vec2(label):\n",
    "    if label == \"1. Close\":\n",
    "        return {\"x1\": 1, \"x2\": -1}\n",
    "    elif label == \"2. Know each other\": \n",
    "        return {\"x1\": 0, \"x2\": 2}\n",
    "    elif label == \"3. Don't know each other\": ## Base category\n",
    "        return {\"x1\": -1, \"x2\": 1}\n",
    "    elif label == \"4. Don't like each other\":\n",
    "        return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def authority_to_vec2(label):\n",
    "    if label == '0. Very respect':\n",
    "        return None\n",
    "    elif label == '1. Respect': \n",
    "        return {\"x1\": 1, \"x2\": -1}\n",
    "    elif label == '2. Normal': ## Base category\n",
    "        return {\"x1\": 0, \"x2\": 2}\n",
    "    elif label == '3. Not respect':\n",
    "        return {\"x1\": -1, \"x2\": -1}\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eeb1c491-f902-4174-b929-bb29eed0a5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error particles_?? wrong shape for coefs\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 1, closeness_to_vec2)\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# clse_coef_labels = [\"b\", \"2. Know each other\", \"4. Don't like each other\"]\n",
    "# print_weights(outputs, clse_coef_labels, clse_print_labels, \"3. Don't know each other\")\n",
    "printed_text3 = print_weights(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "987c34d3-bd59-41d5-985e-299161b6d308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error particles_?? wrong shape for coefs\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 1, authority_to_vec2)\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# auth2_coef_labels = [\"b\", '1. Respect', '3. Not respect']\n",
    "# print_weights(outputs, auth2_coef_labels, auth_print_labels, \"2. Normal\")\n",
    "printed_text4 = print_weights(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1d045e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "550f18a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imtk/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/Users/imtk/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 2, closeness_to_vec2, skips=[])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# print_weights(outputs, clse_coef_labels, clse_print_labels, \"2. Know each other\")\n",
    "printed_text5 = print_weights(outputs)\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 2, authority_to_vec2, skips=[])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# print_weights(outputs, auth_coef_labels, auth_print_labels, \"1. Respect\")\n",
    "printed_text6 = print_weights(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9cedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1bd0f30-6750-4e6d-a1fc-60717f9b2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections = [\n",
    "#     \"Setting 1: Private Conversations with Self-Reported Labels\",\n",
    "#     \"Setting 2: Public Conversations with Labels from 3rd Party \",\n",
    "#     \"Setting 3: Private Conversations with Labels from 3rd Party \",\n",
    "# ]\n",
    "\n",
    "# table_contents = [\n",
    "#     (printed_text1, printed_text2),\n",
    "#     (printed_text3, printed_text4),\n",
    "#     (printed_text5, printed_text6),\n",
    "# ]\n",
    "\n",
    "# printed_text = \"\"\n",
    "# for section, (t1, t2) in zip(sections, table_contents):\n",
    "    \n",
    "#     printed_text += \"\\subsection{\"+section+\"}\"+\"\\n\\n\"\n",
    "    \n",
    "#     printed_text += '''\\subsubsection{Closeness}\n",
    "# \\\\begin{longtable}[h]{\n",
    "#     p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|c|c|c\n",
    "# }\n",
    "#     \\hline\n",
    "\n",
    "#     Lexical Features & b & a1 & a2 \\\\\\\\\n",
    "#     \\hline\n",
    "#     \\endfirsthead\n",
    "\n",
    "#     \\endhead\n",
    "#     '''\n",
    "    \n",
    "#     printed_text += (\"\\n\"+t1).replace(\"\\n\", \"\\n    \")\n",
    "#     printed_text += \"\\n\"\n",
    "#     printed_text += \"\\end{longtable}\"\n",
    "#     printed_text += \"\\n\\n\"\n",
    "\n",
    "#     printed_text += '''\\clearpage\n",
    "# \\subsubsection{Respect}\n",
    "# \\\\begin{longtable}[h]{\n",
    "#     p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|c|c|c\n",
    "# }\n",
    "#     \\hline\n",
    "\n",
    "#     Lexical Features & b & a1 & a2 \\\\\\\\\n",
    "#     \\hline\n",
    "#     \\endfirsthead\n",
    "\n",
    "#     \\endhead\n",
    "#     '''\n",
    "    \n",
    "#     printed_text += (\"\\n\"+t2).replace(\"\\n\", \"\\n    \")\n",
    "#     printed_text += \"\\n\"\n",
    "#     printed_text += \"\\end{longtable}\"\n",
    "#     printed_text += \"\\n\\n\"\n",
    "    \n",
    "#     printed_text += \"\\clearpage\"\n",
    "#     printed_text += \"\\n\\n\"\n",
    "#     # break\n",
    "    \n",
    "# print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d391969-05f1-43d4-ba90-8eac82bc0c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7a88e-1efd-49c2-a577-7911b4e97529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46a1405-2b91-495b-b7c9-c393c8816fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d074d8d-640b-442a-9dc0-498d1313e900",
   "metadata": {},
   "source": [
    "## Appendix D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c32a6648-fa5d-4398-8de5-daae33257db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeness_to_vec_effect(label):\n",
    "    if label == \"1. Close\":\n",
    "        return {\"x1\": 1, \"x2\": 0}\n",
    "    elif label == \"2. Know each other\": ## Base category\n",
    "        return {\"x1\": -1, \"x2\": -1}\n",
    "    elif label == \"3. Don't know each other\": \n",
    "        return {\"x1\": 0, \"x2\": 1}\n",
    "    elif label == \"4. Don't like each other\":\n",
    "        return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def authority_to_vec_effect(label):\n",
    "    if label == '0. Very respect':\n",
    "        return {\"x1\": 1, \"x2\": 0}\n",
    "    elif label == '1. Respect': \n",
    "        return {\"x1\": 0, \"x2\": 1}\n",
    "    elif label == '2. Normal':    ## Base category\n",
    "        return {\"x1\": -1, \"x2\": -1}\n",
    "    elif label == '3. Not respect':\n",
    "        # return None\n",
    "        return {\"x1\": 1, \"x2\": 0}\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "afbdeaca-b972-4eca-8be4-f7ab964cfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights_effect(outputs, coef_labels):\n",
    "    coefs = {}\n",
    "    for i, label in coef_labels.items():\n",
    "        if i is None:\n",
    "            continue\n",
    "            \n",
    "        for _, row in outputs.iterrows():\n",
    "            coefs[(label, row[\"feat\"])] = (row[f\"coef{i}\"], row[f\"pval{i}\"])\n",
    "\n",
    "    printed_text = \"\"\n",
    "    for g in metric_names:\n",
    "        # print(\"\\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "        printed_text += \"\\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "        for m in metric_names[g]:\n",
    "            s = f\"{metric_names[g][m]} \"\n",
    "            for i, l in coef_labels.items():                    \n",
    "                if i is None:\n",
    "                    s += f\"& * \"\n",
    "                    continue\n",
    "                \n",
    "                val, pval = coefs[(l, m)]\n",
    "                if l==\"Grand Mean\":\n",
    "                    s += f\"& {val:.2f} \"\n",
    "                elif pval < 0.05:\n",
    "                    s += \"& \\cellcolor{gray!25} \"+f\"{val:.2f} \"\n",
    "                else:\n",
    "                    s += f\"& {val:.2f} \"\n",
    "            s += \"\\\\\\\\\"\n",
    "            # print(s)\n",
    "            printed_text += s+\"\\n\"\n",
    "        printed_text += \"&  & &\\\\\\\\\" + \"\\n\"\n",
    "        printed_text += \"\\hline\" + \"\\n\"\n",
    "        # print(\"&  & &\\\\\\\\\")\n",
    "        # print(\"\\hline\")\n",
    "    return printed_text, coef_labels\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 0, closeness_to_vec_effect, skips=[])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# [\"Grand Mean\", \"0. Very respect\", \"1. Respect\", \"\", \"3. Not respect\"], \"2. Normal\"\n",
    "\n",
    "coef_labels = {0:\"Grand Mean\", 1: \"Close\", None: \"Know each other\", 2: \"Don't know each other\"}\n",
    "printed_text1 = print_weights_effect(outputs, coef_labels)\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 0, authority_to_vec_effect, skips=[\"3. Not respect\"])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "\n",
    "coef_labels = {0:\"Grand Mean\", 1: \"Very respect\", 2: \"Respect\", None: \"Normal\"}\n",
    "printed_text2 = print_weights_effect(outputs, coef_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "96b3b6bd-54cb-46b6-85c4-a5c9649342e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error particles_?? wrong shape for coefs\n",
      "error particles_?? wrong shape for coefs\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 1, closeness_to_vec_effect, skips=[])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "coef_labels = {0:\"Grand Mean\", 1: \"Close\", None: \"Know each other\", 2: \"Don't know each other\"}\n",
    "printed_text3 = print_weights_effect(outputs, coef_labels)\n",
    "\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 1, authority_to_vec_effect, skips=[\"0. Very respect\"])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "coef_labels = {0:\"Grand Mean\", None: \"Normal\", 2: \"Respect\", 1: \"Not respect\"}\n",
    "printed_text4 = print_weights_effect(outputs, coef_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4d32ca6d-47e1-45b9-890f-f4e3842c9d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imtk/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/Users/imtk/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 2, closeness_to_vec_effect, skips=[])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "coef_labels = {0:\"Grand Mean\", 1: \"Close\", None: \"Know each other\", 2: \"Don't know each other\"}\n",
    "printed_text5 = print_weights_effect(outputs, coef_labels)\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 2, authority_to_vec_effect, skips=[\"0. Very respect\"])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "coef_labels = {0:\"Grand Mean\", None: \"Normal\", 2: \"Respect\", 1: \"Not respect\"}\n",
    "printed_text6 = print_weights_effect(outputs, coef_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "76969f31-4866-4638-af6b-9ac3fe37cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats[feats[\"metric\"]==\"nsent\"].groupby([\"x1\", \"x2\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aaeda7c3-d475-4738-a743-69363387a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections = [\n",
    "#     \"Setting 1: Private Conversations with Self-Reported Labels\",\n",
    "#     \"Setting 2: Public Conversations with Labels from 3rd Party \",\n",
    "#     \"Setting 3: Private Conversations with Labels from 3rd Party \",\n",
    "# ]\n",
    "\n",
    "# table_contents = [\n",
    "#     (printed_text1, printed_text2),\n",
    "#     (printed_text3, printed_text4),\n",
    "#     (printed_text5, printed_text6),\n",
    "# ]\n",
    "\n",
    "# # columns = \n",
    "# # ([\"Grand Mean\", \"1. Close\", \"2. Know each other\", \"3. Don't know each other\"], \"2. Know each other\")\n",
    "\n",
    "# # [\"Grand Mean\", \"0. Very respect\", \"1. Respect\", \"2. Normal\", \"3. Not respect\"], \"2. Normal\"\n",
    "\n",
    "# printed_text = \"\"\n",
    "# for section, (v1, v2) in zip(sections, table_contents):\n",
    "    \n",
    "#     printed_text += \"\\subsection{\"+section+\"}\"+\"\\n\\n\"\n",
    "    \n",
    "#     printed_text += '''\\subsubsection{Closeness}\n",
    "# \\\\begin{longtable}[h]{\n",
    "#     p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "# }\n",
    "#     \\hline\n",
    "#     '''\n",
    "    \n",
    "#     t1, col1 = v1\n",
    "#     printed_text += \"Lexical Features & \" + \" & \".join(col1.values()) + \"\\\\\\\\\"\n",
    "        \n",
    "#     printed_text +='''\n",
    "#     \\hline\n",
    "#     \\endfirsthead\n",
    "\n",
    "#     \\endhead\n",
    "#     '''\n",
    "\n",
    "    \n",
    "#     printed_text += (\"\\n\"+t1).replace(\"\\n\", \"\\n    \")\n",
    "#     printed_text += \"\\n\"\n",
    "#     printed_text += \"\\end{longtable}\"\n",
    "#     printed_text += \"\\n\\n\"\n",
    "\n",
    "    \n",
    "#     printed_text += '''\\clearpage\n",
    "# \\subsubsection{Respect}\n",
    "# \\\\begin{longtable}[h]{\n",
    "#     p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "# }\n",
    "#     \\hline\n",
    "#     '''\n",
    "\n",
    "#     t2, col2 = v2\n",
    "    \n",
    "#     printed_text += \"Lexical Features & \" + \" & \".join(col2.values()) + \"\\\\\\\\\"\n",
    "        \n",
    "#     printed_text +='''\n",
    "#     \\hline\n",
    "#     \\endfirsthead\n",
    "\n",
    "#     \\endhead\n",
    "#     '''\n",
    "    \n",
    "#     printed_text += (\"\\n\"+t2).replace(\"\\n\", \"\\n    \")\n",
    "#     printed_text += \"\\n\"\n",
    "#     printed_text += \"\\end{longtable}\"\n",
    "#     printed_text += \"\\n\\n\"\n",
    "    \n",
    "#     printed_text += \"\\clearpage\"\n",
    "#     printed_text += \"\\n\\n\"\n",
    "#     # break\n",
    "    \n",
    "# print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3265f4a8-30e3-4152-a72c-b87a3a87f49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79a59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8acd686",
   "metadata": {},
   "source": [
    "## Appendix E: Linear Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e232280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import datasets, linear_model\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# import statsmodels.api as sm\n",
    "# from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9b1acc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_linear_features(analysis_values, analysis_labels, factor, setting):\n",
    "#     values = analysis_values[factor][setting]\n",
    "#     labels = analysis_labels[factor][setting]\n",
    "#     assert(len(values)==len(labels))\n",
    "    \n",
    "#     rows = []\n",
    "#     for (ms, mu), l in zip(values, labels):\n",
    "        \n",
    "#         o = {\"label\": l, \"bias\": 1}\n",
    "#         for m in mu:\n",
    "#             if m in [\"nsent\", \"nword\"]:\n",
    "#                 v = mu[m]\n",
    "#             else:\n",
    "#                 v = mu[m]*100/mu[\"nword\"]\n",
    "            \n",
    "#             o[m] = v\n",
    "#         rows.append(o)\n",
    "        \n",
    "#     feats = pd.DataFrame(rows).fillna(0)  \n",
    "#     return feats\n",
    "\n",
    "\n",
    "\n",
    "# def run_linear_model(feats, skips=[]):\n",
    "#     col = []\n",
    "#     for g in metric_names:\n",
    "#         for m in metric_names[g]:\n",
    "#             if m in [\"nsent\", \"nword\"]:\n",
    "#                 continue\n",
    "                \n",
    "#             col.append(m)\n",
    "    \n",
    "#     X = feats[col].values\n",
    "\n",
    "#     saved_results = {}\n",
    "#     for label in labels:\n",
    "#         if label in skips:\n",
    "#             continue\n",
    "        \n",
    "#         print(label)\n",
    "#         Y = (feats[\"label\"]==label).astype(int)\n",
    "#         model = sm.Logit(Y, X)\n",
    "#         result = model.fit()\n",
    "# #         print(result.summary())\n",
    "#         ncoef = len(col)\n",
    "#         t_test = result.t_test(np.identity(ncoef))\n",
    "        \n",
    "# #         print(t_test.tvalue) #Z\n",
    "# #         print(t_test.pvalue) #p-value\n",
    "# #         print(t_test.effect) #coef\n",
    "\n",
    "#         for f, coef, pvalue in zip(feats, t_test.effect, t_test.pvalue):\n",
    "#             saved_results[(label, f)] = (coef, pvalue)\n",
    "#     return saved_results\n",
    "\n",
    "# def print_linear_weights(weights, labels, skips=[]):\n",
    "#     for g in metric_names:\n",
    "#         print(\"\\multicolumn{\"+str(len(labels)+1)+\"}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "#         for m in metric_names[g]:\n",
    "#             if m in [\"nwordputterance\", \"nsent\", \"nword\"]:\n",
    "#                 continue\n",
    "                \n",
    "#             s = f\"{metric_names[g][m]} \"\n",
    "#             for l in labels:\n",
    "#                 if l in skips:\n",
    "#                     s += f\"& - \"\n",
    "#                     continue\n",
    "                \n",
    "#                 if (l, m) not in weights:\n",
    "#                     s += f\"& - \"\n",
    "#                     continue\n",
    "                    \n",
    "#                 val, pvalue = weights[(l, m)]\n",
    "#                 if pvalue < 0.05:\n",
    "#                     s += \"& \\cellcolor{gray!25} \"+f\"{val:.3f} \"\n",
    "#                 else:\n",
    "#                     s += f\"& {val:.3f} \"\n",
    "\n",
    "#             s += \"\\\\\\\\\"\n",
    "#             print(s)\n",
    "#         print(\"&  & &  & \\\\\\\\\")\n",
    "#         print(\"\\hline\")\n",
    "        \n",
    "#     return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "bab11900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = to_linear_features(analysis_values, analysis_labels, \"closeness\", 0)\n",
    "# weights = run_linear_model(feats, skips=[\"4. Don't like each other\"])\n",
    "# print_linear_weights(weights, clse_print_labels, skips=[\"4. Don't like each other\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "46fd7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = to_linear_features(analysis_values, analysis_labels, \"authority\", 0)\n",
    "# weights = run_linear_model(feats, skips=[\"3. Not respect\"])\n",
    "# print_linear_weights(weights, auth_print_labels, skips=[\"3. Not respect\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ce27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
