{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1877f9b4",
   "metadata": {},
   "source": [
    "## Load Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93deeee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "from utils import load_jsonl, dump_jsonl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87c53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f99623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task1_conver(in_dir, col_label, skips=[]):\n",
    "    conversations = load_jsonl(f\"{in_dir}\")\n",
    "    \n",
    "    \n",
    "    def to_message_str(messages, users):\n",
    "        s = []\n",
    "        u = []\n",
    "        for m in messages:\n",
    "            if users[m['user_id']] == \"SYS\":\n",
    "                s.append(m['text'])\n",
    "            else:\n",
    "                u.append(m['text'])\n",
    "                \n",
    "        return s, u\n",
    "        \n",
    "    newdata = []\n",
    "    for row in conversations:\n",
    "        row[\"messages\"].sort(key=lambda x: x[\"date_created\"], reverse=False)\n",
    "        \n",
    "        users = {}\n",
    "        for m in row[\"messages\"]:\n",
    "            if m[\"user_id\"] not in users:\n",
    "#                 username = \"USR\"+str(len(users)+1) if len(users.keys())==0 else \"SYS\"\n",
    "                username = \"USR\" if len(users.keys())==0 else \"SYS\"\n",
    "                users[m[\"user_id\"]] = username\n",
    "                \n",
    "#         if len(users)>2:\n",
    "#             print(\"More than 1 users\", len(users))\n",
    "        \n",
    "        \n",
    "        messages = row[\"messages\"]\n",
    "        chunk_size = 100\n",
    "        for i in range(0, len(messages), chunk_size):\n",
    "            sub_messages = messages[i:i+chunk_size]\n",
    "            s, u = to_message_str(sub_messages, users)\n",
    "            \n",
    "            if pd.isna(row[col_label]):\n",
    "                continue\n",
    "            \n",
    "            if row[col_label] in skips:\n",
    "                continue\n",
    "                \n",
    "            label = row[col_label]\n",
    "                \n",
    "            newdata.append({\n",
    "                \"user\": u,\n",
    "                \"sys\": s,\n",
    "                \"label\": label,\n",
    "                \"nturn\": len(sub_messages)\n",
    "            })\n",
    "        \n",
    "#     n_val = int(len(newdata)*0.05)\n",
    "#     n_test = n_val\n",
    "    \n",
    "#     test = newdata[0:n_test]\n",
    "#     val = newdata[n_test:n_test+n_val]\n",
    "#     train = newdata[n_test+n_val:]\n",
    "    \n",
    "    return pd.DataFrame(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92feb049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1234 records from ./Task1/annotated_conersations.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...</td>\n",
       "      <td>[ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...</td>\n",
       "      <td>[โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...</td>\n",
       "      <td>[อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...</td>\n",
       "      <td>[ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...</td>\n",
       "      <td>[ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...   \n",
       "1  [วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...   \n",
       "2  [เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...   \n",
       "3  [มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...   \n",
       "4  [อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...   \n",
       "\n",
       "                                                 sys     label  nturn  \n",
       "0  [ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...  1. Close     35  \n",
       "1  [โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...  1. Close     39  \n",
       "2  [อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...  1. Close     40  \n",
       "3  [ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...  1. Close     35  \n",
       "4  [ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...  1. Close     39  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task1_conver(\"./Task1/annotated_conersations.jsonl\", \"closeness\", skips = [])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e31cf-71f1-4fdb-b865-2f8b37eca3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554617d6-e691-4d93-acd3-bd65c7e93cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Close</th>\n",
       "      <td>551</td>\n",
       "      <td>551</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Know each other</th>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Don't know each other</th>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. Don't like each other</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user  sys  nturn\n",
       "label                                     \n",
       "1. Close                   551  551    551\n",
       "2. Know each other         230  230    230\n",
       "3. Don't know each other   435  435    435\n",
       "4. Don't like each other     5    5      5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b648fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc25201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task2_conver(in_dir, col_label, skips=[]):\n",
    "    conversations = load_jsonl(f\"{in_dir}\")\n",
    "        \n",
    "    newdata = []\n",
    "    for row in conversations:\n",
    "        row[\"messages\"].sort(key=lambda x: x[\"created_at\"], reverse=False)\n",
    "        \n",
    "        users = {}\n",
    "        for m in row[\"messages\"]:\n",
    "            if m[\"user_id\"] not in users:\n",
    "#                 username = \"USR\"+str(len(users)+1) if len(users.keys())==0 else \"SYS\"\n",
    "                username = \"USR\" if len(users.keys())!=0 else \"SYS\"\n",
    "                users[m[\"user_id\"]] = username\n",
    "                \n",
    "        if len(users)>2:\n",
    "            print(\"More than 1 users\", len(users))\n",
    "        \n",
    "        \n",
    "        \n",
    "        messages = row[\"messages\"]\n",
    "        s = []\n",
    "        u = []\n",
    "        for m in messages:\n",
    "            text = m['text'].replace(\"[USR]\", \"\").replace(\"[URL]\", \"URL\")\n",
    "            if users[m['user_id']] == \"SYS\":\n",
    "                s.append(text)\n",
    "            else:\n",
    "                u.append(text)\n",
    "        \n",
    "        label = row[col_label]\n",
    "            \n",
    "        if pd.isna(label):\n",
    "            continue\n",
    "        \n",
    "        if label in skips:\n",
    "            continue\n",
    "                \n",
    "        newdata.append({\n",
    "            \"user\": u,\n",
    "            \"sys\": s,\n",
    "            \"label\": label,\n",
    "            \"nturn\": len(messages)\n",
    "        })\n",
    "                \n",
    "            \n",
    "    n_val = int(len(newdata)*0.1)\n",
    "    n_test = n_val\n",
    "    \n",
    "    test = newdata[0:n_test]\n",
    "    val = newdata[n_test:n_test+n_val]\n",
    "    train = newdata[n_test+n_val:]\n",
    "    \n",
    "    return pd.DataFrame(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b980cc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2463 records from ./Task2/annotated/annotated.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ แตงโม ชวนแฟนไปค่ะ ไม่ใช่กระติกชวนไป กลับไปหา...</td>\n",
       "      <td>[ทบทวน\\nงานคืนนั้น #กระติก ชวนแฟนพี่ตม.ไปด้วยน...</td>\n",
       "      <td>3. Not respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[   รูปนี้จ้า ยัยน้องตัวเล็กของพี่มิว☀️🌻\\n \\n#...</td>\n",
       "      <td>[เนื่ิองจากวันนี้...เป็นวันครบรอบ 3 ปี\\nมาเล่น...</td>\n",
       "      <td>1. Respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ แอบคิดเหมือนกัน้ลยค่ะว่าจะมีอีกรอบ]</td>\n",
       "      <td>[เธรดนี้จะมาวิเคราะห์น้ำท่วมปี54 ที่จริงมันอาจ...</td>\n",
       "      <td>2. Normal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ เนี่ยสิ่งที่กูพูด URL]</td>\n",
       "      <td>[มาดิ้นควยไรชองมึง\\nมึงอ่ะโชว์โง่ไอ้สัตว์ เสร่...</td>\n",
       "      <td>3. Not respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ สรุปปวินนี่บล็อกคนด้วยมั้ย?,  สรุป ที่น่าโมโ...</td>\n",
       "      <td>[แต่ปวินกับไพรวัลย์ก็ไม่เข้าใจนะเหมือนเจ้เกลีย...</td>\n",
       "      <td>2. Normal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [ แตงโม ชวนแฟนไปค่ะ ไม่ใช่กระติกชวนไป กลับไปหา...   \n",
       "1  [   รูปนี้จ้า ยัยน้องตัวเล็กของพี่มิว☀️🌻\\n \\n#...   \n",
       "2              [ แอบคิดเหมือนกัน้ลยค่ะว่าจะมีอีกรอบ]   \n",
       "3                           [ เนี่ยสิ่งที่กูพูด URL]   \n",
       "4  [ สรุปปวินนี่บล็อกคนด้วยมั้ย?,  สรุป ที่น่าโมโ...   \n",
       "\n",
       "                                                 sys           label  nturn  \n",
       "0  [ทบทวน\\nงานคืนนั้น #กระติก ชวนแฟนพี่ตม.ไปด้วยน...  3. Not respect      3  \n",
       "1  [เนื่ิองจากวันนี้...เป็นวันครบรอบ 3 ปี\\nมาเล่น...      1. Respect      3  \n",
       "2  [เธรดนี้จะมาวิเคราะห์น้ำท่วมปี54 ที่จริงมันอาจ...       2. Normal      3  \n",
       "3  [มาดิ้นควยไรชองมึง\\nมึงอ่ะโชว์โง่ไอ้สัตว์ เสร่...  3. Not respect      3  \n",
       "4  [แต่ปวินกับไพรวัลย์ก็ไม่เข้าใจนะเหมือนเจ้เกลีย...       2. Normal      5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task2_conver(\"./Task2/annotated/annotated.jsonl\", \"authority\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc1405-7676-4a1d-b2a7-894083116d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27de11af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Respect</th>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Normal</th>\n",
       "      <td>1403</td>\n",
       "      <td>1403</td>\n",
       "      <td>1403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Not respect</th>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user   sys  nturn\n",
       "label                            \n",
       "1. Respect       303   303    303\n",
       "2. Normal       1403  1403   1403\n",
       "3. Not respect   346   346    346"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27dfc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a566de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1221 records from ./Task3/annotated/annotated.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...</td>\n",
       "      <td>[ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...</td>\n",
       "      <td>[โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...</td>\n",
       "      <td>2. Know each other</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...</td>\n",
       "      <td>[อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...</td>\n",
       "      <td>2. Know each other</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...</td>\n",
       "      <td>[ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...</td>\n",
       "      <td>[ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...   \n",
       "1  [วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...   \n",
       "2  [เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...   \n",
       "3  [มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...   \n",
       "4  [อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...   \n",
       "\n",
       "                                                 sys               label  \\\n",
       "0  [ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...            1. Close   \n",
       "1  [โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...  2. Know each other   \n",
       "2  [อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...  2. Know each other   \n",
       "3  [ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...            1. Close   \n",
       "4  [ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...            1. Close   \n",
       "\n",
       "   nturn  \n",
       "0     35  \n",
       "1     39  \n",
       "2     40  \n",
       "3     35  \n",
       "4     39  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task1_conver(\"./Task3/annotated/annotated.jsonl\", \"closeness\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282e5a5b-4206-46bd-ae7f-604b8c24574a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Close</th>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Know each other</th>\n",
       "      <td>696</td>\n",
       "      <td>696</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Don't know each other</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. Don't like each other</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user  sys  nturn\n",
       "label                                     \n",
       "1. Close                   462  462    462\n",
       "2. Know each other         696  696    696\n",
       "3. Don't know each other    52   52     52\n",
       "4. Don't like each other    11   11     11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a42643-11c4-427c-b3c5-662a21a5af31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d21d30-3555-4593-919c-6f7581ac0a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8d78a46",
   "metadata": {},
   "source": [
    "## Load Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caafaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "755a8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./PrivateSpace/thai-dictionary/RoyalInstituteDictionary/words.json\", encoding=\"utf-8\") as fin:\n",
    "    raw = json.load(fin)\n",
    "    thaidict_royal = set()\n",
    "    for k in raw:\n",
    "        thaidict_royal.update(raw[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63a63c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25573 records from lexicons.jsonl\n"
     ]
    }
   ],
   "source": [
    "lexicons_arr = load_jsonl(\"lexicons.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bbccb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "tags = set()\n",
    "lexicons = {}\n",
    "lexicons_keys = defaultdict(list)\n",
    "\n",
    "for key, values  in lexicons_arr:\n",
    "    if len(key) <= 1:\n",
    "        continue\n",
    "        \n",
    "    key = key.lower()\n",
    "    if key.endswith(\"rep\"):\n",
    "        key = key.replace(\"rep\", \"\")\n",
    "        \n",
    "    w = word_tokenize(key)\n",
    "    \n",
    "    lexicons_keys[w[0]].append(key)\n",
    "    \n",
    "    tag = [t for t in values[\"tags\"] if not t.startswith(\"cat:\")]\n",
    "    lexicons[key] = tag\n",
    "    tags.update(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "320f0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.util import countthai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12380160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "388acee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "import emoji\n",
    "from pythainlp.util import countthai\n",
    "from tqdm import tqdm\n",
    "\n",
    "def rm_reptitive(text):\n",
    "    s = \"\"\n",
    "    groups = groupby(text)\n",
    "    for label, group in groups:\n",
    "        g = list(group)\n",
    "        if len(g) >= 3:\n",
    "            s += f\"{label*3} rep \"\n",
    "        else:\n",
    "            s += \"\".join(g)\n",
    "    return s\n",
    "\n",
    "def remove_space(sent):\n",
    "    newwords = []\n",
    "    for w in sent:\n",
    "        if len(w.strip())==0:\n",
    "            continue\n",
    "        newwords.append(w)\n",
    "    return newwords\n",
    "    \n",
    "def analyse_conv_per_person(texts):\n",
    "    \n",
    "    # Word Statistic\n",
    "    texts = [t.lower() for t in texts]\n",
    "    texts = [rm_reptitive(t) for t in texts]\n",
    "    words = [word_tokenize(t) for t in texts]\n",
    "    words = [remove_space(w) for w in words]\n",
    "    \n",
    "    nlongword = 0\n",
    "    ndict = 0\n",
    "    for sent in words:\n",
    "        ndict += sum([1 if w in thaidict_royal else 0 for w in sent])\n",
    "        nlongword += sum([1 if len(w) > 7 else 0 for w in sent])\n",
    "        nthai = sum([1 if countthai(w) > 50 else 0 for w in sent])\n",
    "        \n",
    "        \n",
    "    \n",
    "    uwords = set()\n",
    "    for sent in words:\n",
    "        uwords.update(sent)\n",
    "    \n",
    "    # Lexicon \n",
    "    lex = []\n",
    "    for sidx, sent in enumerate(words):\n",
    "        for widx, w in enumerate(sent):\n",
    "            if w not in lexicons_keys:\n",
    "                continue \n",
    "            \n",
    "            s = \"\".join(sent[widx:])\n",
    "            for l in lexicons_keys[w]:\n",
    "                if not s.startswith(l):\n",
    "                    continue\n",
    "\n",
    "                lex.extend(lexicons[l])\n",
    "#                 print(\">>\", w, l, lexicons[l])\n",
    "\n",
    "    lexcat = {}\n",
    "    for l in lex:\n",
    "        if l not in lexcat:\n",
    "            lexcat[l] = 0\n",
    "        lexcat[l] += 1\n",
    "    \n",
    "    # Stylistic words\n",
    "    nrepeat = 0\n",
    "    for sidx, sent in enumerate(words):\n",
    "        nrepeat += sum([1 if w==\"rep\" else 0 for w in sent])\n",
    "    \n",
    "    s = \" \".join(texts)\n",
    "    nemoji = emoji.emoji_count(s)\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"nsent\": len(texts),\n",
    "        \"nword\": sum([len(w) for w in words]),\n",
    "        \"ndict\": ndict,\n",
    "        \"nunique\": len(uwords),\n",
    "        \"nlongword\": nlongword,\n",
    "        \"nrepeat\": nrepeat,\n",
    "        \"nthai\": nthai,\n",
    "        \"nemoji\": nemoji,\n",
    "        **lexcat\n",
    "    }\n",
    "  \n",
    "\n",
    "\n",
    "def analyse_conversation(df):\n",
    "    metrics = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        ms = analyse_conv_per_person(row[\"sys\"])\n",
    "        mu = analyse_conv_per_person(row[\"user\"])\n",
    "        metrics.append((ms, mu))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "analyse_conv_per_person([\"เมิงงงงงงงมันโง่เหมือนควายยยยยยยยย\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28f22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e63519",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14df6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj_values(filepath, obj):\n",
    "  with open(filepath, 'wb') as fin:\n",
    "    pickle.dump(obj, fin)\n",
    "    \n",
    "def load_obj_values(filepath):\n",
    "  with open(filepath, 'rb') as fin:\n",
    "    obj = pickle.load(fin)\n",
    "  return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05a13ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_values = {\n",
    "    \"closeness\": [None, None, None],\n",
    "    \"authority\": [None, None, None],\n",
    "}\n",
    "\n",
    "analysis_labels = {\n",
    "    \"closeness\": [None, None, None],\n",
    "    \"authority\": [None, None, None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07ac4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_task1_conver(\"./Task1/annotated_conersations.jsonl\", \"closeness\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"closeness\"][0] = metrics\n",
    "# analysis_labels[\"closeness\"][0] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task2_conver(\"./Task2/annotated/annotated.jsonl\", \"closeness\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"closeness\"][1] = metrics\n",
    "# analysis_labels[\"closeness\"][1] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task1_conver(\"./Task3/annotated/annotated.jsonl\", \"closeness\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"closeness\"][2] = metrics\n",
    "# analysis_labels[\"closeness\"][2] = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe536b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_task1_conver(\"./Task1/annotated_conersations.jsonl\", \"authority\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"authority\"][0] = metrics\n",
    "# analysis_labels[\"authority\"][0] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task2_conver(\"./Task2/annotated/annotated.jsonl\", \"authority\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"authority\"][1] = metrics\n",
    "# analysis_labels[\"authority\"][1] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task1_conver(\"./Task3/annotated/annotated.jsonl\", \"authority\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"authority\"][2] = metrics\n",
    "# analysis_labels[\"authority\"][2] = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16fbe703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_obj_values(\"analysis_values.pkl\", analysis_values)\n",
    "# save_obj_values(\"analysis_labels.pkl\", analysis_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af1b2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_values = load_obj_values(\"analysis_values.pkl\")\n",
    "analysis_labels = load_obj_values(\"analysis_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d8bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff512b96",
   "metadata": {},
   "source": [
    "## Appendix C: Descriptive Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7098221",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = {\n",
    "    \"Word Statistics\" : {\n",
    "        \"nsent\": \"Number of utterance\",\n",
    "        \"nword\": \"Number of word\",\n",
    "    },\n",
    "    \"Lexicon Diversity\" : {\n",
    "        \"nunique\": \"Vocabulary size\",\n",
    "        \"nthai\": \"Thai words\",\n",
    "        \"nlongword\": \"Long words\",\n",
    "        \"ndict\": \"Dictionary words\"\n",
    "    },\n",
    "    \n",
    "    \"Function Words\": {\n",
    "\n",
    "        \"pronoun\": \"Pronoun\",\n",
    "        \"pronoun_1st\": \">> 1st person pronoun\",\n",
    "        \"pronoun_2nd\": \">> 2nd person pronoun\",\n",
    "        \"pronoun_3rd\": \">> 3rd person pronoun\",\n",
    "        \"pronoun_misspelling\": \">> Pronoun in non-standard spelling\",\n",
    "\n",
    "        \"particles\": \"Particles\",\n",
    "        \"particles_SARP\": \">> Socially-related particles\",\n",
    "        \"particles_notSARP\": \">> Non-socially-related particles\",\n",
    "        \"particles_misspelling\": \">> Particle in non-standard spelling\",\n",
    "    },\n",
    "    \n",
    "    \"Sentiment-related\": {\n",
    "    \n",
    "        \"sentiment\": \"Sentiment words\",\n",
    "        \"sentiment_positive\": \">> Positive words\",\n",
    "        \"sentiment_negative\": \">> Negative words\",\n",
    "    },\n",
    "    \n",
    "    \"Internet Lexicons\": {\n",
    "        \"misspelling\": \"Spelling variation\",\n",
    "        \"misspelling_common\": \">> Common misspelt words\",\n",
    "        \"misspelling_intention\": \">> Sematic variation\",\n",
    "        \"misspelling_shorten\": \">> Simplified variation\",\n",
    "        \"nrepeat\": \">> Repeated characters\",\n",
    "\n",
    "        \"abbr\": \"Abbreviation\",\n",
    "        \"slang\": \"Slang\",\n",
    "        \"swear\": \"Swear words\",\n",
    "        \"transliterated\": \"Transliteration\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaf894e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clse_print_labels = ['1. Close', '2. Know each other', \"3. Don't know each other\", \"4. Don't like each other\"]\n",
    "auth_print_labels = ['0. Very respect', '1. Respect', '2. Normal', '3. Not respect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ba33341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lexi_stat(analysis_values, analysis_labels, factor, setting, print_labels):\n",
    "    values = analysis_values[factor][setting]\n",
    "    labels = analysis_labels[factor][setting]\n",
    "    assert(len(values)==len(labels))\n",
    "    \n",
    "    printed_text = \"\"\n",
    "    rows = []\n",
    "    for (ms, mu), l in zip(values, labels):\n",
    "        for m in mu:\n",
    "            if m in [\"nsent\", \"nword\"]:\n",
    "                v = mu[m]\n",
    "            else:\n",
    "                v = mu[m]*100/mu[\"nword\"]\n",
    "                \n",
    "            rows.append({\n",
    "                \"label\": l,\n",
    "                \"metric\": m,\n",
    "                \"value\": v\n",
    "            })\n",
    "        \n",
    "        if \"particles_SARP\" in mu:\n",
    "            particles_notSARP = mu[\"particles\"] - mu[\"particles_SARP\"]\n",
    "            rows.append({\n",
    "                \"label\": l,\n",
    "                \"metric\": \"particles_notSARP\",\n",
    "                \"value\": particles_notSARP\n",
    "            })\n",
    "            \n",
    "    df = pd.DataFrame(rows).groupby([\"label\", \"metric\"]).mean().reset_index()\n",
    "    \n",
    "    for g in metric_names:\n",
    "        # print(\"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "        printed_text += \"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "        for m in metric_names[g]:\n",
    "            s = f\"{metric_names[g][m]} \"\n",
    "            for l in print_labels:\n",
    "                row = df[(df[\"label\"]==l) & (df[\"metric\"]==m)]\n",
    "#                 print(l, m)\n",
    "#                 print(df)\n",
    "                if len(row)!=0:\n",
    "                    s += f\"& {row['value'].values[0]:.2f} \"\n",
    "                else:\n",
    "                    s += f\"& - \"\n",
    "\n",
    "            s += \"\\\\\\\\\"\n",
    "            # print(s)\n",
    "            printed_text += \"    \"+s+\"\\n\"\n",
    "        \n",
    "        printed_text += \"    &  & &  & \\\\\\\\\"+\"\\n\"\n",
    "        printed_text += \"\\hline\"+\"\\n\"\n",
    "        \n",
    "        # print(\"&  & &  & \\\\\\\\\")\n",
    "        # print(\"\\hline\")\n",
    "    # print(printed_text)\n",
    "    return df, printed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e49d35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text1 = print_lexi_stat(analysis_values, analysis_labels, \"closeness\", 0, clse_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bd4031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text2 = print_lexi_stat(analysis_values, analysis_labels, \"authority\", 0, auth_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1066c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text3 = print_lexi_stat(analysis_values, analysis_labels, \"closeness\", 1, clse_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aec5617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text4 = print_lexi_stat(analysis_values, analysis_labels, \"authority\", 1, auth_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e702d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text5 = print_lexi_stat(analysis_values, analysis_labels, \"closeness\", 2, clse_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d6b6aed-8f23-44ec-8f65-8aa698cbabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(analysis_labels[\"authority\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81e5baab-871b-4647-a9cc-88819ca077c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text6 = print_lexi_stat(analysis_values, analysis_labels, \"authority\", 2, auth_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f05354e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\n",
    "    \"Setting 1: Private Conversations with Self-Reported Labels\",\n",
    "    \"Setting 2: Public Conversations with Labels from 3rd Party \",\n",
    "    \"Setting 3: Private Conversations with Labels from 3rd Party \",\n",
    "]\n",
    "\n",
    "table_contents = [\n",
    "    (printed_text1, printed_text2),\n",
    "    (printed_text3, printed_text4),\n",
    "    (printed_text5, printed_text6),\n",
    "]\n",
    "\n",
    "printed_text = \"\"\n",
    "for section, (t1, t2) in zip(sections, table_contents):\n",
    "    \n",
    "    printed_text += \"\\subsection{\"+section+\"}\"+\"\\n\\n\"\n",
    "    \n",
    "    printed_text += '''\\subsubsection{Closeness}\n",
    "\\\\begin{longtable}[h]{\n",
    "    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "}\n",
    "    \\hline\n",
    "\n",
    "    Linguistic Features & Close & Know each other & Don't know each other &  Don't like each other\\\\\\\\\n",
    "    \\hline\n",
    "    \\endfirsthead\n",
    "\n",
    "    \\endhead\n",
    "    '''\n",
    "    \n",
    "    printed_text += (\"\\n\"+t1).replace(\"\\n\", \"\\n    \")\n",
    "    printed_text += \"\\n\"\n",
    "    printed_text += \"\\end{longtable}\"\n",
    "    printed_text += \"\\n\\n\"\n",
    "\n",
    "    printed_text += '''\\clearpage\n",
    "\\subsubsection{Respect}\n",
    "\\\\begin{longtable}[h]{\n",
    "    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\n",
    "    p{\\dimexpr 0.16\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "}\n",
    "    \\hline\n",
    "\n",
    "    Linguistic Features & Very respect & Respect & Normal &  Not respect\\\\\\\\\n",
    "    \\hline\n",
    "    \\endfirsthead\n",
    "\n",
    "    \\endhead\n",
    "    '''\n",
    "    \n",
    "    printed_text += (\"\\n\"+t2).replace(\"\\n\", \"\\n    \")\n",
    "    printed_text += \"\\n\"\n",
    "    printed_text += \"\\end{longtable}\"\n",
    "    printed_text += \"\\n\\n\"\n",
    "    printed_text += \"\\clearpage\"\n",
    "    printed_text += \"\\n\\n\"\n",
    "    # break\n",
    "    \n",
    "# print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0566b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128a745-0d9e-4545-95f2-f2bbbe6df10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cad66f10",
   "metadata": {},
   "source": [
    "## Appendix D: Regression Analysis\n",
    "https://medium.com/@wyess/demystifying-statistical-analysis-3-the-one-way-anova-expressed-in-linear-regression-99269e84edd9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65d94022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def closeness_to_vec1(label):\n",
    "#     if label == \"1. Close\":\n",
    "#         return {\"x1\": 1, \"x2\": 0}\n",
    "#     elif label == \"2. Know each other\": ## Base category\n",
    "#         return {\"x1\": 0, \"x2\": 0}\n",
    "#     elif label == \"3. Don't know each other\": \n",
    "#         return {\"x1\": 0, \"x2\": 1}\n",
    "#     elif label == \"4. Don't like each other\":\n",
    "#         return None\n",
    "#     else:\n",
    "#         return None\n",
    "    \n",
    "# def authority_to_vec1(label):\n",
    "#     if label == '0. Very respect':\n",
    "#         return {\"x1\": 1, \"x2\": 0}\n",
    "#     elif label == '1. Respect': ## Base category\n",
    "#         return {\"x1\": 0, \"x2\": 0}\n",
    "#     elif label == '2. Normal':\n",
    "#         return {\"x1\": 0, \"x2\": 1}\n",
    "#     elif label == '3. Not respect':\n",
    "#         return None\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "def closeness_to_vec1(label):\n",
    "    if label == \"1. Close\":\n",
    "        return {\"x1\": 1, \"x2\": -1}\n",
    "    elif label == \"2. Know each other\":\n",
    "        return {\"x1\": 0, \"x2\": 2}\n",
    "    elif label == \"3. Don't know each other\": \n",
    "        return {\"x1\": -1, \"x2\": -1}\n",
    "    elif label == \"4. Don't like each other\":\n",
    "        return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def authority_to_vec1(label):\n",
    "    if label == '0. Very respect':\n",
    "        return {\"x1\": 1, \"x2\": -1}\n",
    "    elif label == '1. Respect': \n",
    "        return {\"x1\": 0, \"x2\": 2}\n",
    "    elif label == '2. Normal':\n",
    "        return {\"x1\": -1, \"x2\": -1}\n",
    "    elif label == '3. Not respect':\n",
    "        return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d08665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clse_coef_labels = [\"b\", \"a1\", \"a2\"]\n",
    "auth_coef_labels = [\"b\", 'a1', 'a2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85b93ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_features(analysis_values, analysis_labels, factor, setting, to_vec_func, skips=[]):\n",
    "    values = analysis_values[factor][setting]\n",
    "    labels = analysis_labels[factor][setting]\n",
    "    assert(len(values)==len(labels))\n",
    "    \n",
    "    rows = []\n",
    "    for (ms, mu), l in zip(values, labels):\n",
    "        if l in skips:\n",
    "            continue\n",
    "            \n",
    "        x = to_vec_func(l)\n",
    "        if x is None:\n",
    "            continue\n",
    "        \n",
    "        for m in mu:\n",
    "            if m in [\"nsent\", \"nword\"]:\n",
    "                v = mu[m]\n",
    "            else:\n",
    "                v = mu[m]*100/mu[\"nword\"]\n",
    "            \n",
    "            \n",
    "            rows.append({\n",
    "                \"metric\": m,\n",
    "                \"value\": v,\n",
    "                **x\n",
    "            })\n",
    "            \n",
    "        if \"particles_SARP\" in mu:\n",
    "            particles_notSARP = mu[\"particles\"] - mu[\"particles_SARP\"]\n",
    "            rows.append({\n",
    "                \"metric\": \"particles_notSARP\",\n",
    "                \"value\": particles_notSARP,\n",
    "                **x\n",
    "            })\n",
    "            \n",
    "    feats = pd.DataFrame(rows)  \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fceb9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "def print_anova_test(feats, n=3):\n",
    "    feat_names = feats[\"metric\"].unique()\n",
    "    \n",
    "    feat_important = []\n",
    "    for f in feat_names:\n",
    "        if \"cat:\" in f:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            d = feats[feats[\"metric\"]==f]\n",
    "        #     print(f, len(d))\n",
    "            x_columns = [f\"x{i+1}\" for i in range(n)]\n",
    "            X = d[x_columns]\n",
    "            X = sm.add_constant(X)\n",
    "            Y = d[\"value\"]\n",
    "            model = sm.OLS(Y,X)\n",
    "            results = model.fit()\n",
    "            \n",
    "            ncoef = n + 1\n",
    "            \n",
    "            t_test = results.t_test(np.identity(ncoef))\n",
    "            f_test = results.f_test(np.identity(ncoef))\n",
    "            o = {\"feat\": f, \"f_value\": f_test.pvalue}\n",
    "            for i in range(ncoef):\n",
    "                o[f\"coef{i}\"] = t_test.effect[i]\n",
    "                \n",
    "            for i in range(ncoef):\n",
    "                o[f\"pval{i}\"] = t_test.pvalue[i]\n",
    "                \n",
    "            feat_important.append(o)\n",
    "        except Exception as e:\n",
    "            print(\"error\", f, e)\n",
    "\n",
    "    outputs = pd.DataFrame(feat_important)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860eae70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b7e208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_weights(outputs, coef_labels, labels, base_category=None):\n",
    "    \n",
    "#     coefs = {}\n",
    "#     non_coefs = {}\n",
    "#     for i, label in enumerate(coef_labels):\n",
    "#         if i==0:\n",
    "#             continue\n",
    "            \n",
    "#         cond = outputs[f\"pval{i}\"] < 0.05\n",
    "#         for _, row in outputs[cond].sort_values(f\"coef{i}\", ascending=False).iterrows():\n",
    "#             coefs[(label, row[\"feat\"])] = row[f\"coef{i}\"]\n",
    "        \n",
    "#         cond = outputs[f\"pval{i}\"] >= 0.05\n",
    "#         for _, row in outputs[cond].iterrows():\n",
    "#             non_coefs[(label, row[\"feat\"])] = row[f\"coef{i}\"]\n",
    "\n",
    "# #     print(coefs)\n",
    "#     for g in metric_names:\n",
    "#         print(\"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "#         for m in metric_names[g]:\n",
    "#             s = f\"{metric_names[g][m]} \"\n",
    "#             for l in labels:\n",
    "#                 if l == base_category:\n",
    "#                     s += f\"& * \"\n",
    "#                 elif (l, m) in coefs:\n",
    "#                     val = coefs[(l, m)]\n",
    "#                     s += \"& \\cellcolor{gray!25} \"+f\"{val:.2f} \"\n",
    "#                 elif (l, m) in non_coefs:\n",
    "#                     val = non_coefs[(l, m)]\n",
    "#                     s += f\"& {val:.2f} \"\n",
    "#                 else:\n",
    "#                     s += f\"& - \"\n",
    "\n",
    "#             s += \"\\\\\\\\\"\n",
    "#             print(s)\n",
    "#         print(\"&  & &  & \\\\\\\\\")\n",
    "#         print(\"\\hline\")\n",
    "\n",
    "# # gray!25 < gray!50 < gray!80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "574751f3-cfd7-49fe-9bbd-bdfc44bf37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights(outputs):\n",
    "    \n",
    "    coefs = {}\n",
    "    coef_labels = [\"b\", \"a1\", \"a2\"]\n",
    "    for i, label in enumerate(coef_labels):\n",
    "        for _, row in outputs.iterrows():\n",
    "            coefs[(label, row[\"feat\"])] = (row[f\"coef{i}\"], row[f\"pval{i}\"])\n",
    "\n",
    "#     print(coefs)\n",
    "\n",
    "    printed_text = \"\"\n",
    "    for g in metric_names:\n",
    "        # print(\"\\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "        printed_text += \"\\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "        for m in metric_names[g]:\n",
    "            s = f\"{metric_names[g][m]} \"\n",
    "            for l in coef_labels:                    \n",
    "                val, pval = coefs[(l, m)]\n",
    "                if l==\"b\":\n",
    "                    s += f\"& {val:.2f} \"\n",
    "                elif pval < 0.05:\n",
    "                    s += \"& \\cellcolor{gray!25} \"+f\"{val:.2f} \"\n",
    "                else:\n",
    "                    s += f\"& {val:.2f} \"\n",
    "            s += \"\\\\\\\\\"\n",
    "            # print(s)\n",
    "            printed_text += s+\"\\n\"\n",
    "        printed_text += \"&  & &\\\\\\\\\" + \"\\n\"\n",
    "        printed_text += \"\\hline\" + \"\\n\"\n",
    "        # print(\"&  & &\\\\\\\\\")\n",
    "        # print(\"\\hline\")\n",
    "    return printed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123595e1-f763-455a-87a6-62bc1fc253fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f82a11-1c8c-45b6-8b02-1a05e1563a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11badd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 0, closeness_to_vec1, skips=[])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# print_weights(outputs, clse_coef_labels, clse_print_labels, \"2. Know each other\")\n",
    "printed_text1 = print_weights(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50750d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 0, authority_to_vec1, skips=[\"3. Not respect\"])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# print_weights(outputs, auth_coef_labels, auth_print_labels, \"1. Respect\")\n",
    "printed_text2 = print_weights(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366bdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a18a5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def closeness_to_vec2(label):\n",
    "#     if label == \"1. Close\":\n",
    "#         return {\"x1\": 1, \"x2\": 0}\n",
    "#     elif label == \"2. Know each other\": \n",
    "#         return {\"x1\": 1, \"x2\": 0}\n",
    "#     elif label == \"3. Don't know each other\": ## Base category\n",
    "#         return {\"x1\": 0, \"x2\": 0}\n",
    "#     elif label == \"4. Don't like each other\":\n",
    "#         return {\"x1\": 0, \"x2\": 1}\n",
    "#     else:\n",
    "#         return None\n",
    "    \n",
    "# def authority_to_vec2(label):\n",
    "#     if label == '0. Very respect':\n",
    "#         return None\n",
    "#     elif label == '1. Respect': \n",
    "#         return {\"x1\": 1, \"x2\": 0}\n",
    "#     elif label == '2. Normal': ## Base category\n",
    "#         return {\"x1\": 0, \"x2\": 0}\n",
    "#     elif label == '3. Not respect':\n",
    "#         return {\"x1\": 0, \"x2\": 1}\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "def closeness_to_vec2(label):\n",
    "    if label == \"1. Close\":\n",
    "        return {\"x1\": 1, \"x2\": -1}\n",
    "    elif label == \"2. Know each other\": \n",
    "        return {\"x1\": 0, \"x2\": 2}\n",
    "    elif label == \"3. Don't know each other\": ## Base category\n",
    "        return {\"x1\": -1, \"x2\": 1}\n",
    "    elif label == \"4. Don't like each other\":\n",
    "        return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def authority_to_vec2(label):\n",
    "    if label == '0. Very respect':\n",
    "        return None\n",
    "    elif label == '1. Respect': \n",
    "        return {\"x1\": 1, \"x2\": -1}\n",
    "    elif label == '2. Normal': ## Base category\n",
    "        return {\"x1\": 0, \"x2\": 2}\n",
    "    elif label == '3. Not respect':\n",
    "        return {\"x1\": -1, \"x2\": -1}\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eeb1c491-f902-4174-b929-bb29eed0a5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error particles_?? wrong shape for coefs\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 1, closeness_to_vec2)\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# clse_coef_labels = [\"b\", \"2. Know each other\", \"4. Don't like each other\"]\n",
    "# print_weights(outputs, clse_coef_labels, clse_print_labels, \"3. Don't know each other\")\n",
    "printed_text3 = print_weights(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "987c34d3-bd59-41d5-985e-299161b6d308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error particles_?? wrong shape for coefs\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 1, authority_to_vec2)\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# auth2_coef_labels = [\"b\", '1. Respect', '3. Not respect']\n",
    "# print_weights(outputs, auth2_coef_labels, auth_print_labels, \"2. Normal\")\n",
    "printed_text4 = print_weights(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1d045e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "550f18a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imtk/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/Users/imtk/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 2, closeness_to_vec2, skips=[])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# print_weights(outputs, clse_coef_labels, clse_print_labels, \"2. Know each other\")\n",
    "printed_text5 = print_weights(outputs)\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 2, authority_to_vec2, skips=[])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# print_weights(outputs, auth_coef_labels, auth_print_labels, \"1. Respect\")\n",
    "printed_text6 = print_weights(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9cedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1bd0f30-6750-4e6d-a1fc-60717f9b2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections = [\n",
    "#     \"Setting 1: Private Conversations with Self-Reported Labels\",\n",
    "#     \"Setting 2: Public Conversations with Labels from 3rd Party \",\n",
    "#     \"Setting 3: Private Conversations with Labels from 3rd Party \",\n",
    "# ]\n",
    "\n",
    "# table_contents = [\n",
    "#     (printed_text1, printed_text2),\n",
    "#     (printed_text3, printed_text4),\n",
    "#     (printed_text5, printed_text6),\n",
    "# ]\n",
    "\n",
    "# printed_text = \"\"\n",
    "# for section, (t1, t2) in zip(sections, table_contents):\n",
    "    \n",
    "#     printed_text += \"\\subsection{\"+section+\"}\"+\"\\n\\n\"\n",
    "    \n",
    "#     printed_text += '''\\subsubsection{Closeness}\n",
    "# \\\\begin{longtable}[h]{\n",
    "#     p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|c|c|c\n",
    "# }\n",
    "#     \\hline\n",
    "\n",
    "#     Lexical Features & b & a1 & a2 \\\\\\\\\n",
    "#     \\hline\n",
    "#     \\endfirsthead\n",
    "\n",
    "#     \\endhead\n",
    "#     '''\n",
    "    \n",
    "#     printed_text += (\"\\n\"+t1).replace(\"\\n\", \"\\n    \")\n",
    "#     printed_text += \"\\n\"\n",
    "#     printed_text += \"\\end{longtable}\"\n",
    "#     printed_text += \"\\n\\n\"\n",
    "\n",
    "#     printed_text += '''\\clearpage\n",
    "# \\subsubsection{Respect}\n",
    "# \\\\begin{longtable}[h]{\n",
    "#     p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|c|c|c\n",
    "# }\n",
    "#     \\hline\n",
    "\n",
    "#     Lexical Features & b & a1 & a2 \\\\\\\\\n",
    "#     \\hline\n",
    "#     \\endfirsthead\n",
    "\n",
    "#     \\endhead\n",
    "#     '''\n",
    "    \n",
    "#     printed_text += (\"\\n\"+t2).replace(\"\\n\", \"\\n    \")\n",
    "#     printed_text += \"\\n\"\n",
    "#     printed_text += \"\\end{longtable}\"\n",
    "#     printed_text += \"\\n\\n\"\n",
    "    \n",
    "#     printed_text += \"\\clearpage\"\n",
    "#     printed_text += \"\\n\\n\"\n",
    "#     # break\n",
    "    \n",
    "# print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d391969-05f1-43d4-ba90-8eac82bc0c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7a88e-1efd-49c2-a577-7911b4e97529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46a1405-2b91-495b-b7c9-c393c8816fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d074d8d-640b-442a-9dc0-498d1313e900",
   "metadata": {},
   "source": [
    "## Appendix D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c32a6648-fa5d-4398-8de5-daae33257db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeness_to_vec_effect(label):\n",
    "    if label == \"1. Close\":\n",
    "        return {\"x1\": 1, \"x2\": 0}\n",
    "    elif label == \"2. Know each other\": ## Base category\n",
    "        return {\"x1\": -1, \"x2\": -1}\n",
    "    elif label == \"3. Don't know each other\": \n",
    "        return {\"x1\": 0, \"x2\": 1}\n",
    "    elif label == \"4. Don't like each other\":\n",
    "        return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def authority_to_vec_effect(label):\n",
    "    if label == '0. Very respect':\n",
    "        return {\"x1\": 1, \"x2\": 0}\n",
    "    elif label == '1. Respect': \n",
    "        return {\"x1\": 0, \"x2\": 1}\n",
    "    elif label == '2. Normal':    ## Base category\n",
    "        return {\"x1\": -1, \"x2\": -1}\n",
    "    elif label == '3. Not respect':\n",
    "        # return None\n",
    "        return {\"x1\": 1, \"x2\": 0}\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "afbdeaca-b972-4eca-8be4-f7ab964cfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights_effect(outputs, coef_labels):\n",
    "    coefs = {}\n",
    "    for i, label in coef_labels.items():\n",
    "        if i is None:\n",
    "            continue\n",
    "            \n",
    "        for _, row in outputs.iterrows():\n",
    "            coefs[(label, row[\"feat\"])] = (row[f\"coef{i}\"], row[f\"pval{i}\"])\n",
    "\n",
    "    printed_text = \"\"\n",
    "    for g in metric_names:\n",
    "        # print(\"\\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "        printed_text += \"\\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "        for m in metric_names[g]:\n",
    "            s = f\"{metric_names[g][m]} \"\n",
    "            for i, l in coef_labels.items():                    \n",
    "                if i is None:\n",
    "                    s += f\"& * \"\n",
    "                    continue\n",
    "                \n",
    "                val, pval = coefs[(l, m)]\n",
    "                if l==\"Grand Mean\":\n",
    "                    s += f\"& {val:.2f} \"\n",
    "                elif pval < 0.05:\n",
    "                    s += \"& \\cellcolor{gray!25} \"+f\"{val:.2f} \"\n",
    "                else:\n",
    "                    s += f\"& {val:.2f} \"\n",
    "            s += \"\\\\\\\\\"\n",
    "            # print(s)\n",
    "            printed_text += s+\"\\n\"\n",
    "        printed_text += \"&  & &\\\\\\\\\" + \"\\n\"\n",
    "        printed_text += \"\\hline\" + \"\\n\"\n",
    "        # print(\"&  & &\\\\\\\\\")\n",
    "        # print(\"\\hline\")\n",
    "    return printed_text, coef_labels\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 0, closeness_to_vec_effect, skips=[])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "# [\"Grand Mean\", \"0. Very respect\", \"1. Respect\", \"\", \"3. Not respect\"], \"2. Normal\"\n",
    "\n",
    "coef_labels = {0:\"Grand Mean\", 1: \"Close\", None: \"Know each other\", 2: \"Don't know each other\"}\n",
    "printed_text1 = print_weights_effect(outputs, coef_labels)\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 0, authority_to_vec_effect, skips=[\"3. Not respect\"])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "\n",
    "coef_labels = {0:\"Grand Mean\", 1: \"Very respect\", 2: \"Respect\", None: \"Normal\"}\n",
    "printed_text2 = print_weights_effect(outputs, coef_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "96b3b6bd-54cb-46b6-85c4-a5c9649342e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error particles_?? wrong shape for coefs\n",
      "error particles_?? wrong shape for coefs\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 1, closeness_to_vec_effect, skips=[])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "coef_labels = {0:\"Grand Mean\", 1: \"Close\", None: \"Know each other\", 2: \"Don't know each other\"}\n",
    "printed_text3 = print_weights_effect(outputs, coef_labels)\n",
    "\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 1, authority_to_vec_effect, skips=[\"0. Very respect\"])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "coef_labels = {0:\"Grand Mean\", None: \"Normal\", 2: \"Respect\", 1: \"Not respect\"}\n",
    "printed_text4 = print_weights_effect(outputs, coef_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4d32ca6d-47e1-45b9-890f-f4e3842c9d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imtk/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/Users/imtk/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 2\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 2, closeness_to_vec_effect, skips=[])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "coef_labels = {0:\"Grand Mean\", 1: \"Close\", None: \"Know each other\", 2: \"Don't know each other\"}\n",
    "printed_text5 = print_weights_effect(outputs, coef_labels)\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 2, authority_to_vec_effect, skips=[\"0. Very respect\"])\n",
    "outputs = print_anova_test(feats, n=2)\n",
    "coef_labels = {0:\"Grand Mean\", None: \"Normal\", 2: \"Respect\", 1: \"Not respect\"}\n",
    "printed_text6 = print_weights_effect(outputs, coef_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "76969f31-4866-4638-af6b-9ac3fe37cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats[feats[\"metric\"]==\"nsent\"].groupby([\"x1\", \"x2\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aaeda7c3-d475-4738-a743-69363387a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections = [\n",
    "#     \"Setting 1: Private Conversations with Self-Reported Labels\",\n",
    "#     \"Setting 2: Public Conversations with Labels from 3rd Party \",\n",
    "#     \"Setting 3: Private Conversations with Labels from 3rd Party \",\n",
    "# ]\n",
    "\n",
    "# table_contents = [\n",
    "#     (printed_text1, printed_text2),\n",
    "#     (printed_text3, printed_text4),\n",
    "#     (printed_text5, printed_text6),\n",
    "# ]\n",
    "\n",
    "# # columns = \n",
    "# # ([\"Grand Mean\", \"1. Close\", \"2. Know each other\", \"3. Don't know each other\"], \"2. Know each other\")\n",
    "\n",
    "# # [\"Grand Mean\", \"0. Very respect\", \"1. Respect\", \"2. Normal\", \"3. Not respect\"], \"2. Normal\"\n",
    "\n",
    "# printed_text = \"\"\n",
    "# for section, (v1, v2) in zip(sections, table_contents):\n",
    "    \n",
    "#     printed_text += \"\\subsection{\"+section+\"}\"+\"\\n\\n\"\n",
    "    \n",
    "#     printed_text += '''\\subsubsection{Closeness}\n",
    "# \\\\begin{longtable}[h]{\n",
    "#     p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "# }\n",
    "#     \\hline\n",
    "#     '''\n",
    "    \n",
    "#     t1, col1 = v1\n",
    "#     printed_text += \"Lexical Features & \" + \" & \".join(col1.values()) + \"\\\\\\\\\"\n",
    "        \n",
    "#     printed_text +='''\n",
    "#     \\hline\n",
    "#     \\endfirsthead\n",
    "\n",
    "#     \\endhead\n",
    "#     '''\n",
    "\n",
    "    \n",
    "#     printed_text += (\"\\n\"+t1).replace(\"\\n\", \"\\n    \")\n",
    "#     printed_text += \"\\n\"\n",
    "#     printed_text += \"\\end{longtable}\"\n",
    "#     printed_text += \"\\n\\n\"\n",
    "\n",
    "    \n",
    "#     printed_text += '''\\clearpage\n",
    "# \\subsubsection{Respect}\n",
    "# \\\\begin{longtable}[h]{\n",
    "#     p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "#     p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "# }\n",
    "#     \\hline\n",
    "#     '''\n",
    "\n",
    "#     t2, col2 = v2\n",
    "    \n",
    "#     printed_text += \"Lexical Features & \" + \" & \".join(col2.values()) + \"\\\\\\\\\"\n",
    "        \n",
    "#     printed_text +='''\n",
    "#     \\hline\n",
    "#     \\endfirsthead\n",
    "\n",
    "#     \\endhead\n",
    "#     '''\n",
    "    \n",
    "#     printed_text += (\"\\n\"+t2).replace(\"\\n\", \"\\n    \")\n",
    "#     printed_text += \"\\n\"\n",
    "#     printed_text += \"\\end{longtable}\"\n",
    "#     printed_text += \"\\n\\n\"\n",
    "    \n",
    "#     printed_text += \"\\clearpage\"\n",
    "#     printed_text += \"\\n\\n\"\n",
    "#     # break\n",
    "    \n",
    "# print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3265f4a8-30e3-4152-a72c-b87a3a87f49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79a59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8acd686",
   "metadata": {},
   "source": [
    "## Appendix E: Linear Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e232280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import datasets, linear_model\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# import statsmodels.api as sm\n",
    "# from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9b1acc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_linear_features(analysis_values, analysis_labels, factor, setting):\n",
    "#     values = analysis_values[factor][setting]\n",
    "#     labels = analysis_labels[factor][setting]\n",
    "#     assert(len(values)==len(labels))\n",
    "    \n",
    "#     rows = []\n",
    "#     for (ms, mu), l in zip(values, labels):\n",
    "        \n",
    "#         o = {\"label\": l, \"bias\": 1}\n",
    "#         for m in mu:\n",
    "#             if m in [\"nsent\", \"nword\"]:\n",
    "#                 v = mu[m]\n",
    "#             else:\n",
    "#                 v = mu[m]*100/mu[\"nword\"]\n",
    "            \n",
    "#             o[m] = v\n",
    "#         rows.append(o)\n",
    "        \n",
    "#     feats = pd.DataFrame(rows).fillna(0)  \n",
    "#     return feats\n",
    "\n",
    "\n",
    "\n",
    "# def run_linear_model(feats, skips=[]):\n",
    "#     col = []\n",
    "#     for g in metric_names:\n",
    "#         for m in metric_names[g]:\n",
    "#             if m in [\"nsent\", \"nword\"]:\n",
    "#                 continue\n",
    "                \n",
    "#             col.append(m)\n",
    "    \n",
    "#     X = feats[col].values\n",
    "\n",
    "#     saved_results = {}\n",
    "#     for label in labels:\n",
    "#         if label in skips:\n",
    "#             continue\n",
    "        \n",
    "#         print(label)\n",
    "#         Y = (feats[\"label\"]==label).astype(int)\n",
    "#         model = sm.Logit(Y, X)\n",
    "#         result = model.fit()\n",
    "# #         print(result.summary())\n",
    "#         ncoef = len(col)\n",
    "#         t_test = result.t_test(np.identity(ncoef))\n",
    "        \n",
    "# #         print(t_test.tvalue) #Z\n",
    "# #         print(t_test.pvalue) #p-value\n",
    "# #         print(t_test.effect) #coef\n",
    "\n",
    "#         for f, coef, pvalue in zip(feats, t_test.effect, t_test.pvalue):\n",
    "#             saved_results[(label, f)] = (coef, pvalue)\n",
    "#     return saved_results\n",
    "\n",
    "# def print_linear_weights(weights, labels, skips=[]):\n",
    "#     for g in metric_names:\n",
    "#         print(\"\\multicolumn{\"+str(len(labels)+1)+\"}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "#         for m in metric_names[g]:\n",
    "#             if m in [\"nwordputterance\", \"nsent\", \"nword\"]:\n",
    "#                 continue\n",
    "                \n",
    "#             s = f\"{metric_names[g][m]} \"\n",
    "#             for l in labels:\n",
    "#                 if l in skips:\n",
    "#                     s += f\"& - \"\n",
    "#                     continue\n",
    "                \n",
    "#                 if (l, m) not in weights:\n",
    "#                     s += f\"& - \"\n",
    "#                     continue\n",
    "                    \n",
    "#                 val, pvalue = weights[(l, m)]\n",
    "#                 if pvalue < 0.05:\n",
    "#                     s += \"& \\cellcolor{gray!25} \"+f\"{val:.3f} \"\n",
    "#                 else:\n",
    "#                     s += f\"& {val:.3f} \"\n",
    "\n",
    "#             s += \"\\\\\\\\\"\n",
    "#             print(s)\n",
    "#         print(\"&  & &  & \\\\\\\\\")\n",
    "#         print(\"\\hline\")\n",
    "        \n",
    "#     return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "bab11900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = to_linear_features(analysis_values, analysis_labels, \"closeness\", 0)\n",
    "# weights = run_linear_model(feats, skips=[\"4. Don't like each other\"])\n",
    "# print_linear_weights(weights, clse_print_labels, skips=[\"4. Don't like each other\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "46fd7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = to_linear_features(analysis_values, analysis_labels, \"authority\", 0)\n",
    "# weights = run_linear_model(feats, skips=[\"3. Not respect\"])\n",
    "# print_linear_weights(weights, auth_print_labels, skips=[\"3. Not respect\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ce27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
