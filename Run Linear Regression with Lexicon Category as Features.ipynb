{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1877f9b4",
   "metadata": {},
   "source": [
    "## Load Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93deeee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "import pandas as pd\n",
    "from utils import load_jsonl, dump_jsonl\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87c53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79f99623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task1_conver(in_dir, col_label, skips=[]):\n",
    "    conversations = load_jsonl(f\"{in_dir}\")\n",
    "    \n",
    "    \n",
    "    def to_message_str(messages, users):\n",
    "        s = []\n",
    "        u = []\n",
    "        for m in messages:\n",
    "            if users[m['user_id']] == \"SYS\":\n",
    "                s.append(m['text'])\n",
    "            else:\n",
    "                u.append(m['text'])\n",
    "                \n",
    "        return s, u\n",
    "        \n",
    "    newdata = []\n",
    "    for row in conversations:\n",
    "        row[\"messages\"].sort(key=lambda x: x[\"date_created\"], reverse=False)\n",
    "        \n",
    "        users = {}\n",
    "        for m in row[\"messages\"]:\n",
    "            if m[\"user_id\"] not in users:\n",
    "#                 username = \"USR\"+str(len(users)+1) if len(users.keys())==0 else \"SYS\"\n",
    "                username = \"USR\" if len(users.keys())==0 else \"SYS\"\n",
    "                users[m[\"user_id\"]] = username\n",
    "                \n",
    "#         if len(users)>2:\n",
    "#             print(\"More than 1 users\", len(users))\n",
    "        \n",
    "        \n",
    "        messages = row[\"messages\"]\n",
    "        chunk_size = 100\n",
    "        for i in range(0, len(messages), chunk_size):\n",
    "            sub_messages = messages[i:i+chunk_size]\n",
    "            s, u = to_message_str(sub_messages, users)\n",
    "            \n",
    "            if pd.isna(row[col_label]):\n",
    "                continue\n",
    "            \n",
    "            if row[col_label] in skips:\n",
    "                continue\n",
    "                \n",
    "            label = row[col_label]\n",
    "                \n",
    "            newdata.append({\n",
    "                \"user\": u,\n",
    "                \"sys\": s,\n",
    "                \"label\": label,\n",
    "                \"nturn\": len(sub_messages)\n",
    "            })\n",
    "        \n",
    "#     n_val = int(len(newdata)*0.05)\n",
    "#     n_test = n_val\n",
    "    \n",
    "#     test = newdata[0:n_test]\n",
    "#     val = newdata[n_test:n_test+n_val]\n",
    "#     train = newdata[n_test+n_val:]\n",
    "    \n",
    "    return pd.DataFrame(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92feb049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1234 records from ./Task1/annotated_conersations.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...</td>\n",
       "      <td>[ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...</td>\n",
       "      <td>[โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...</td>\n",
       "      <td>[อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...</td>\n",
       "      <td>[ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...</td>\n",
       "      <td>[ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...   \n",
       "1  [วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...   \n",
       "2  [เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...   \n",
       "3  [มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...   \n",
       "4  [อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...   \n",
       "\n",
       "                                                 sys     label  nturn  \n",
       "0  [ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...  1. Close     35  \n",
       "1  [โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...  1. Close     39  \n",
       "2  [อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...  1. Close     40  \n",
       "3  [ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...  1. Close     35  \n",
       "4  [ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...  1. Close     39  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task1_conver(\"./Task1/annotated_conersations.jsonl\", \"closeness\", skips = [])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e31cf-71f1-4fdb-b865-2f8b37eca3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "554617d6-e691-4d93-acd3-bd65c7e93cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Close</th>\n",
       "      <td>551</td>\n",
       "      <td>551</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Know each other</th>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Don't know each other</th>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. Don't like each other</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user  sys  nturn\n",
       "label                                     \n",
       "1. Close                   551  551    551\n",
       "2. Know each other         230  230    230\n",
       "3. Don't know each other   435  435    435\n",
       "4. Don't like each other     5    5      5"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b648fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc25201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task2_conver(in_dir, col_label, skips=[]):\n",
    "    conversations = load_jsonl(f\"{in_dir}\")\n",
    "        \n",
    "    newdata = []\n",
    "    for row in conversations:\n",
    "        row[\"messages\"].sort(key=lambda x: x[\"created_at\"], reverse=False)\n",
    "        \n",
    "        users = {}\n",
    "        for m in row[\"messages\"]:\n",
    "            if m[\"user_id\"] not in users:\n",
    "#                 username = \"USR\"+str(len(users)+1) if len(users.keys())==0 else \"SYS\"\n",
    "                username = \"USR\" if len(users.keys())!=0 else \"SYS\"\n",
    "                users[m[\"user_id\"]] = username\n",
    "                \n",
    "        if len(users)>2:\n",
    "            print(\"More than 1 users\", len(users))\n",
    "        \n",
    "        \n",
    "        \n",
    "        messages = row[\"messages\"]\n",
    "        s = []\n",
    "        u = []\n",
    "        for m in messages:\n",
    "            text = m['text'].replace(\"[USR]\", \"\").replace(\"[URL]\", \"URL\")\n",
    "            if users[m['user_id']] == \"SYS\":\n",
    "                s.append(text)\n",
    "            else:\n",
    "                u.append(text)\n",
    "        \n",
    "        label = row[col_label]\n",
    "            \n",
    "        if pd.isna(label):\n",
    "            continue\n",
    "        \n",
    "        if label in skips:\n",
    "            continue\n",
    "                \n",
    "        newdata.append({\n",
    "            \"user\": u,\n",
    "            \"sys\": s,\n",
    "            \"label\": label,\n",
    "            \"nturn\": len(messages)\n",
    "        })\n",
    "                \n",
    "            \n",
    "    n_val = int(len(newdata)*0.1)\n",
    "    n_test = n_val\n",
    "    \n",
    "    test = newdata[0:n_test]\n",
    "    val = newdata[n_test:n_test+n_val]\n",
    "    train = newdata[n_test+n_val:]\n",
    "    \n",
    "    return pd.DataFrame(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b980cc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2486 records from ./Task2/annotated/annotated.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ แตงโม ชวนแฟนไปค่ะ ไม่ใช่กระติกชวนไป กลับไปหา...</td>\n",
       "      <td>[ทบทวน\\nงานคืนนั้น #กระติก ชวนแฟนพี่ตม.ไปด้วยน...</td>\n",
       "      <td>3. Not respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[   รูปนี้จ้า ยัยน้องตัวเล็กของพี่มิว☀️🌻\\n \\n#...</td>\n",
       "      <td>[เนื่ิองจากวันนี้...เป็นวันครบรอบ 3 ปี\\nมาเล่น...</td>\n",
       "      <td>1. Respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ แอบคิดเหมือนกัน้ลยค่ะว่าจะมีอีกรอบ]</td>\n",
       "      <td>[เธรดนี้จะมาวิเคราะห์น้ำท่วมปี54 ที่จริงมันอาจ...</td>\n",
       "      <td>2. Normal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ เนี่ยสิ่งที่กูพูด URL]</td>\n",
       "      <td>[มาดิ้นควยไรชองมึง\\nมึงอ่ะโชว์โง่ไอ้สัตว์ เสร่...</td>\n",
       "      <td>3. Not respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ สรุปปวินนี่บล็อกคนด้วยมั้ย?,  สรุป ที่น่าโมโ...</td>\n",
       "      <td>[แต่ปวินกับไพรวัลย์ก็ไม่เข้าใจนะเหมือนเจ้เกลีย...</td>\n",
       "      <td>2. Normal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [ แตงโม ชวนแฟนไปค่ะ ไม่ใช่กระติกชวนไป กลับไปหา...   \n",
       "1  [   รูปนี้จ้า ยัยน้องตัวเล็กของพี่มิว☀️🌻\\n \\n#...   \n",
       "2              [ แอบคิดเหมือนกัน้ลยค่ะว่าจะมีอีกรอบ]   \n",
       "3                           [ เนี่ยสิ่งที่กูพูด URL]   \n",
       "4  [ สรุปปวินนี่บล็อกคนด้วยมั้ย?,  สรุป ที่น่าโมโ...   \n",
       "\n",
       "                                                 sys           label  nturn  \n",
       "0  [ทบทวน\\nงานคืนนั้น #กระติก ชวนแฟนพี่ตม.ไปด้วยน...  3. Not respect      3  \n",
       "1  [เนื่ิองจากวันนี้...เป็นวันครบรอบ 3 ปี\\nมาเล่น...      1. Respect      3  \n",
       "2  [เธรดนี้จะมาวิเคราะห์น้ำท่วมปี54 ที่จริงมันอาจ...       2. Normal      3  \n",
       "3  [มาดิ้นควยไรชองมึง\\nมึงอ่ะโชว์โง่ไอ้สัตว์ เสร่...  3. Not respect      3  \n",
       "4  [แต่ปวินกับไพรวัลย์ก็ไม่เข้าใจนะเหมือนเจ้เกลีย...       2. Normal      5  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task2_conver(\"./Task2/annotated/annotated.jsonl\", \"authority\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc1405-7676-4a1d-b2a7-894083116d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27de11af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Respect</th>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Normal</th>\n",
       "      <td>1661</td>\n",
       "      <td>1661</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Not respect</th>\n",
       "      <td>364</td>\n",
       "      <td>364</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user   sys  nturn\n",
       "label                            \n",
       "1. Respect       319   319    319\n",
       "2. Normal       1661  1661   1661\n",
       "3. Not respect   364   364    364"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27dfc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a566de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1221 records from ./Task3/annotated/annotated.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...</td>\n",
       "      <td>[ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...</td>\n",
       "      <td>[โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...</td>\n",
       "      <td>2. Know each other</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...</td>\n",
       "      <td>[อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...</td>\n",
       "      <td>2. Know each other</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...</td>\n",
       "      <td>[ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...</td>\n",
       "      <td>[ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...   \n",
       "1  [วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...   \n",
       "2  [เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...   \n",
       "3  [มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...   \n",
       "4  [อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...   \n",
       "\n",
       "                                                 sys               label  \\\n",
       "0  [ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...            1. Close   \n",
       "1  [โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...  2. Know each other   \n",
       "2  [อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...  2. Know each other   \n",
       "3  [ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...            1. Close   \n",
       "4  [ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...            1. Close   \n",
       "\n",
       "   nturn  \n",
       "0     35  \n",
       "1     39  \n",
       "2     40  \n",
       "3     35  \n",
       "4     39  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task1_conver(\"./Task3/annotated/annotated.jsonl\", \"closeness\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "282e5a5b-4206-46bd-ae7f-604b8c24574a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Close</th>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Know each other</th>\n",
       "      <td>696</td>\n",
       "      <td>696</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Don't know each other</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. Don't like each other</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user  sys  nturn\n",
       "label                                     \n",
       "1. Close                   462  462    462\n",
       "2. Know each other         696  696    696\n",
       "3. Don't know each other    52   52     52\n",
       "4. Don't like each other    11   11     11"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a42643-11c4-427c-b3c5-662a21a5af31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d21d30-3555-4593-919c-6f7581ac0a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8d78a46",
   "metadata": {},
   "source": [
    "## Load Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "caafaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "755a8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./PrivateSpace/thai-dictionary/RoyalInstituteDictionary/words.json\", encoding=\"utf-8\") as fin:\n",
    "    raw = json.load(fin)\n",
    "    thaidict_royal = set()\n",
    "    for k in raw:\n",
    "        thaidict_royal.update(raw[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "63a63c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25573 records from lexicons.jsonl\n"
     ]
    }
   ],
   "source": [
    "lexicons_arr = load_jsonl(\"lexicons.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1bbccb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "tags = set()\n",
    "lexicons = {}\n",
    "lexicons_keys = defaultdict(list)\n",
    "\n",
    "for key, values  in lexicons_arr:\n",
    "    if len(key) <= 1:\n",
    "        continue\n",
    "        \n",
    "    key = key.lower()\n",
    "    if key.endswith(\"rep\"):\n",
    "        key = key.replace(\"rep\", \"\")\n",
    "        \n",
    "    w = word_tokenize(key)\n",
    "    \n",
    "    lexicons_keys[w[0]].append(key)\n",
    "    \n",
    "    tag = [t for t in values[\"tags\"] if not t.startswith(\"cat:\")]\n",
    "    lexicons[key] = tag\n",
    "    tags.update(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "320f0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.util import countthai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12380160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "388acee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "import emoji\n",
    "from pythainlp.util import countthai\n",
    "from tqdm import tqdm\n",
    "\n",
    "def rm_reptitive(text):\n",
    "    s = \"\"\n",
    "    groups = groupby(text)\n",
    "    for label, group in groups:\n",
    "        g = list(group)\n",
    "        if len(g) >= 3:\n",
    "            s += f\"{label*3} rep \"\n",
    "        else:\n",
    "            s += \"\".join(g)\n",
    "    return s\n",
    "\n",
    "def remove_space(sent):\n",
    "    newwords = []\n",
    "    for w in sent:\n",
    "        if len(w.strip())==0:\n",
    "            continue\n",
    "        newwords.append(w)\n",
    "    return newwords\n",
    "\n",
    "\n",
    "import re\n",
    "def notthai(w):\n",
    "    if countthai(w) > 50:\n",
    "        return False\n",
    "    \n",
    "    if w in [\"usr\", \"sys\", \"rep\"]:\n",
    "        return False\n",
    "    \n",
    "    nt = re.sub(r'\\W+', '', w)\n",
    "    if len(nt) > 0 and not nt.isnumeric():\n",
    "#         print(nt)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def analyse_conv_per_person(texts):\n",
    "    \n",
    "    # Word Statistic\n",
    "    texts = [t.lower() for t in texts]\n",
    "    texts = [rm_reptitive(t) for t in texts]\n",
    "    words = [word_tokenize(t) for t in texts]\n",
    "    words = [remove_space(w) for w in words]\n",
    "    \n",
    "    nlongword = 0\n",
    "    ndict = 0\n",
    "    nthai = 0\n",
    "    nnotthai = 0\n",
    "    for sent in words:\n",
    "        ndict += sum([1 if w in thaidict_royal else 0 for w in sent])\n",
    "        nlongword += sum([1 if len(w) > 7 else 0 for w in sent])\n",
    "        nthai += sum([1 if countthai(w) > 50 else 0 for w in sent])\n",
    "            \n",
    "        nnotthai += sum([1 if notthai(w) else 0 for w in sent])\n",
    "        \n",
    "        \n",
    "    \n",
    "    uwords = set()\n",
    "    for sent in words:\n",
    "        uwords.update(sent)\n",
    "    \n",
    "    # Lexicon \n",
    "    lex = []\n",
    "    for sidx, sent in enumerate(words):\n",
    "        for widx, w in enumerate(sent):\n",
    "            if w not in lexicons_keys:\n",
    "                continue \n",
    "            \n",
    "            s = \"\".join(sent[widx:])\n",
    "            for l in lexicons_keys[w]:\n",
    "                if not s.startswith(l):\n",
    "                    continue\n",
    "\n",
    "                lex.extend(lexicons[l])\n",
    "#                 print(\">>\", w, l, lexicons[l])\n",
    "\n",
    "    lexcat = {}\n",
    "    for l in lex:\n",
    "        if l not in lexcat:\n",
    "            lexcat[l] = 0\n",
    "        lexcat[l] += 1\n",
    "    \n",
    "    # Stylistic words\n",
    "    nrepeat = 0\n",
    "    for sidx, sent in enumerate(words):\n",
    "        nrepeat += sum([1 if w==\"rep\" else 0 for w in sent])\n",
    "    \n",
    "    s = \" \".join(texts)\n",
    "    nemoji = emoji.emoji_count(s)\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"nsent\": len(texts),\n",
    "        \"nword\": sum([len(w) for w in words]),\n",
    "        \"ndict\": ndict,\n",
    "        \"nunique\": len(uwords),\n",
    "        \"nlongword\": nlongword,\n",
    "        \"nrepeat\": nrepeat,\n",
    "        \"nthai\": nthai,\n",
    "        \"nnotthai\": nnotthai,\n",
    "        \"nemoji\": nemoji,\n",
    "        **lexcat\n",
    "    }\n",
    "  \n",
    "\n",
    "\n",
    "def analyse_conversation(df):\n",
    "    metrics = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        ms = analyse_conv_per_person(row[\"sys\"])\n",
    "        mu = analyse_conv_per_person(row[\"user\"])\n",
    "        metrics.append((ms, mu))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "analyse_conv_per_person([\"เมิงงงงงงงมันโง่เหมือนควายยยยยยยยย\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28f22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e63519",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14df6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj_values(filepath, obj):\n",
    "  with open(filepath, 'wb') as fin:\n",
    "    pickle.dump(obj, fin)\n",
    "    \n",
    "def load_obj_values(filepath):\n",
    "  with open(filepath, 'rb') as fin:\n",
    "    obj = pickle.load(fin)\n",
    "  return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "05a13ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_values = {\n",
    "    \"closeness\": [None, None, None],\n",
    "    \"authority\": [None, None, None],\n",
    "}\n",
    "\n",
    "analysis_labels = {\n",
    "    \"closeness\": [None, None, None],\n",
    "    \"authority\": [None, None, None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "07ac4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_task1_conver(\"./Task1/annotated_conersations.jsonl\", \"closeness\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"closeness\"][0] = metrics\n",
    "# analysis_labels[\"closeness\"][0] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task2_conver(\"./Task2/annotated/annotated.jsonl\", \"closeness\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"closeness\"][1] = metrics\n",
    "# analysis_labels[\"closeness\"][1] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task1_conver(\"./Task3/annotated/annotated.jsonl\", \"closeness\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"closeness\"][2] = metrics\n",
    "# analysis_labels[\"closeness\"][2] = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe536b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_task1_conver(\"./Task1/annotated_conersations.jsonl\", \"authority\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"authority\"][0] = metrics\n",
    "# analysis_labels[\"authority\"][0] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task2_conver(\"./Task2/annotated/annotated.jsonl\", \"authority\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"authority\"][1] = metrics\n",
    "# analysis_labels[\"authority\"][1] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task1_conver(\"./Task3/annotated/annotated.jsonl\", \"authority\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"authority\"][2] = metrics\n",
    "# analysis_labels[\"authority\"][2] = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "16fbe703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_obj_values(\"analysis_values.pkl\", analysis_values)\n",
    "# save_obj_values(\"analysis_labels.pkl\", analysis_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af1b2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_values = load_obj_values(\"analysis_values.pkl\")\n",
    "analysis_labels = load_obj_values(\"analysis_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d8bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b7098221",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = {\n",
    "    \"Conversational Statistics\" : {\n",
    "        \"nsent\": \"Number of utterance\",\n",
    "        \"nword\": \"Number of word\",\n",
    "    },\n",
    "    \"Linguistic Complexity\" : {\n",
    "        \"nunique\": \"Vocabulary size\",\n",
    "        \"nthai\": \"Thai words\",\n",
    "        \"nnotthai\": \"Non-Thai words\",\n",
    "        \"nlongword\": \"Long words\",\n",
    "        \"ndict\": \"Dictionary words\",\n",
    "        \"transliterated\": \"Transliteration\",\n",
    "    },\n",
    "    \"Pronoun\": {\n",
    "        \"pronoun\": \"All pronoun\",\n",
    "        \"pronoun_1st\": \">> 1st person pronoun\",\n",
    "        \"pronoun_2nd\": \">> 2nd person pronoun\",\n",
    "        \"pronoun_3rd\": \">> 3rd person pronoun\",\n",
    "        \"pronoun_misspelling\": \">> Pronoun in non-standard spelling\",\n",
    "    },\n",
    "    \n",
    "    \"Sentence-ending Particles\": {\n",
    "        \"particles\": \"All particles\",\n",
    "        \"particles_SARP\": \">> Socially-related particles\",\n",
    "        \"particles_notSARP\": \">> Non-socially-related particles\",\n",
    "        \"particles_misspelling\": \">> Particle in non-standard spelling\",\n",
    "    },\n",
    "    \n",
    "    \"Sentiment-related\": {\n",
    "        \"sentiment\": \"Sentiment words\",\n",
    "        \"sentiment_positive\": \">> Positive words\",\n",
    "        \"sentiment_negative\": \">> Negative words\",\n",
    "    },\n",
    "    \n",
    "    \"Spelling Variation\": {\n",
    "        \"misspelling\": \"All spelling variation\",\n",
    "        \"misspelling_common\": \">> Common misspelt words\",\n",
    "        \"misspelling_intention\": \">> Morphophonemic variation\",\n",
    "        \"misspelling_shorten\": \">> Simplified variation\",\n",
    "        \"nrepeat\": \">> Repeated characters\",\n",
    "        \"nemoji\": \">> Emoji\",\n",
    "#         \"abbr\": \"Abbreviation\",\n",
    "#         \"slang\": \"Slang\",\n",
    "#         \"swear\": \"Swear words\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aaf894e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clse_print_labels = ['1. Close', '2. Know each other', \"3. Don't know each other\", \"4. Don't like each other\"]\n",
    "auth_print_labels = ['0. Very respect', '1. Respect', '2. Normal', '3. Not respect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad66f10",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "85b93ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_features(analysis_values, analysis_labels, factor, setting, to_vec_func, skips=[]):\n",
    "    values = analysis_values[factor][setting]\n",
    "    labels = analysis_labels[factor][setting]\n",
    "    assert(len(values)==len(labels))\n",
    "    \n",
    "    rows = []\n",
    "    for (ms, mu), l in zip(values, labels):\n",
    "        if l in skips:\n",
    "            continue\n",
    "        \n",
    "        x = {}\n",
    "        for m in mu:\n",
    "            if m in [\"nsent\", \"nword\"]:\n",
    "                continue\n",
    "            x[m] = mu[m]*100/mu[\"nword\"]\n",
    "        \n",
    "        if \"particles_SARP\" in x:\n",
    "            x[\"particles_notSARP\"] = x[\"particles\"] - x[\"particles_SARP\"]\n",
    "                \n",
    "        y = to_vec_func(l)\n",
    "        rows.append({\n",
    "            **x,\n",
    "            **y\n",
    "        })\n",
    "            \n",
    "    feats = pd.DataFrame(rows)\n",
    "    feats.dropna(subset=[\"y\"], inplace=True)\n",
    "    feats.drop(columns=['particles_??', \"slang\", \"abbr\", \"swear\"], inplace=True)  ## drop unused features\n",
    "    feats.drop(columns=['sentiment', \"misspelling\", \"particles\", \"pronoun\"], inplace=True) ## drop overal features\n",
    "    feats.fillna(0, inplace=True)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fceb9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "def print_anova_test(feats):\n",
    "    x_columns = [col for col in feats.columns if col!=\"y\"]\n",
    "    X = feats[x_columns]\n",
    "    X = sm.add_constant(X)\n",
    "    Y = feats[\"y\"]\n",
    "    model = sm.OLS(Y,X)\n",
    "    results = model.fit()\n",
    "\n",
    "    \n",
    "    ncoef = len(x_columns)+1\n",
    "    \n",
    "    t_test = results.t_test(np.identity(ncoef))\n",
    "    f_test = results.f_test(np.identity(ncoef))\n",
    "    \n",
    "    weights = []\n",
    "    for i, col in enumerate([\"bias\"]+x_columns):\n",
    "        o = {\n",
    "            \"feat\": col, \n",
    "            \"coef\": t_test.effect[i], \n",
    "            \"pval\": t_test.pvalue[i]\n",
    "        }\n",
    "\n",
    "        weights.append(o)\n",
    "    \n",
    "    outputs = pd.DataFrame(weights)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860eae70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9b7e208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_weights(outputs, coef_labels, labels, base_category=None):\n",
    "    \n",
    "#     coefs = {}\n",
    "#     non_coefs = {}\n",
    "#     for i, label in enumerate(coef_labels):\n",
    "#         if i==0:\n",
    "#             continue\n",
    "            \n",
    "#         cond = outputs[f\"pval{i}\"] < 0.05\n",
    "#         for _, row in outputs[cond].sort_values(f\"coef{i}\", ascending=False).iterrows():\n",
    "#             coefs[(label, row[\"feat\"])] = row[f\"coef{i}\"]\n",
    "        \n",
    "#         cond = outputs[f\"pval{i}\"] >= 0.05\n",
    "#         for _, row in outputs[cond].iterrows():\n",
    "#             non_coefs[(label, row[\"feat\"])] = row[f\"coef{i}\"]\n",
    "\n",
    "# #     print(coefs)\n",
    "#     for g in metric_names:\n",
    "#         print(\"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "#         for m in metric_names[g]:\n",
    "#             s = f\"{metric_names[g][m]} \"\n",
    "#             for l in labels:\n",
    "#                 if l == base_category:\n",
    "#                     s += f\"& * \"\n",
    "#                 elif (l, m) in coefs:\n",
    "#                     val = coefs[(l, m)]\n",
    "#                     s += \"& \\cellcolor{gray!25} \"+f\"{val:.2f} \"\n",
    "#                 elif (l, m) in non_coefs:\n",
    "#                     val = non_coefs[(l, m)]\n",
    "#                     s += f\"& {val:.2f} \"\n",
    "#                 else:\n",
    "#                     s += f\"& - \"\n",
    "\n",
    "#             s += \"\\\\\\\\\"\n",
    "#             print(s)\n",
    "#         print(\"&  & &  & \\\\\\\\\")\n",
    "#         print(\"\\hline\")\n",
    "\n",
    "# # gray!25 < gray!50 < gray!80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574751f3-cfd7-49fe-9bbd-bdfc44bf37a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123595e1-f763-455a-87a6-62bc1fc253fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f82a11-1c8c-45b6-8b02-1a05e1563a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "11badd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bias</td>\n",
       "      <td>-1.189055</td>\n",
       "      <td>2.154550e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ndict</td>\n",
       "      <td>-0.009350</td>\n",
       "      <td>2.667411e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nunique</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>1.961348e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nlongword</td>\n",
       "      <td>-0.015214</td>\n",
       "      <td>7.956090e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nthai</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>5.941378e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentiment_positive</td>\n",
       "      <td>-0.006051</td>\n",
       "      <td>1.369086e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pronoun_3rd</td>\n",
       "      <td>0.025668</td>\n",
       "      <td>3.394937e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>particles_SARP</td>\n",
       "      <td>-0.016895</td>\n",
       "      <td>2.041104e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>particles_notSARP</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>1.252328e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feat      coef          pval\n",
       "0                 bias -1.189055  2.154550e-03\n",
       "1                ndict -0.009350  2.667411e-05\n",
       "2              nunique  0.006037  1.961348e-06\n",
       "3            nlongword -0.015214  7.956090e-04\n",
       "5                nthai  0.023700  5.941378e-10\n",
       "8   sentiment_positive -0.006051  1.369086e-02\n",
       "12         pronoun_3rd  0.025668  3.394937e-05\n",
       "15      particles_SARP -0.016895  2.041104e-24\n",
       "16   particles_notSARP -0.020475  1.252328e-08"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def closeness_to_vec1(label):\n",
    "    if label == \"1. Close\":\n",
    "        return {\"y\": 1}\n",
    "    elif label == \"2. Know each other\":\n",
    "        return {\"y\": 0.5}\n",
    "    elif label == \"3. Don't know each other\": \n",
    "        return {\"y\": 0}\n",
    "    elif label == \"4. Don't like each other\":\n",
    "        return {}\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 0, closeness_to_vec1, skips=[])\n",
    "clos1_weights = print_anova_test(feats)\n",
    "clos1_weights[clos1_weights[\"pval\"]<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d71119f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ndict', 'nunique', 'nlongword', 'nrepeat', 'nthai', 'nnotthai',\n",
       "       'nemoji', 'sentiment_positive', 'misspelling_shorten',\n",
       "       'misspelling_intention', 'pronoun_2nd', 'pronoun_3rd', 'pronoun_1st',\n",
       "       'sentiment_negative', 'y', 'particles_SARP', 'particles_notSARP',\n",
       "       'transliterated', 'particles_misspelling', 'misspelling_common',\n",
       "       'pronoun_misspelling'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "33e733fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nunique</td>\n",
       "      <td>-0.003508</td>\n",
       "      <td>0.004878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nrepeat</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pronoun_2nd</td>\n",
       "      <td>-0.009892</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sentiment_negative</td>\n",
       "      <td>-0.011918</td>\n",
       "      <td>0.025318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>particles_SARP</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>0.004808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>transliterated</td>\n",
       "      <td>-0.031692</td>\n",
       "      <td>0.047050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feat      coef      pval\n",
       "2              nunique -0.003508  0.004878\n",
       "4              nrepeat  0.028485  0.000115\n",
       "11         pronoun_2nd -0.009892  0.044444\n",
       "14  sentiment_negative -0.011918  0.025318\n",
       "15      particles_SARP  0.004521  0.004808\n",
       "17      transliterated -0.031692  0.047050"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def authority_to_vec1(label):\n",
    "    if label == '0. Very respect':\n",
    "        return {\"y\":1}\n",
    "    elif label == '1. Respect': \n",
    "        return {\"y\":0.5}\n",
    "    elif label == '2. Normal':\n",
    "        return {\"y\":0}\n",
    "    elif label == '3. Not respect':\n",
    "        return {}\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 0, authority_to_vec1, skips=[\"3. Not respect\"])\n",
    "auth1_weights = print_anova_test(feats)\n",
    "auth1_weights[auth1_weights[\"pval\"]<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50750d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366bdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eeb1c491-f902-4174-b929-bb29eed0a5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bias</td>\n",
       "      <td>-0.383416</td>\n",
       "      <td>1.666208e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nunique</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>1.278620e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nrepeat</td>\n",
       "      <td>0.014329</td>\n",
       "      <td>6.433758e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nthai</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>4.558186e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nnotthai</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>4.844615e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nemoji</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>7.771816e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>misspelling_intention</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>2.173902e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pronoun_1st</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>2.305669e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sentiment_positive</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>8.144852e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feat      coef          pval\n",
       "0                    bias -0.383416  1.666208e-04\n",
       "2                 nunique  0.002139  1.278620e-03\n",
       "4                 nrepeat  0.014329  6.433758e-10\n",
       "5                   nthai  0.004042  4.558186e-04\n",
       "6                nnotthai  0.006106  4.844615e-05\n",
       "7                  nemoji  0.003191  7.771816e-04\n",
       "9   misspelling_intention  0.001958  2.173902e-02\n",
       "10            pronoun_1st  0.006063  2.305669e-02\n",
       "17     sentiment_positive  0.003102  8.144852e-03"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 1, closeness_to_vec1, skips=[])\n",
    "clos2_weights = print_anova_test(feats)\n",
    "clos2_weights[clos2_weights[\"pval\"]<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01b579e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bias</td>\n",
       "      <td>0.709841</td>\n",
       "      <td>3.610281e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ndict</td>\n",
       "      <td>-0.002766</td>\n",
       "      <td>3.980655e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nrepeat</td>\n",
       "      <td>-0.003256</td>\n",
       "      <td>2.670828e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nemoji</td>\n",
       "      <td>0.004648</td>\n",
       "      <td>3.240347e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>misspelling_shorten</td>\n",
       "      <td>-0.002203</td>\n",
       "      <td>3.287505e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>misspelling_intention</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>9.779449e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>particles_SARP</td>\n",
       "      <td>0.006343</td>\n",
       "      <td>2.775427e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sentiment_negative</td>\n",
       "      <td>-0.006525</td>\n",
       "      <td>9.490411e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sentiment_positive</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>2.852760e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>particles_notSARP</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>4.597548e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pronoun_misspelling</td>\n",
       "      <td>-0.005383</td>\n",
       "      <td>4.060548e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feat      coef          pval\n",
       "0                    bias  0.709841  3.610281e-24\n",
       "1                   ndict -0.002766  3.980655e-09\n",
       "4                 nrepeat -0.003256  2.670828e-02\n",
       "7                  nemoji  0.004648  3.240347e-12\n",
       "8     misspelling_shorten -0.002203  3.287505e-04\n",
       "9   misspelling_intention  0.002784  9.779449e-07\n",
       "10         particles_SARP  0.006343  2.775427e-09\n",
       "11     sentiment_negative -0.006525  9.490411e-13\n",
       "12     sentiment_positive  0.006605  2.852760e-16\n",
       "13      particles_notSARP  0.004785  4.597548e-03\n",
       "19    pronoun_misspelling -0.005383  4.060548e-02"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def authority_to_vec2(label):\n",
    "    if label == '0. Very respect':\n",
    "        return {}\n",
    "    elif label == '1. Respect': \n",
    "        return {\"y\":1}\n",
    "    elif label == '2. Normal':\n",
    "        return {\"y\":0.5}\n",
    "    elif label == '3. Not respect':\n",
    "        return {\"y\":0}\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 1, authority_to_vec2)\n",
    "auth2_weights = print_anova_test(feats)\n",
    "auth2_weights[auth2_weights[\"pval\"]<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c34d3-bd59-41d5-985e-299161b6d308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108492a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3de7ffca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ndict</td>\n",
       "      <td>-0.005251</td>\n",
       "      <td>1.109585e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nunique</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>4.712851e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nlongword</td>\n",
       "      <td>-0.012976</td>\n",
       "      <td>2.904897e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nrepeat</td>\n",
       "      <td>0.011652</td>\n",
       "      <td>7.029028e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nthai</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>8.385601e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentiment_positive</td>\n",
       "      <td>-0.004750</td>\n",
       "      <td>1.522921e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pronoun_3rd</td>\n",
       "      <td>0.013399</td>\n",
       "      <td>4.520069e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pronoun_1st</td>\n",
       "      <td>0.012760</td>\n",
       "      <td>8.521153e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sentiment_negative</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>2.410188e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>particles_SARP</td>\n",
       "      <td>-0.009866</td>\n",
       "      <td>1.351083e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>particles_notSARP</td>\n",
       "      <td>-0.007692</td>\n",
       "      <td>4.321395e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feat      coef          pval\n",
       "1                ndict -0.005251  1.109585e-04\n",
       "2              nunique  0.002181  4.712851e-03\n",
       "3            nlongword -0.012976  2.904897e-06\n",
       "4              nrepeat  0.011652  7.029028e-03\n",
       "5                nthai  0.013428  8.385601e-09\n",
       "8   sentiment_positive -0.004750  1.522921e-03\n",
       "12         pronoun_3rd  0.013399  4.520069e-04\n",
       "13         pronoun_1st  0.012760  8.521153e-04\n",
       "14  sentiment_negative  0.010084  2.410188e-03\n",
       "15      particles_SARP -0.009866  1.351083e-22\n",
       "16   particles_notSARP -0.007692  4.321395e-04"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 2, closeness_to_vec1, skips=[])\n",
    "clos3_weights = print_anova_test(feats)\n",
    "clos3_weights[clos3_weights[\"pval\"]<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "550f18a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bias</td>\n",
       "      <td>1.217911</td>\n",
       "      <td>1.170197e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nunique</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>2.510124e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nlongword</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>7.835378e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nrepeat</td>\n",
       "      <td>-0.018801</td>\n",
       "      <td>3.272427e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nthai</td>\n",
       "      <td>-0.008090</td>\n",
       "      <td>4.364052e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nnotthai</td>\n",
       "      <td>-0.015874</td>\n",
       "      <td>4.191689e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentiment_positive</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>1.401141e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>misspelling_shorten</td>\n",
       "      <td>-0.004453</td>\n",
       "      <td>1.960161e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pronoun_1st</td>\n",
       "      <td>-0.005656</td>\n",
       "      <td>2.692381e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>particles_SARP</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>2.020995e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feat      coef          pval\n",
       "0                  bias  1.217911  1.170197e-13\n",
       "2               nunique  0.001186  2.510124e-02\n",
       "3             nlongword  0.006385  7.835378e-04\n",
       "4               nrepeat -0.018801  3.272427e-10\n",
       "5                 nthai -0.008090  4.364052e-07\n",
       "6              nnotthai -0.015874  4.191689e-05\n",
       "8    sentiment_positive  0.003289  1.401141e-03\n",
       "9   misspelling_shorten -0.004453  1.960161e-05\n",
       "13          pronoun_1st -0.005656  2.692381e-02\n",
       "15       particles_SARP  0.005261  2.020995e-14"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 2, authority_to_vec2)\n",
    "auth3_weights = print_anova_test(feats)\n",
    "auth3_weights[auth3_weights[\"pval\"]<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9cedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e46a1405-2b91-495b-b7c9-c393c8816fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clos3_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89049f3f",
   "metadata": {},
   "source": [
    "### Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "035f2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\n",
    "    \"Setting 1: Private Conversations with Self-Reported Labels\",\n",
    "    \"Setting 2: Public Conversations with Labels from 3rd Party \",\n",
    "    \"Setting 3: Private Conversations with Labels from 3rd Party \",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7824106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputs_to_dict(outputs):\n",
    "    coefs = {}\n",
    "    \n",
    "    for _, row in outputs.iterrows():\n",
    "        coefs[row[\"feat\"]] = (row[\"coef\"], row[\"pval\"])\n",
    "\n",
    "    return coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7398c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259b1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471573ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f696abce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "925d851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "printed_text = \"\" \n",
    "printed_text += \"\\subsection{Closeness}\"+\"\\n\"\n",
    "outputs = [\n",
    "    outputs_to_dict(clos1_weights),\n",
    "    outputs_to_dict(clos2_weights),\n",
    "    outputs_to_dict(clos3_weights)\n",
    "]\n",
    "\n",
    "printed_text += \"\\\\begin{longtable}[h]{\"+\"\\n\"\n",
    "printed_text += \"    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\"+\"\\n\"\n",
    "\n",
    "printed_text += \"    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "printed_text += \"    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "printed_text += \"    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "\n",
    "printed_text += \"}\"+\"\\n\"\n",
    "printed_text += \"    \\hline\"+\"\\n\"\n",
    "printed_text += \"    Lexical Features & Setting 1  & Setting 2 & Setting 3 \\\\\\\\\"+\"\\n\"\n",
    "printed_text += \"    \\hline\"+\"\\n\"\n",
    "#     printed_text += \"    \\endfirsthead\"+\"\\n\"\n",
    "#     printed_text += \"\"+\"\\n\"\n",
    "printed_text += \"    \\endhead\"+\"\\n\"\n",
    "printed_text += \"\"+\"\\n\"\n",
    "\n",
    "# for sec, results in zip(sections, outputs):\n",
    "for g in metric_names:\n",
    "    if g in [\"Conversational Statistics\"]:\n",
    "        continue\n",
    "\n",
    "    printed_text += \"    \\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "    printed_text += \"    \\hline\"+\"\\n\"\n",
    "\n",
    "    for m in metric_names[g]:\n",
    "        s = f\"        {metric_names[g][m]} \"\n",
    "        for out in outputs:\n",
    "            if m not in out:\n",
    "                s += f\"& - \"\n",
    "            else:\n",
    "                val, pval = out[m]\n",
    "\n",
    "                if pval < 0.05:\n",
    "                    s += \"& \\cellcolor{gray!25} \"+f\"{val:.2e} \"\n",
    "                else:\n",
    "                    s += f\"& {val:.2e} \"\n",
    "        s += \"\\\\\\\\\"\n",
    "        # print(s)\n",
    "        printed_text += s+\"\\n\"\n",
    "\n",
    "\n",
    "    printed_text += \"        &  & &\\\\\\\\\"+\"\\n\"\n",
    "    printed_text += \"    \\hline\"+\"\\n\"\n",
    "    printed_text += \"\"+\"\\n\"\n",
    "printed_text += \"\\label{closeness_linear_weights}\"+\"\\n\"\n",
    "printed_text += \"\\end{longtable}\"+\"\\n\"\n",
    "printed_text += \"\\clearpage\"+\"\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8325a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "printed_text += \"\\subsection{Respect}\"+\"\\n\"\n",
    "outputs = [\n",
    "    outputs_to_dict(auth1_weights),\n",
    "    outputs_to_dict(auth2_weights),\n",
    "    outputs_to_dict(auth3_weights)\n",
    "]\n",
    "\n",
    "printed_text += \"\\\\begin{longtable}[h]{\"+\"\\n\"\n",
    "printed_text += \"    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\"+\"\\n\"\n",
    "\n",
    "printed_text += \"    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "printed_text += \"    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "printed_text += \"    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "\n",
    "printed_text += \"}\"+\"\\n\"\n",
    "printed_text += \"    \\hline\"+\"\\n\"\n",
    "printed_text += \"    Lexical Features & Setting 1  & Setting 2 & Setting 3 \\\\\\\\\"+\"\\n\"\n",
    "printed_text += \"    \\hline\"+\"\\n\"\n",
    "#     printed_text += \"    \\endfirsthead\"+\"\\n\"\n",
    "#     printed_text += \"\"+\"\\n\"\n",
    "printed_text += \"    \\endhead\"+\"\\n\"\n",
    "printed_text += \"\"+\"\\n\"\n",
    "\n",
    "# for sec, results in zip(sections, outputs):\n",
    "for g in metric_names:\n",
    "    if g in [\"Conversational Statistics\"]:\n",
    "        continue\n",
    "\n",
    "    printed_text += \"    \\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "    printed_text += \"    \\hline\"+\"\\n\"\n",
    "\n",
    "    for m in metric_names[g]:\n",
    "        s = f\"        {metric_names[g][m]} \"\n",
    "        for out in outputs:\n",
    "            if m not in out:\n",
    "                s += f\"& - \"\n",
    "            else:\n",
    "                val, pval = out[m]\n",
    "\n",
    "                if pval < 0.05:\n",
    "                    s += \"& \\cellcolor{gray!25} \"+f\"{val:.2e} \"\n",
    "                else:\n",
    "                    s += f\"& {val:.2e} \"\n",
    "        s += \"\\\\\\\\\"\n",
    "        # print(s)\n",
    "        printed_text += s+\"\\n\"\n",
    "\n",
    "\n",
    "    printed_text += \"        &  & &\\\\\\\\\"+\"\\n\"\n",
    "    printed_text += \"    \\hline\"+\"\\n\"\n",
    "    printed_text += \"\"+\"\\n\"\n",
    "printed_text += \"\\label{closeness_linear_weights}\"+\"\\n\"\n",
    "printed_text += \"\\end{longtable}\"+\"\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4c1ce27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\subsection{Closeness}\n",
      "\\begin{longtable}[h]{\n",
      "    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "}\n",
      "    \\hline\n",
      "    Lexical Features & Setting 1  & Setting 2 & Setting 3 \\\\\n",
      "    \\hline\n",
      "    \\endhead\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Linguistic Complexity}} \\\\\n",
      "    \\hline\n",
      "        Vocabulary size & \\cellcolor{gray!25} 6.04e-03 & \\cellcolor{gray!25} 2.14e-03 & \\cellcolor{gray!25} 2.18e-03 \\\\\n",
      "        Thai words & \\cellcolor{gray!25} 2.37e-02 & \\cellcolor{gray!25} 4.04e-03 & \\cellcolor{gray!25} 1.34e-02 \\\\\n",
      "        Non-Thai words & 1.17e-02 & \\cellcolor{gray!25} 6.11e-03 & 8.24e-04 \\\\\n",
      "        Long words & \\cellcolor{gray!25} -1.52e-02 & -1.74e-03 & \\cellcolor{gray!25} -1.30e-02 \\\\\n",
      "        Dictionary words & \\cellcolor{gray!25} -9.35e-03 & -1.19e-03 & \\cellcolor{gray!25} -5.25e-03 \\\\\n",
      "        Transliteration & -6.47e-03 & -3.32e-03 & -7.13e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Pronoun}} \\\\\n",
      "    \\hline\n",
      "        All pronoun & - & - & - \\\\\n",
      "        >> 1st person pronoun & 1.08e-02 & \\cellcolor{gray!25} 6.06e-03 & \\cellcolor{gray!25} 1.28e-02 \\\\\n",
      "        >> 2nd person pronoun & -5.88e-03 & -1.45e-03 & -2.44e-03 \\\\\n",
      "        >> 3rd person pronoun & \\cellcolor{gray!25} 2.57e-02 & 2.74e-03 & \\cellcolor{gray!25} 1.34e-02 \\\\\n",
      "        >> Pronoun in non-standard spelling & 6.20e-03 & -1.25e-03 & 7.06e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "    \\hline\n",
      "        All particles & - & - & - \\\\\n",
      "        >> Socially-related particles & \\cellcolor{gray!25} -1.69e-02 & -2.84e-03 & \\cellcolor{gray!25} -9.87e-03 \\\\\n",
      "        >> Non-socially-related particles & \\cellcolor{gray!25} -2.05e-02 & -3.59e-03 & \\cellcolor{gray!25} -7.69e-03 \\\\\n",
      "        >> Particle in non-standard spelling & 6.52e-03 & -3.78e-03 & 4.68e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Sentiment-related}} \\\\\n",
      "    \\hline\n",
      "        Sentiment words & - & - & - \\\\\n",
      "        >> Positive words & \\cellcolor{gray!25} -6.05e-03 & \\cellcolor{gray!25} 3.10e-03 & \\cellcolor{gray!25} -4.75e-03 \\\\\n",
      "        >> Negative words & 2.40e-03 & 5.04e-04 & \\cellcolor{gray!25} 1.01e-02 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Spelling Variation}} \\\\\n",
      "    \\hline\n",
      "        All spelling variation & - & - & - \\\\\n",
      "        >> Common misspelt words & 1.48e-02 & -2.61e-03 & 3.99e-03 \\\\\n",
      "        >> Morphophonemic variation & -7.21e-04 & \\cellcolor{gray!25} 1.96e-03 & 1.32e-03 \\\\\n",
      "        >> Simplified variation & -3.41e-03 & 1.22e-03 & 2.39e-03 \\\\\n",
      "        >> Repeated characters & 4.43e-03 & \\cellcolor{gray!25} 1.43e-02 & \\cellcolor{gray!25} 1.17e-02 \\\\\n",
      "        >> Emoji & -2.60e-02 & \\cellcolor{gray!25} 3.19e-03 & -5.35e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "\\label{closeness_linear_weights}\n",
      "\\end{longtable}\n",
      "\\clearpage\n",
      "\\subsection{Respect}\n",
      "\\begin{longtable}[h]{\n",
      "    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "}\n",
      "    \\hline\n",
      "    Lexical Features & Setting 1  & Setting 2 & Setting 3 \\\\\n",
      "    \\hline\n",
      "    \\endhead\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Linguistic Complexity}} \\\\\n",
      "    \\hline\n",
      "        Vocabulary size & \\cellcolor{gray!25} -3.51e-03 & -7.95e-04 & \\cellcolor{gray!25} 1.19e-03 \\\\\n",
      "        Thai words & 7.22e-03 & 1.75e-04 & \\cellcolor{gray!25} -8.09e-03 \\\\\n",
      "        Non-Thai words & 1.35e-02 & 1.01e-04 & \\cellcolor{gray!25} -1.59e-02 \\\\\n",
      "        Long words & 3.07e-03 & 1.19e-03 & \\cellcolor{gray!25} 6.39e-03 \\\\\n",
      "        Dictionary words & 2.43e-03 & \\cellcolor{gray!25} -2.77e-03 & 4.42e-04 \\\\\n",
      "        Transliteration & \\cellcolor{gray!25} -3.17e-02 & -2.15e-03 & -1.13e-02 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Pronoun}} \\\\\n",
      "    \\hline\n",
      "        All pronoun & - & - & - \\\\\n",
      "        >> 1st person pronoun & -2.36e-03 & 1.96e-03 & \\cellcolor{gray!25} -5.66e-03 \\\\\n",
      "        >> 2nd person pronoun & \\cellcolor{gray!25} -9.89e-03 & -2.29e-03 & -3.01e-03 \\\\\n",
      "        >> 3rd person pronoun & 5.01e-03 & -3.33e-04 & 3.52e-03 \\\\\n",
      "        >> Pronoun in non-standard spelling & 3.55e-03 & \\cellcolor{gray!25} -5.38e-03 & -5.53e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "    \\hline\n",
      "        All particles & - & - & - \\\\\n",
      "        >> Socially-related particles & \\cellcolor{gray!25} 4.52e-03 & \\cellcolor{gray!25} 6.34e-03 & \\cellcolor{gray!25} 5.26e-03 \\\\\n",
      "        >> Non-socially-related particles & 6.71e-03 & \\cellcolor{gray!25} 4.78e-03 & 1.49e-03 \\\\\n",
      "        >> Particle in non-standard spelling & 6.09e-03 & -3.44e-03 & -9.49e-04 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Sentiment-related}} \\\\\n",
      "    \\hline\n",
      "        Sentiment words & - & - & - \\\\\n",
      "        >> Positive words & 2.63e-03 & \\cellcolor{gray!25} 6.61e-03 & \\cellcolor{gray!25} 3.29e-03 \\\\\n",
      "        >> Negative words & \\cellcolor{gray!25} -1.19e-02 & \\cellcolor{gray!25} -6.53e-03 & -4.08e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Spelling Variation}} \\\\\n",
      "    \\hline\n",
      "        All spelling variation & - & - & - \\\\\n",
      "        >> Common misspelt words & -1.07e-02 & -2.33e-03 & 3.61e-03 \\\\\n",
      "        >> Morphophonemic variation & -4.33e-03 & \\cellcolor{gray!25} 2.78e-03 & 6.12e-04 \\\\\n",
      "        >> Simplified variation & -2.40e-03 & \\cellcolor{gray!25} -2.20e-03 & \\cellcolor{gray!25} -4.45e-03 \\\\\n",
      "        >> Repeated characters & \\cellcolor{gray!25} 2.85e-02 & \\cellcolor{gray!25} -3.26e-03 & \\cellcolor{gray!25} -1.88e-02 \\\\\n",
      "        >> Emoji & -7.54e-03 & \\cellcolor{gray!25} 4.65e-03 & 5.05e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "\\label{closeness_linear_weights}\n",
      "\\end{longtable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74abbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc15ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a22a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c8ae0ea",
   "metadata": {},
   "source": [
    "### Evaluate Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e8d08c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from random import random\n",
    "\n",
    "def get_data_from_df_to_data(df):\n",
    "    x_columns = [col for col in df.columns if col!=\"y\"]\n",
    "    X = df[x_columns]\n",
    "    X = sm.add_constant(X)\n",
    "    Y = df[\"y\"]\n",
    "    \n",
    "    return X, Y\n",
    "    \n",
    "def train_model(feats, label_fn, random_state=42, random_guess=False):\n",
    "    d = feats.sample(frac=1, random_state=random_state)\n",
    "    train, test = np.split(d, [int(0.9*len(d))])\n",
    "#     train, validate, test = np.split(d, [int(0.8*len(d)), int(0.9*len(d))])\n",
    "    \n",
    "    Xtrain, Ytrain = get_data_from_df_to_data(train)\n",
    "    model = sm.OLS(Ytrain,Xtrain)\n",
    "    M = model.fit()\n",
    "    \n",
    "#     Xval, Yval = get_data_from_df_to_data(validate)\n",
    "#     thesholds = tune_thesholds(M, Xval, Yval)\n",
    "        \n",
    "    Xtest, Ytest = get_data_from_df_to_data(test)\n",
    "\n",
    "    predictions = M.predict(Xtest)\n",
    "    \n",
    "    predicted_labels = [label_fn(p) for p in predictions]\n",
    "    actual_labels = [label_fn(p) for p in Ytest]\n",
    "    p, r, f1, _ = precision_recall_fscore_support(actual_labels, predicted_labels, average='macro', zero_division=0)\n",
    "    \n",
    "#     print((np.array(predicted_labels)==np.array(actual_labels)).sum())\n",
    "    return {\n",
    "        \"rmse\": np.sqrt(mean_squared_error(Ytest, predictions)),\n",
    "        \"r2\": r2_score(Ytest, predictions),\n",
    "        \n",
    "        \"accuracy\": accuracy_score(actual_labels, predicted_labels),\n",
    "        \"f1\": f1,\n",
    "        \"precision\": p,\n",
    "        \"recall\": r,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7755e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d62f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(feats, label_fn, random_guess=False):\n",
    "    eval_metrics = {}\n",
    "    for i in range(100):\n",
    "        metrics = train_model(feats, label_fn, random_state=i, random_guess=random_guess)\n",
    "        for k in metrics:\n",
    "            if k not in eval_metrics:\n",
    "                eval_metrics[k] = []\n",
    "            eval_metrics[k].append(metrics[k])\n",
    "\n",
    "    for k in eval_metrics:\n",
    "        print(f\"{k}: {np.mean(eval_metrics[k]):.3f} ± {np.std(eval_metrics[k]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11c33e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_guess=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7472591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.405 ± 0.018\n",
      "r2: 0.173 ± 0.064\n",
      "accuracy: 0.408 ± 0.042\n",
      "f1: 0.400 ± 0.040\n",
      "precision: 0.533 ± 0.046\n",
      "recall: 0.435 ± 0.042\n"
     ]
    }
   ],
   "source": [
    "def closeness_label_fn(label):\n",
    "    if label == '1. Close':\n",
    "        return 1\n",
    "    elif label =='2. Know each other':\n",
    "        return 0.5\n",
    "    elif label == \"3. Don't know each other\":\n",
    "        return 0\n",
    "    elif type(label)==str:\n",
    "        assert(False)\n",
    "    \n",
    "    # [0, 0.33) =>\n",
    "    # [0.33, 0.66) =>\n",
    "    # [0.66, 1] =>\n",
    "    \n",
    "    if label > 0.66:\n",
    "        return '1. Close'\n",
    "    elif label > 0.33:\n",
    "        return '2. Know each other'\n",
    "    else:\n",
    "        return \"3. Don't know each other\"\n",
    "    \n",
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 0, closeness_to_vec1, skips=[])\n",
    "print_accuracy(feats, closeness_label_fn, random_guess=random_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4454838c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.395 ± 0.017\n",
      "r2: 0.013 ± 0.051\n",
      "accuracy: 0.450 ± 0.038\n",
      "f1: 0.314 ± 0.028\n",
      "precision: 0.313 ± 0.083\n",
      "recall: 0.364 ± 0.033\n"
     ]
    }
   ],
   "source": [
    "def authority_label_fn(label):\n",
    "    if label == '0. Very respect':\n",
    "        return 1\n",
    "    elif label =='1. Respect':\n",
    "        return 0.5\n",
    "    elif label == \"2. Normal\":\n",
    "        return 0\n",
    "    elif type(label)==str:\n",
    "        assert(False)\n",
    "    \n",
    "    # [0, 0.33) =>\n",
    "    # [0.33, 0.66) =>\n",
    "    # [0.66, 1] =>\n",
    "    \n",
    "    if label > 0.66:\n",
    "        return '0. Very respect'\n",
    "    elif label > 0.33:\n",
    "        return '1. Respect'\n",
    "    else:\n",
    "        return \"2. Normal\"\n",
    "    \n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 0, authority_to_vec1, skips=[])\n",
    "print_accuracy(feats, authority_label_fn, random_guess=random_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d650d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e5f5c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.331 ± 0.023\n",
      "r2: 0.035 ± 0.050\n",
      "accuracy: 0.773 ± 0.029\n",
      "f1: 0.327 ± 0.027\n",
      "precision: 0.419 ± 0.151\n",
      "recall: 0.346 ± 0.019\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 1, closeness_to_vec1, skips=[])\n",
    "print_accuracy(feats, closeness_label_fn, random_guess=random_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9167fd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.248 ± 0.011\n",
      "r2: 0.153 ± 0.048\n",
      "accuracy: 0.704 ± 0.029\n",
      "f1: 0.444 ± 0.038\n",
      "precision: 0.572 ± 0.069\n",
      "recall: 0.430 ± 0.028\n"
     ]
    }
   ],
   "source": [
    "def authority2_label_fn(label):\n",
    "    if label == '1. Respect':\n",
    "        return 1\n",
    "    elif label =='2. Normal':\n",
    "        return 0.5\n",
    "    elif label == \"3. Not respect\":\n",
    "        return 0\n",
    "    elif type(label)==str:\n",
    "        assert(False)\n",
    "    \n",
    "    if label > 0.66:\n",
    "        return '1. Respect'\n",
    "    elif label > 0.33:\n",
    "        return '2. Normal'\n",
    "    else:\n",
    "        return \"3. Not respect\"\n",
    "    \n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 1, authority_to_vec2)\n",
    "print_accuracy(feats, authority2_label_fn, random_guess=random_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d634e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c58ca858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.247 ± 0.016\n",
      "r2: 0.203 ± 0.080\n",
      "accuracy: 0.629 ± 0.048\n",
      "f1: 0.542 ± 0.087\n",
      "precision: 0.602 ± 0.121\n",
      "recall: 0.544 ± 0.079\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 2, closeness_to_vec1, skips=[])\n",
    "print_accuracy(feats, closeness_label_fn, random_guess=random_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5cae9d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.165 ± 0.019\n",
      "r2: 0.119 ± 0.131\n",
      "accuracy: 0.883 ± 0.029\n",
      "f1: 0.463 ± 0.065\n",
      "precision: 0.543 ± 0.122\n",
      "recall: 0.447 ± 0.058\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 2, authority_to_vec2)\n",
    "print_accuracy(feats, authority2_label_fn, random_guess=random_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23894106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da725a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272d7e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
