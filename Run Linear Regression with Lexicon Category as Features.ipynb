{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1877f9b4",
   "metadata": {},
   "source": [
    "## Load Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93deeee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "import pandas as pd\n",
    "from utils import load_jsonl, dump_jsonl\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87c53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f99623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task1_conver(in_dir, col_label, skips=[]):\n",
    "    conversations = load_jsonl(f\"{in_dir}\")\n",
    "    \n",
    "    \n",
    "    def to_message_str(messages, users):\n",
    "        s = []\n",
    "        u = []\n",
    "        for m in messages:\n",
    "            if users[m['user_id']] == \"SYS\":\n",
    "                s.append(m['text'])\n",
    "            else:\n",
    "                u.append(m['text'])\n",
    "                \n",
    "        return s, u\n",
    "        \n",
    "    newdata = []\n",
    "    for row in conversations:\n",
    "        row[\"messages\"].sort(key=lambda x: x[\"date_created\"], reverse=False)\n",
    "        \n",
    "        users = {}\n",
    "        for m in row[\"messages\"]:\n",
    "            if m[\"user_id\"] not in users:\n",
    "#                 username = \"USR\"+str(len(users)+1) if len(users.keys())==0 else \"SYS\"\n",
    "                username = \"USR\" if len(users.keys())==0 else \"SYS\"\n",
    "                users[m[\"user_id\"]] = username\n",
    "                \n",
    "#         if len(users)>2:\n",
    "#             print(\"More than 1 users\", len(users))\n",
    "        \n",
    "        \n",
    "        messages = row[\"messages\"]\n",
    "        chunk_size = 100\n",
    "        for i in range(0, len(messages), chunk_size):\n",
    "            sub_messages = messages[i:i+chunk_size]\n",
    "            s, u = to_message_str(sub_messages, users)\n",
    "            \n",
    "            if pd.isna(row[col_label]):\n",
    "                continue\n",
    "            \n",
    "            if row[col_label] in skips:\n",
    "                continue\n",
    "                \n",
    "            label = row[col_label]\n",
    "                \n",
    "            newdata.append({\n",
    "                \"user\": u,\n",
    "                \"sys\": s,\n",
    "                \"label\": label,\n",
    "                \"nturn\": len(sub_messages)\n",
    "            })\n",
    "        \n",
    "#     n_val = int(len(newdata)*0.05)\n",
    "#     n_test = n_val\n",
    "    \n",
    "#     test = newdata[0:n_test]\n",
    "#     val = newdata[n_test:n_test+n_val]\n",
    "#     train = newdata[n_test+n_val:]\n",
    "    \n",
    "    return pd.DataFrame(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92feb049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1234 records from ./Task1/annotated_conersations.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...</td>\n",
       "      <td>[ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...</td>\n",
       "      <td>[โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...</td>\n",
       "      <td>[อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...</td>\n",
       "      <td>[ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...</td>\n",
       "      <td>[ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...   \n",
       "1  [วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...   \n",
       "2  [เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...   \n",
       "3  [มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...   \n",
       "4  [อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...   \n",
       "\n",
       "                                                 sys     label  nturn  \n",
       "0  [ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...  1. Close     35  \n",
       "1  [โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...  1. Close     39  \n",
       "2  [อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...  1. Close     40  \n",
       "3  [ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...  1. Close     35  \n",
       "4  [ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...  1. Close     39  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task1_conver(\"./Task1/annotated_conersations.jsonl\", \"closeness\", skips = [])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e31cf-71f1-4fdb-b865-2f8b37eca3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554617d6-e691-4d93-acd3-bd65c7e93cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Close</th>\n",
       "      <td>551</td>\n",
       "      <td>551</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Know each other</th>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Don't know each other</th>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. Don't like each other</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user  sys  nturn\n",
       "label                                     \n",
       "1. Close                   551  551    551\n",
       "2. Know each other         230  230    230\n",
       "3. Don't know each other   435  435    435\n",
       "4. Don't like each other     5    5      5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b648fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc25201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task2_conver(in_dir, col_label, skips=[]):\n",
    "    conversations = load_jsonl(f\"{in_dir}\")\n",
    "        \n",
    "    newdata = []\n",
    "    for row in conversations:\n",
    "        row[\"messages\"].sort(key=lambda x: x[\"created_at\"], reverse=False)\n",
    "        \n",
    "        users = {}\n",
    "        for m in row[\"messages\"]:\n",
    "            if m[\"user_id\"] not in users:\n",
    "#                 username = \"USR\"+str(len(users)+1) if len(users.keys())==0 else \"SYS\"\n",
    "                username = \"USR\" if len(users.keys())!=0 else \"SYS\"\n",
    "                users[m[\"user_id\"]] = username\n",
    "                \n",
    "        if len(users)>2:\n",
    "            print(\"More than 1 users\", len(users))\n",
    "        \n",
    "        \n",
    "        \n",
    "        messages = row[\"messages\"]\n",
    "        s = []\n",
    "        u = []\n",
    "        for m in messages:\n",
    "            text = m['text'].replace(\"[USR]\", \"\").replace(\"[URL]\", \"URL\")\n",
    "            if users[m['user_id']] == \"SYS\":\n",
    "                s.append(text)\n",
    "            else:\n",
    "                u.append(text)\n",
    "        \n",
    "        label = row[col_label]\n",
    "            \n",
    "        if pd.isna(label):\n",
    "            continue\n",
    "        \n",
    "        if label in skips:\n",
    "            continue\n",
    "                \n",
    "        newdata.append({\n",
    "            \"user\": u,\n",
    "            \"sys\": s,\n",
    "            \"label\": label,\n",
    "            \"nturn\": len(messages)\n",
    "        })\n",
    "                \n",
    "            \n",
    "    n_val = int(len(newdata)*0.1)\n",
    "    n_test = n_val\n",
    "    \n",
    "    test = newdata[0:n_test]\n",
    "    val = newdata[n_test:n_test+n_val]\n",
    "    train = newdata[n_test+n_val:]\n",
    "    \n",
    "    return pd.DataFrame(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b980cc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2486 records from ./Task2/annotated/annotated.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ แตงโม ชวนแฟนไปค่ะ ไม่ใช่กระติกชวนไป กลับไปหา...</td>\n",
       "      <td>[ทบทวน\\nงานคืนนั้น #กระติก ชวนแฟนพี่ตม.ไปด้วยน...</td>\n",
       "      <td>3. Not respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[   รูปนี้จ้า ยัยน้องตัวเล็กของพี่มิว☀️🌻\\n \\n#...</td>\n",
       "      <td>[เนื่ิองจากวันนี้...เป็นวันครบรอบ 3 ปี\\nมาเล่น...</td>\n",
       "      <td>1. Respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ แอบคิดเหมือนกัน้ลยค่ะว่าจะมีอีกรอบ]</td>\n",
       "      <td>[เธรดนี้จะมาวิเคราะห์น้ำท่วมปี54 ที่จริงมันอาจ...</td>\n",
       "      <td>2. Normal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ เนี่ยสิ่งที่กูพูด URL]</td>\n",
       "      <td>[มาดิ้นควยไรชองมึง\\nมึงอ่ะโชว์โง่ไอ้สัตว์ เสร่...</td>\n",
       "      <td>3. Not respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ สรุปปวินนี่บล็อกคนด้วยมั้ย?,  สรุป ที่น่าโมโ...</td>\n",
       "      <td>[แต่ปวินกับไพรวัลย์ก็ไม่เข้าใจนะเหมือนเจ้เกลีย...</td>\n",
       "      <td>2. Normal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [ แตงโม ชวนแฟนไปค่ะ ไม่ใช่กระติกชวนไป กลับไปหา...   \n",
       "1  [   รูปนี้จ้า ยัยน้องตัวเล็กของพี่มิว☀️🌻\\n \\n#...   \n",
       "2              [ แอบคิดเหมือนกัน้ลยค่ะว่าจะมีอีกรอบ]   \n",
       "3                           [ เนี่ยสิ่งที่กูพูด URL]   \n",
       "4  [ สรุปปวินนี่บล็อกคนด้วยมั้ย?,  สรุป ที่น่าโมโ...   \n",
       "\n",
       "                                                 sys           label  nturn  \n",
       "0  [ทบทวน\\nงานคืนนั้น #กระติก ชวนแฟนพี่ตม.ไปด้วยน...  3. Not respect      3  \n",
       "1  [เนื่ิองจากวันนี้...เป็นวันครบรอบ 3 ปี\\nมาเล่น...      1. Respect      3  \n",
       "2  [เธรดนี้จะมาวิเคราะห์น้ำท่วมปี54 ที่จริงมันอาจ...       2. Normal      3  \n",
       "3  [มาดิ้นควยไรชองมึง\\nมึงอ่ะโชว์โง่ไอ้สัตว์ เสร่...  3. Not respect      3  \n",
       "4  [แต่ปวินกับไพรวัลย์ก็ไม่เข้าใจนะเหมือนเจ้เกลีย...       2. Normal      5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task2_conver(\"./Task2/annotated/annotated.jsonl\", \"authority\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc1405-7676-4a1d-b2a7-894083116d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27de11af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Respect</th>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Normal</th>\n",
       "      <td>1661</td>\n",
       "      <td>1661</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Not respect</th>\n",
       "      <td>364</td>\n",
       "      <td>364</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user   sys  nturn\n",
       "label                            \n",
       "1. Respect       319   319    319\n",
       "2. Normal       1661  1661   1661\n",
       "3. Not respect   364   364    364"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27dfc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a566de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1221 records from ./Task3/annotated/annotated.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...</td>\n",
       "      <td>[ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...</td>\n",
       "      <td>[โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...</td>\n",
       "      <td>2. Know each other</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...</td>\n",
       "      <td>[อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...</td>\n",
       "      <td>2. Know each other</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...</td>\n",
       "      <td>[ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...</td>\n",
       "      <td>[ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...</td>\n",
       "      <td>1. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...   \n",
       "1  [วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...   \n",
       "2  [เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...   \n",
       "3  [มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...   \n",
       "4  [อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...   \n",
       "\n",
       "                                                 sys               label  \\\n",
       "0  [ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...            1. Close   \n",
       "1  [โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...  2. Know each other   \n",
       "2  [อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...  2. Know each other   \n",
       "3  [ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...            1. Close   \n",
       "4  [ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...            1. Close   \n",
       "\n",
       "   nturn  \n",
       "0     35  \n",
       "1     39  \n",
       "2     40  \n",
       "3     35  \n",
       "4     39  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_task1_conver(\"./Task3/annotated/annotated.jsonl\", \"closeness\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282e5a5b-4206-46bd-ae7f-604b8c24574a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Close</th>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Know each other</th>\n",
       "      <td>696</td>\n",
       "      <td>696</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Don't know each other</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. Don't like each other</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user  sys  nturn\n",
       "label                                     \n",
       "1. Close                   462  462    462\n",
       "2. Know each other         696  696    696\n",
       "3. Don't know each other    52   52     52\n",
       "4. Don't like each other    11   11     11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a42643-11c4-427c-b3c5-662a21a5af31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d21d30-3555-4593-919c-6f7581ac0a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8d78a46",
   "metadata": {},
   "source": [
    "## Load Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caafaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "755a8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./PrivateSpace/thai-dictionary/RoyalInstituteDictionary/words.json\", encoding=\"utf-8\") as fin:\n",
    "    raw = json.load(fin)\n",
    "    thaidict_royal = set()\n",
    "    for k in raw:\n",
    "        thaidict_royal.update(raw[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63a63c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25573 records from lexicons.jsonl\n"
     ]
    }
   ],
   "source": [
    "lexicons_arr = load_jsonl(\"lexicons.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bbccb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "tags = set()\n",
    "lexicons = {}\n",
    "lexicons_keys = defaultdict(list)\n",
    "\n",
    "for key, values  in lexicons_arr:\n",
    "    if len(key) <= 1:\n",
    "        continue\n",
    "        \n",
    "    key = key.lower()\n",
    "    if key.endswith(\"rep\"):\n",
    "        key = key.replace(\"rep\", \"\")\n",
    "        \n",
    "    w = word_tokenize(key)\n",
    "    \n",
    "    lexicons_keys[w[0]].append(key)\n",
    "    \n",
    "    tag = [t for t in values[\"tags\"] if not t.startswith(\"cat:\")]\n",
    "    lexicons[key] = tag\n",
    "    tags.update(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "320f0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.util import countthai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12380160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "388acee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "import emoji\n",
    "from pythainlp.util import countthai\n",
    "from tqdm import tqdm\n",
    "\n",
    "def rm_reptitive(text):\n",
    "    s = \"\"\n",
    "    groups = groupby(text)\n",
    "    for label, group in groups:\n",
    "        g = list(group)\n",
    "        if len(g) >= 3:\n",
    "            s += f\"{label*3} rep \"\n",
    "        else:\n",
    "            s += \"\".join(g)\n",
    "    return s\n",
    "\n",
    "def remove_space(sent):\n",
    "    newwords = []\n",
    "    for w in sent:\n",
    "        if len(w.strip())==0:\n",
    "            continue\n",
    "        newwords.append(w)\n",
    "    return newwords\n",
    "    \n",
    "def analyse_conv_per_person(texts):\n",
    "    \n",
    "    # Word Statistic\n",
    "    texts = [t.lower() for t in texts]\n",
    "    texts = [rm_reptitive(t) for t in texts]\n",
    "    words = [word_tokenize(t) for t in texts]\n",
    "    words = [remove_space(w) for w in words]\n",
    "    \n",
    "    nlongword = 0\n",
    "    ndict = 0\n",
    "    for sent in words:\n",
    "        ndict += sum([1 if w in thaidict_royal else 0 for w in sent])\n",
    "        nlongword += sum([1 if len(w) > 7 else 0 for w in sent])\n",
    "        nthai = sum([1 if countthai(w) > 50 else 0 for w in sent])\n",
    "        \n",
    "        \n",
    "    \n",
    "    uwords = set()\n",
    "    for sent in words:\n",
    "        uwords.update(sent)\n",
    "    \n",
    "    # Lexicon \n",
    "    lex = []\n",
    "    for sidx, sent in enumerate(words):\n",
    "        for widx, w in enumerate(sent):\n",
    "            if w not in lexicons_keys:\n",
    "                continue \n",
    "            \n",
    "            s = \"\".join(sent[widx:])\n",
    "            for l in lexicons_keys[w]:\n",
    "                if not s.startswith(l):\n",
    "                    continue\n",
    "\n",
    "                lex.extend(lexicons[l])\n",
    "#                 print(\">>\", w, l, lexicons[l])\n",
    "\n",
    "    lexcat = {}\n",
    "    for l in lex:\n",
    "        if l not in lexcat:\n",
    "            lexcat[l] = 0\n",
    "        lexcat[l] += 1\n",
    "    \n",
    "    # Stylistic words\n",
    "    nrepeat = 0\n",
    "    for sidx, sent in enumerate(words):\n",
    "        nrepeat += sum([1 if w==\"rep\" else 0 for w in sent])\n",
    "    \n",
    "    s = \" \".join(texts)\n",
    "    nemoji = emoji.emoji_count(s)\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"nsent\": len(texts),\n",
    "        \"nword\": sum([len(w) for w in words]),\n",
    "        \"ndict\": ndict,\n",
    "        \"nunique\": len(uwords),\n",
    "        \"nlongword\": nlongword,\n",
    "        \"nrepeat\": nrepeat,\n",
    "        \"nthai\": nthai,\n",
    "        \"nemoji\": nemoji,\n",
    "        **lexcat\n",
    "    }\n",
    "  \n",
    "\n",
    "\n",
    "def analyse_conversation(df):\n",
    "    metrics = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        ms = analyse_conv_per_person(row[\"sys\"])\n",
    "        mu = analyse_conv_per_person(row[\"user\"])\n",
    "        metrics.append((ms, mu))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "analyse_conv_per_person([\"เมิงงงงงงงมันโง่เหมือนควายยยยยยยยย\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28f22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e63519",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14df6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj_values(filepath, obj):\n",
    "  with open(filepath, 'wb') as fin:\n",
    "    pickle.dump(obj, fin)\n",
    "    \n",
    "def load_obj_values(filepath):\n",
    "  with open(filepath, 'rb') as fin:\n",
    "    obj = pickle.load(fin)\n",
    "  return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05a13ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_values = {\n",
    "    \"closeness\": [None, None, None],\n",
    "    \"authority\": [None, None, None],\n",
    "}\n",
    "\n",
    "analysis_labels = {\n",
    "    \"closeness\": [None, None, None],\n",
    "    \"authority\": [None, None, None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07ac4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_task1_conver(\"./Task1/annotated_conersations.jsonl\", \"closeness\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"closeness\"][0] = metrics\n",
    "# analysis_labels[\"closeness\"][0] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task2_conver(\"./Task2/annotated/annotated.jsonl\", \"closeness\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"closeness\"][1] = metrics\n",
    "# analysis_labels[\"closeness\"][1] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task1_conver(\"./Task3/annotated/annotated.jsonl\", \"closeness\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"closeness\"][2] = metrics\n",
    "# analysis_labels[\"closeness\"][2] = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe536b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_task1_conver(\"./Task1/annotated_conersations.jsonl\", \"authority\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"authority\"][0] = metrics\n",
    "# analysis_labels[\"authority\"][0] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task2_conver(\"./Task2/annotated/annotated.jsonl\", \"authority\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"authority\"][1] = metrics\n",
    "# analysis_labels[\"authority\"][1] = df[\"label\"].values\n",
    "\n",
    "\n",
    "# df = get_task1_conver(\"./Task3/annotated/annotated.jsonl\", \"authority\", skips = [])\n",
    "# metrics = analyse_conversation(df)\n",
    "# analysis_values[\"authority\"][2] = metrics\n",
    "# analysis_labels[\"authority\"][2] = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16fbe703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_obj_values(\"analysis_values.pkl\", analysis_values)\n",
    "# save_obj_values(\"analysis_labels.pkl\", analysis_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af1b2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_values = load_obj_values(\"analysis_values.pkl\")\n",
    "analysis_labels = load_obj_values(\"analysis_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d8bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b7098221",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = {\n",
    "    \"Conversational Statistics\" : {\n",
    "        \"nsent\": \"Number of utterance\",\n",
    "        \"nword\": \"Number of word\",\n",
    "    },\n",
    "    \"Linguistic Complexity\" : {\n",
    "        \"nunique\": \"Unique lexicons\",\n",
    "        \"nthai\": \"Code-switching\",\n",
    "        \"nlongword\": \"Long words\",\n",
    "        \"ndict\": \"Dictionary words\",\n",
    "        \"transliterated\": \"Transliteration\",\n",
    "    },\n",
    "    \"Pronoun\": {\n",
    "#         \"pronoun\": \"All pronoun\",\n",
    "        \"pronoun_1st\": \">> 1st person pronoun\",\n",
    "        \"pronoun_2nd\": \">> 2nd person pronoun\",\n",
    "        \"pronoun_3rd\": \">> 3rd person pronoun\",\n",
    "        \"pronoun_misspelling\": \">> Pronoun in non-standard spelling\",\n",
    "    },\n",
    "    \n",
    "    \"Sentence-ending Particles\": {\n",
    "#         \"pronoun\": \"All particles\",\n",
    "        \"particles_SARP\": \">> Socially-related particles\",\n",
    "        \"particles_notSARP\": \">> Non-socially-related particles\",\n",
    "        \"particles_misspelling\": \">> Particle in non-standard spelling\",\n",
    "    },\n",
    "    \n",
    "    \"Sentiment-related\": {\n",
    "#         \"sentiment\": \"Sentiment words\",\n",
    "        \"sentiment_positive\": \">> Positive words\",\n",
    "        \"sentiment_negative\": \">> Negative words\",\n",
    "    },\n",
    "    \n",
    "    \"Spelling variation\": {\n",
    "#         \"misspelling\": \"Spelling variation\",\n",
    "        \"misspelling_common\": \">> Common misspelt words\",\n",
    "        \"misspelling_intention\": \">> Morphophonemic variation\",\n",
    "        \"misspelling_shorten\": \">> Simplified variation\",\n",
    "        \"nrepeat\": \">> Repeated characters\",\n",
    "    },\n",
    "    \"Other Common Internet Lexicons\": {\n",
    "        \"abbr\": \"Abbreviation\",\n",
    "#         \"slang\": \"Slang\",\n",
    "        \"swear\": \"Swear words\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "aaf894e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clse_print_labels = ['1. Close', '2. Know each other', \"3. Don't know each other\", \"4. Don't like each other\"]\n",
    "auth_print_labels = ['0. Very respect', '1. Respect', '2. Normal', '3. Not respect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad66f10",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "85b93ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_features(analysis_values, analysis_labels, factor, setting, to_vec_func, skips=[]):\n",
    "    values = analysis_values[factor][setting]\n",
    "    labels = analysis_labels[factor][setting]\n",
    "    assert(len(values)==len(labels))\n",
    "    \n",
    "    rows = []\n",
    "    for (ms, mu), l in zip(values, labels):\n",
    "        if l in skips:\n",
    "            continue\n",
    "        \n",
    "        x = {}\n",
    "        for m in mu:\n",
    "            if m in [\"nsent\", \"nword\"]:\n",
    "                continue\n",
    "            x[m] = mu[m]*100/mu[\"nword\"]\n",
    "        \n",
    "        if \"particles_SARP\" in x:\n",
    "            x[\"particles_notSARP\"] = x[\"particles\"] - x[\"particles_SARP\"]\n",
    "                \n",
    "        y = to_vec_func(l)\n",
    "        rows.append({\n",
    "            **x,\n",
    "            **y\n",
    "        })\n",
    "            \n",
    "    feats = pd.DataFrame(rows)\n",
    "    feats.dropna(subset=[\"y\"], inplace=True)\n",
    "    feats.drop(columns=['particles_??', \"nemoji\", \"slang\"], inplace=True)  ## drop unused features\n",
    "    feats.drop(columns=['sentiment', \"misspelling\", \"particles\", \"pronoun\"], inplace=True) ## drop overal features\n",
    "    feats.fillna(0, inplace=True)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "fceb9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "def print_anova_test(feats):\n",
    "    x_columns = [col for col in feats.columns if col!=\"y\"]\n",
    "    X = feats[x_columns]\n",
    "    X = sm.add_constant(X)\n",
    "    Y = feats[\"y\"]\n",
    "    model = sm.OLS(Y,X)\n",
    "    results = model.fit()\n",
    "\n",
    "    \n",
    "    ncoef = len(x_columns)+1\n",
    "    \n",
    "    t_test = results.t_test(np.identity(ncoef))\n",
    "    f_test = results.f_test(np.identity(ncoef))\n",
    "    \n",
    "    weights = []\n",
    "    for i, col in enumerate([\"bias\"]+x_columns):\n",
    "        o = {\n",
    "            \"feat\": col, \n",
    "            \"coef\": t_test.effect[i], \n",
    "            \"pval\": t_test.pvalue[i]\n",
    "        }\n",
    "\n",
    "        weights.append(o)\n",
    "    \n",
    "    outputs = pd.DataFrame(weights)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860eae70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9b7e208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_weights(outputs, coef_labels, labels, base_category=None):\n",
    "    \n",
    "#     coefs = {}\n",
    "#     non_coefs = {}\n",
    "#     for i, label in enumerate(coef_labels):\n",
    "#         if i==0:\n",
    "#             continue\n",
    "            \n",
    "#         cond = outputs[f\"pval{i}\"] < 0.05\n",
    "#         for _, row in outputs[cond].sort_values(f\"coef{i}\", ascending=False).iterrows():\n",
    "#             coefs[(label, row[\"feat\"])] = row[f\"coef{i}\"]\n",
    "        \n",
    "#         cond = outputs[f\"pval{i}\"] >= 0.05\n",
    "#         for _, row in outputs[cond].iterrows():\n",
    "#             non_coefs[(label, row[\"feat\"])] = row[f\"coef{i}\"]\n",
    "\n",
    "# #     print(coefs)\n",
    "#     for g in metric_names:\n",
    "#         print(\"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "#         for m in metric_names[g]:\n",
    "#             s = f\"{metric_names[g][m]} \"\n",
    "#             for l in labels:\n",
    "#                 if l == base_category:\n",
    "#                     s += f\"& * \"\n",
    "#                 elif (l, m) in coefs:\n",
    "#                     val = coefs[(l, m)]\n",
    "#                     s += \"& \\cellcolor{gray!25} \"+f\"{val:.2f} \"\n",
    "#                 elif (l, m) in non_coefs:\n",
    "#                     val = non_coefs[(l, m)]\n",
    "#                     s += f\"& {val:.2f} \"\n",
    "#                 else:\n",
    "#                     s += f\"& - \"\n",
    "\n",
    "#             s += \"\\\\\\\\\"\n",
    "#             print(s)\n",
    "#         print(\"&  & &  & \\\\\\\\\")\n",
    "#         print(\"\\hline\")\n",
    "\n",
    "# # gray!25 < gray!50 < gray!80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574751f3-cfd7-49fe-9bbd-bdfc44bf37a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123595e1-f763-455a-87a6-62bc1fc253fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f82a11-1c8c-45b6-8b02-1a05e1563a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "11badd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nunique</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>9.589083e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nlongword</td>\n",
       "      <td>-0.009592</td>\n",
       "      <td>3.403139e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nrepeat</td>\n",
       "      <td>-0.017450</td>\n",
       "      <td>4.691556e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nthai</td>\n",
       "      <td>-0.002816</td>\n",
       "      <td>1.038987e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pronoun_3rd</td>\n",
       "      <td>0.029463</td>\n",
       "      <td>6.240134e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>particles_SARP</td>\n",
       "      <td>-0.015084</td>\n",
       "      <td>3.821109e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>particles_notSARP</td>\n",
       "      <td>-0.022674</td>\n",
       "      <td>1.357549e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>misspelling_common</td>\n",
       "      <td>0.019376</td>\n",
       "      <td>4.922897e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feat      coef          pval\n",
       "2              nunique  0.008239  9.589083e-08\n",
       "3            nlongword -0.009592  3.403139e-02\n",
       "4              nrepeat -0.017450  4.691556e-03\n",
       "5                nthai -0.002816  1.038987e-02\n",
       "10         pronoun_3rd  0.029463  6.240134e-06\n",
       "13      particles_SARP -0.015084  3.821109e-16\n",
       "14   particles_notSARP -0.022674  1.357549e-09\n",
       "18  misspelling_common  0.019376  4.922897e-02"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def closeness_to_vec1(label):\n",
    "    if label == \"1. Close\":\n",
    "        return {\"y\": 1}\n",
    "    elif label == \"2. Know each other\":\n",
    "        return {\"y\": 0.5}\n",
    "    elif label == \"3. Don't know each other\": \n",
    "        return {\"y\": 0}\n",
    "    elif label == \"4. Don't like each other\":\n",
    "        return {}\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 0, closeness_to_vec1, skips=[])\n",
    "clos1_weights = print_anova_test(feats)\n",
    "clos1_weights[clos1_weights[\"pval\"]<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0d71119f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ndict', 'nunique', 'nlongword', 'nrepeat', 'nthai',\n",
       "       'sentiment_positive', 'misspelling_shorten', 'misspelling_intention',\n",
       "       'pronoun_2nd', 'pronoun_3rd', 'pronoun_1st', 'sentiment_negative', 'y',\n",
       "       'particles_SARP', 'particles_notSARP', 'transliterated',\n",
       "       'particles_misspelling', 'abbr', 'misspelling_common',\n",
       "       'pronoun_misspelling', 'swear'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "33e733fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bias</td>\n",
       "      <td>0.513089</td>\n",
       "      <td>0.021404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nunique</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>0.000595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nrepeat</td>\n",
       "      <td>0.018699</td>\n",
       "      <td>0.002118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nthai</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.048193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>misspelling_intention</td>\n",
       "      <td>-0.004532</td>\n",
       "      <td>0.040372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pronoun_2nd</td>\n",
       "      <td>-0.010224</td>\n",
       "      <td>0.037646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sentiment_negative</td>\n",
       "      <td>-0.011951</td>\n",
       "      <td>0.028246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>particles_notSARP</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.024519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>swear</td>\n",
       "      <td>0.030411</td>\n",
       "      <td>0.042311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feat      coef      pval\n",
       "0                    bias  0.513089  0.021404\n",
       "2                 nunique -0.005109  0.000595\n",
       "4                 nrepeat  0.018699  0.002118\n",
       "5                   nthai  0.002102  0.048193\n",
       "8   misspelling_intention -0.004532  0.040372\n",
       "9             pronoun_2nd -0.010224  0.037646\n",
       "12     sentiment_negative -0.011951  0.028246\n",
       "14      particles_notSARP  0.007933  0.024519\n",
       "20                  swear  0.030411  0.042311"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def authority_to_vec1(label):\n",
    "    if label == '0. Very respect':\n",
    "        return {\"y\":1}\n",
    "    elif label == '1. Respect': \n",
    "        return {\"y\":0.5}\n",
    "    elif label == '2. Normal':\n",
    "        return {\"y\":0}\n",
    "    elif label == '3. Not respect':\n",
    "        return {}\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 0, authority_to_vec1, skips=[\"3. Not respect\"])\n",
    "auth1_weights = print_anova_test(feats)\n",
    "auth1_weights[auth1_weights[\"pval\"]<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50750d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366bdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "eeb1c491-f902-4174-b929-bb29eed0a5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ndict</td>\n",
       "      <td>-0.001105</td>\n",
       "      <td>2.485390e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nunique</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>1.318220e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nrepeat</td>\n",
       "      <td>0.009112</td>\n",
       "      <td>6.427944e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>misspelling_intention</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>1.106582e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sentiment_positive</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>8.544853e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>swear</td>\n",
       "      <td>0.035813</td>\n",
       "      <td>1.042942e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feat      coef          pval\n",
       "1                   ndict -0.001105  2.485390e-02\n",
       "2                 nunique  0.002773  1.318220e-04\n",
       "4                 nrepeat  0.009112  6.427944e-07\n",
       "7   misspelling_intention  0.002114  1.106582e-02\n",
       "15     sentiment_positive  0.003068  8.544853e-03\n",
       "20                  swear  0.035813  1.042942e-08"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 1, closeness_to_vec1, skips=[])\n",
    "clos2_weights = print_anova_test(feats)\n",
    "clos2_weights[clos2_weights[\"pval\"]<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "01b579e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bias</td>\n",
       "      <td>0.765414</td>\n",
       "      <td>1.460918e-64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ndict</td>\n",
       "      <td>-0.003231</td>\n",
       "      <td>6.637271e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nrepeat</td>\n",
       "      <td>-0.002480</td>\n",
       "      <td>2.882226e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>misspelling_shorten</td>\n",
       "      <td>-0.002634</td>\n",
       "      <td>1.611300e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>misspelling_intention</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>2.199503e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>particles_SARP</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>3.157573e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sentiment_negative</td>\n",
       "      <td>-0.006481</td>\n",
       "      <td>1.458833e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sentiment_positive</td>\n",
       "      <td>0.006552</td>\n",
       "      <td>4.455281e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>particles_notSARP</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>3.105326e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pronoun_misspelling</td>\n",
       "      <td>-0.005534</td>\n",
       "      <td>3.538780e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>swear</td>\n",
       "      <td>-0.008440</td>\n",
       "      <td>1.394290e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>abbr</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>2.327243e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feat      coef          pval\n",
       "0                    bias  0.765414  1.460918e-64\n",
       "1                   ndict -0.003231  6.637271e-21\n",
       "4                 nrepeat -0.002480  2.882226e-02\n",
       "6     misspelling_shorten -0.002634  1.611300e-05\n",
       "7   misspelling_intention  0.002382  2.199503e-05\n",
       "8          particles_SARP  0.006336  3.157573e-09\n",
       "9      sentiment_negative -0.006481  1.458833e-12\n",
       "10     sentiment_positive  0.006552  4.455281e-16\n",
       "11      particles_notSARP  0.005035  3.105326e-03\n",
       "17    pronoun_misspelling -0.005534  3.538780e-02\n",
       "19                  swear -0.008440  1.394290e-09\n",
       "20                   abbr  0.005448  2.327243e-02"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def authority_to_vec2(label):\n",
    "    if label == '0. Very respect':\n",
    "        return {}\n",
    "    elif label == '1. Respect': \n",
    "        return {\"y\":1}\n",
    "    elif label == '2. Normal':\n",
    "        return {\"y\":0.5}\n",
    "    elif label == '3. Not respect':\n",
    "        return {\"y\":0}\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 1, authority_to_vec2)\n",
    "auth2_weights = print_anova_test(feats)\n",
    "auth2_weights[auth2_weights[\"pval\"]<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c34d3-bd59-41d5-985e-299161b6d308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108492a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "3de7ffca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bias</td>\n",
       "      <td>0.479821</td>\n",
       "      <td>5.318368e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nunique</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>3.062918e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nlongword</td>\n",
       "      <td>-0.009839</td>\n",
       "      <td>3.495579e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nthai</td>\n",
       "      <td>-0.002172</td>\n",
       "      <td>1.141511e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sentiment_positive</td>\n",
       "      <td>-0.003576</td>\n",
       "      <td>2.052889e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pronoun_3rd</td>\n",
       "      <td>0.016256</td>\n",
       "      <td>4.871385e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pronoun_1st</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>1.680557e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sentiment_negative</td>\n",
       "      <td>0.010343</td>\n",
       "      <td>2.716573e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>particles_SARP</td>\n",
       "      <td>-0.008501</td>\n",
       "      <td>3.433633e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>particles_notSARP</td>\n",
       "      <td>-0.009353</td>\n",
       "      <td>3.550289e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feat      coef          pval\n",
       "0                 bias  0.479821  5.318368e-04\n",
       "2              nunique  0.003898  3.062918e-05\n",
       "3            nlongword -0.009839  3.495579e-04\n",
       "5                nthai -0.002172  1.141511e-03\n",
       "6   sentiment_positive -0.003576  2.052889e-02\n",
       "10         pronoun_3rd  0.016256  4.871385e-05\n",
       "11         pronoun_1st  0.012241  1.680557e-03\n",
       "12  sentiment_negative  0.010343  2.716573e-03\n",
       "13      particles_SARP -0.008501  3.433633e-14\n",
       "14   particles_notSARP -0.009353  3.550289e-05"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 2, closeness_to_vec1, skips=[])\n",
    "clos3_weights = print_anova_test(feats)\n",
    "clos3_weights[clos3_weights[\"pval\"]<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "550f18a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bias</td>\n",
       "      <td>0.625286</td>\n",
       "      <td>3.949011e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nlongword</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>4.376929e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nrepeat</td>\n",
       "      <td>-0.007839</td>\n",
       "      <td>2.063218e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nthai</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>9.519263e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>misspelling_shorten</td>\n",
       "      <td>-0.003570</td>\n",
       "      <td>9.866583e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pronoun_1st</td>\n",
       "      <td>-0.005934</td>\n",
       "      <td>2.098490e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>particles_SARP</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>3.235055e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>abbr</td>\n",
       "      <td>-0.011162</td>\n",
       "      <td>2.693347e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pronoun_misspelling</td>\n",
       "      <td>-0.008525</td>\n",
       "      <td>2.873819e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>swear</td>\n",
       "      <td>-0.015337</td>\n",
       "      <td>1.369579e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feat      coef          pval\n",
       "0                  bias  0.625286  3.949011e-11\n",
       "3             nlongword  0.005317  4.376929e-03\n",
       "4               nrepeat -0.007839  2.063218e-03\n",
       "5                 nthai  0.002225  9.519263e-07\n",
       "7   misspelling_shorten -0.003570  9.866583e-04\n",
       "11          pronoun_1st -0.005934  2.098490e-02\n",
       "13       particles_SARP  0.003519  3.235055e-06\n",
       "17                 abbr -0.011162  2.693347e-02\n",
       "19  pronoun_misspelling -0.008525  2.873819e-02\n",
       "20                swear -0.015337  1.369579e-02"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 2, authority_to_vec2)\n",
    "auth3_weights = print_anova_test(feats)\n",
    "auth3_weights[auth3_weights[\"pval\"]<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9cedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "e46a1405-2b91-495b-b7c9-c393c8816fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clos3_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89049f3f",
   "metadata": {},
   "source": [
    "### Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "035f2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\n",
    "    \"Setting 1: Private Conversations with Self-Reported Labels\",\n",
    "    \"Setting 2: Public Conversations with Labels from 3rd Party \",\n",
    "    \"Setting 3: Private Conversations with Labels from 3rd Party \",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b7824106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputs_to_dict(outputs):\n",
    "    coefs = {}\n",
    "    \n",
    "    for _, row in outputs.iterrows():\n",
    "        coefs[row[\"feat\"]] = (row[\"coef\"], row[\"pval\"])\n",
    "\n",
    "    return coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7398c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259b1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471573ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f696abce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "925d851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "printed_text = \"\" \n",
    "printed_text += \"\\subsection{Closeness}\"+\"\\n\"\n",
    "outputs = [\n",
    "    outputs_to_dict(clos1_weights),\n",
    "    outputs_to_dict(clos2_weights),\n",
    "    outputs_to_dict(clos3_weights)\n",
    "]\n",
    "\n",
    "printed_text += \"\\\\begin{longtable}[h]{\"+\"\\n\"\n",
    "printed_text += \"    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\"+\"\\n\"\n",
    "\n",
    "printed_text += \"    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "printed_text += \"    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "printed_text += \"    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "\n",
    "printed_text += \"}\"+\"\\n\"\n",
    "printed_text += \"    \\hline\"+\"\\n\"\n",
    "printed_text += \"    Lexical Features & Setting 1  & Setting 2 & Setting 3 \\\\\\\\\"+\"\\n\"\n",
    "printed_text += \"    \\hline\"+\"\\n\"\n",
    "#     printed_text += \"    \\endfirsthead\"+\"\\n\"\n",
    "#     printed_text += \"\"+\"\\n\"\n",
    "printed_text += \"    \\endhead\"+\"\\n\"\n",
    "printed_text += \"\"+\"\\n\"\n",
    "\n",
    "# for sec, results in zip(sections, outputs):\n",
    "for g in metric_names:\n",
    "    if g in [\"Conversational Statistics\"]:\n",
    "        continue\n",
    "\n",
    "    printed_text += \"    \\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "    printed_text += \"    \\hline\"+\"\\n\"\n",
    "\n",
    "    for m in metric_names[g]:\n",
    "        s = f\"        {metric_names[g][m]} \"\n",
    "        for out in outputs:\n",
    "            if m not in out:\n",
    "                s += f\"& - \"\n",
    "            else:\n",
    "                val, pval = out[m]\n",
    "\n",
    "                if pval < 0.05:\n",
    "                    s += \"& \\cellcolor{gray!25} \"+f\"{val:.2e} \"\n",
    "                else:\n",
    "                    s += f\"& {val:.2e} \"\n",
    "        s += \"\\\\\\\\\"\n",
    "        # print(s)\n",
    "        printed_text += s+\"\\n\"\n",
    "\n",
    "\n",
    "    printed_text += \"        &  & &\\\\\\\\\"+\"\\n\"\n",
    "    printed_text += \"    \\hline\"+\"\\n\"\n",
    "    printed_text += \"\"+\"\\n\"\n",
    "printed_text += \"\\label{closeness_linear_weights}\"+\"\\n\"\n",
    "printed_text += \"\\end{longtable}\"+\"\\n\"\n",
    "printed_text += \"\\clearpage\"+\"\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8325a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "printed_text += \"\\subsection{Respect}\"+\"\\n\"\n",
    "outputs = [\n",
    "    outputs_to_dict(auth1_weights),\n",
    "    outputs_to_dict(auth2_weights),\n",
    "    outputs_to_dict(auth3_weights)\n",
    "]\n",
    "\n",
    "printed_text += \"\\\\begin{longtable}[h]{\"+\"\\n\"\n",
    "printed_text += \"    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\"+\"\\n\"\n",
    "\n",
    "printed_text += \"    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "printed_text += \"    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "printed_text += \"    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "\n",
    "printed_text += \"}\"+\"\\n\"\n",
    "printed_text += \"    \\hline\"+\"\\n\"\n",
    "printed_text += \"    Lexical Features & Setting 1  & Setting 2 & Setting 3 \\\\\\\\\"+\"\\n\"\n",
    "printed_text += \"    \\hline\"+\"\\n\"\n",
    "#     printed_text += \"    \\endfirsthead\"+\"\\n\"\n",
    "#     printed_text += \"\"+\"\\n\"\n",
    "printed_text += \"    \\endhead\"+\"\\n\"\n",
    "printed_text += \"\"+\"\\n\"\n",
    "\n",
    "# for sec, results in zip(sections, outputs):\n",
    "for g in metric_names:\n",
    "    if g in [\"Conversational Statistics\"]:\n",
    "        continue\n",
    "\n",
    "    printed_text += \"    \\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "    printed_text += \"    \\hline\"+\"\\n\"\n",
    "\n",
    "    for m in metric_names[g]:\n",
    "        s = f\"        {metric_names[g][m]} \"\n",
    "        for out in outputs:\n",
    "            if m not in out:\n",
    "                s += f\"& - \"\n",
    "            else:\n",
    "                val, pval = out[m]\n",
    "\n",
    "                if pval < 0.05:\n",
    "                    s += \"& \\cellcolor{gray!25} \"+f\"{val:.2e} \"\n",
    "                else:\n",
    "                    s += f\"& {val:.2e} \"\n",
    "        s += \"\\\\\\\\\"\n",
    "        # print(s)\n",
    "        printed_text += s+\"\\n\"\n",
    "\n",
    "\n",
    "    printed_text += \"        &  & &\\\\\\\\\"+\"\\n\"\n",
    "    printed_text += \"    \\hline\"+\"\\n\"\n",
    "    printed_text += \"\"+\"\\n\"\n",
    "printed_text += \"\\label{closeness_linear_weights}\"+\"\\n\"\n",
    "printed_text += \"\\end{longtable}\"+\"\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4c1ce27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\subsection{Closeness}\n",
      "\\begin{longtable}[h]{\n",
      "    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "}\n",
      "    \\hline\n",
      "    Lexical Features & Setting 1  & Setting 2 & Setting 3 \\\\\n",
      "    \\hline\n",
      "    \\endhead\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Linguistic Complexity}} \\\\\n",
      "    \\hline\n",
      "        Unique lexicons & \\cellcolor{gray!25} 8.24e-03 & \\cellcolor{gray!25} 2.77e-03 & \\cellcolor{gray!25} 3.90e-03 \\\\\n",
      "        Code-switching & \\cellcolor{gray!25} -2.82e-03 & -9.27e-05 & \\cellcolor{gray!25} -2.17e-03 \\\\\n",
      "        Long words & \\cellcolor{gray!25} -9.59e-03 & -1.00e-03 & \\cellcolor{gray!25} -9.84e-03 \\\\\n",
      "        Dictionary words & -3.01e-03 & \\cellcolor{gray!25} -1.10e-03 & -8.73e-04 \\\\\n",
      "        Transliteration & -7.26e-03 & -2.52e-03 & -9.70e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Pronoun}} \\\\\n",
      "    \\hline\n",
      "        >> 1st person pronoun & 1.11e-02 & 5.16e-03 & \\cellcolor{gray!25} 1.22e-02 \\\\\n",
      "        >> 2nd person pronoun & -3.91e-03 & -9.53e-04 & -6.55e-04 \\\\\n",
      "        >> 3rd person pronoun & \\cellcolor{gray!25} 2.95e-02 & 3.04e-03 & \\cellcolor{gray!25} 1.63e-02 \\\\\n",
      "        >> Pronoun in non-standard spelling & 9.02e-03 & -8.80e-04 & 8.06e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "    \\hline\n",
      "        >> Socially-related particles & \\cellcolor{gray!25} -1.51e-02 & -2.74e-03 & \\cellcolor{gray!25} -8.50e-03 \\\\\n",
      "        >> Non-socially-related particles & \\cellcolor{gray!25} -2.27e-02 & -3.16e-03 & \\cellcolor{gray!25} -9.35e-03 \\\\\n",
      "        >> Particle in non-standard spelling & 1.12e-02 & -3.35e-03 & 7.68e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Sentiment-related}} \\\\\n",
      "    \\hline\n",
      "        >> Positive words & -4.14e-03 & \\cellcolor{gray!25} 3.07e-03 & \\cellcolor{gray!25} -3.58e-03 \\\\\n",
      "        >> Negative words & 2.09e-03 & -6.45e-04 & \\cellcolor{gray!25} 1.03e-02 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Spelling variation}} \\\\\n",
      "    \\hline\n",
      "        >> Common misspelt words & \\cellcolor{gray!25} 1.94e-02 & -3.72e-03 & 6.76e-03 \\\\\n",
      "        >> Morphophonemic variation & -2.96e-04 & \\cellcolor{gray!25} 2.11e-03 & 1.87e-03 \\\\\n",
      "        >> Simplified variation & -4.93e-03 & 9.66e-04 & 1.09e-03 \\\\\n",
      "        >> Repeated characters & \\cellcolor{gray!25} -1.74e-02 & \\cellcolor{gray!25} 9.11e-03 & 1.90e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Other Common Internet Lexicons}} \\\\\n",
      "    \\hline\n",
      "        Abbreviation & -7.67e-03 & 8.31e-04 & -1.16e-02 \\\\\n",
      "        Swear words & 9.89e-03 & \\cellcolor{gray!25} 3.58e-02 & -7.59e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "\\label{closeness_linear_weights}\n",
      "\\end{longtable}\n",
      "\\clearpage\n",
      "\\subsection{Respect}\n",
      "\\begin{longtable}[h]{\n",
      "    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "}\n",
      "    \\hline\n",
      "    Lexical Features & Setting 1  & Setting 2 & Setting 3 \\\\\n",
      "    \\hline\n",
      "    \\endhead\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Linguistic Complexity}} \\\\\n",
      "    \\hline\n",
      "        Unique lexicons & \\cellcolor{gray!25} -5.11e-03 & -8.23e-04 & -3.88e-04 \\\\\n",
      "        Code-switching & \\cellcolor{gray!25} 2.10e-03 & 2.34e-04 & \\cellcolor{gray!25} 2.22e-03 \\\\\n",
      "        Long words & 5.28e-03 & 1.11e-03 & \\cellcolor{gray!25} 5.32e-03 \\\\\n",
      "        Dictionary words & 2.22e-03 & \\cellcolor{gray!25} -3.23e-03 & -9.78e-04 \\\\\n",
      "        Transliteration & -2.55e-02 & -1.67e-03 & -1.10e-02 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Pronoun}} \\\\\n",
      "    \\hline\n",
      "        >> 1st person pronoun & -9.73e-04 & 1.85e-03 & \\cellcolor{gray!25} -5.93e-03 \\\\\n",
      "        >> 2nd person pronoun & \\cellcolor{gray!25} -1.02e-02 & -1.83e-03 & -2.80e-03 \\\\\n",
      "        >> 3rd person pronoun & 5.57e-03 & -4.40e-04 & 3.33e-03 \\\\\n",
      "        >> Pronoun in non-standard spelling & 3.41e-03 & \\cellcolor{gray!25} -5.53e-03 & \\cellcolor{gray!25} -8.52e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "    \\hline\n",
      "        >> Socially-related particles & 3.03e-03 & \\cellcolor{gray!25} 6.34e-03 & \\cellcolor{gray!25} 3.52e-03 \\\\\n",
      "        >> Non-socially-related particles & \\cellcolor{gray!25} 7.93e-03 & \\cellcolor{gray!25} 5.03e-03 & 2.92e-03 \\\\\n",
      "        >> Particle in non-standard spelling & 4.67e-03 & -3.49e-03 & -3.16e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Sentiment-related}} \\\\\n",
      "    \\hline\n",
      "        >> Positive words & 2.10e-03 & \\cellcolor{gray!25} 6.55e-03 & 1.67e-03 \\\\\n",
      "        >> Negative words & \\cellcolor{gray!25} -1.20e-02 & \\cellcolor{gray!25} -6.48e-03 & -1.76e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Spelling variation}} \\\\\n",
      "    \\hline\n",
      "        >> Common misspelt words & -1.03e-02 & 3.00e-03 & 2.70e-03 \\\\\n",
      "        >> Morphophonemic variation & \\cellcolor{gray!25} -4.53e-03 & \\cellcolor{gray!25} 2.38e-03 & 1.11e-03 \\\\\n",
      "        >> Simplified variation & -1.10e-03 & \\cellcolor{gray!25} -2.63e-03 & \\cellcolor{gray!25} -3.57e-03 \\\\\n",
      "        >> Repeated characters & \\cellcolor{gray!25} 1.87e-02 & \\cellcolor{gray!25} -2.48e-03 & \\cellcolor{gray!25} -7.84e-03 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "    \\multicolumn{4}{l}{\\textit{Other Common Internet Lexicons}} \\\\\n",
      "    \\hline\n",
      "        Abbreviation & -1.12e-02 & \\cellcolor{gray!25} 5.45e-03 & \\cellcolor{gray!25} -1.12e-02 \\\\\n",
      "        Swear words & \\cellcolor{gray!25} 3.04e-02 & \\cellcolor{gray!25} -8.44e-03 & \\cellcolor{gray!25} -1.53e-02 \\\\\n",
      "        &  & &\\\\\n",
      "    \\hline\n",
      "\n",
      "\\label{closeness_linear_weights}\n",
      "\\end{longtable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74abbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc15ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a22a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c8ae0ea",
   "metadata": {},
   "source": [
    "### Evaluate Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e8d08c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from random import random\n",
    "\n",
    "def get_data_from_df_to_data(df):\n",
    "    x_columns = [col for col in df.columns if col!=\"y\"]\n",
    "    X = df[x_columns]\n",
    "    X = sm.add_constant(X)\n",
    "    Y = df[\"y\"]\n",
    "    \n",
    "    return X, Y\n",
    "    \n",
    "def train_model(feats, random_state=42, random_guess=False):\n",
    "    d = feats.sample(frac=1, random_state=random_state)\n",
    "    train, test = np.split(d, [int(0.9*len(d))])\n",
    "#     train, validate, test = np.split(d, [int(0.8*len(d)), int(0.9*len(d))])\n",
    "    \n",
    "    Xtrain, Ytrain = get_data_from_df_to_data(train)\n",
    "    model = sm.OLS(Ytrain,Xtrain)\n",
    "    M = model.fit()\n",
    "    \n",
    "#     Xval, Yval = get_data_from_df_to_data(validate)\n",
    "#     thesholds = tune_thesholds(M, Xval, Yval)\n",
    "        \n",
    "    Xtest, Ytest = get_data_from_df_to_data(test)\n",
    "    if random_guess:\n",
    "        predictions = [random() for y in Ytest]\n",
    "    else:\n",
    "        predictions = M.predict(Xtest)\n",
    "    \n",
    "    return np.sqrt(mean_squared_error(Ytest, predictions)), r2_score(Ytest, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7755e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "2d62f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(feats, random_guess=False):\n",
    "    rmse = []\n",
    "    r2 = []\n",
    "    for i in range(100):\n",
    "        _rmse, _r2 = train_model(feats, random_state=i, random_guess=random_guess)\n",
    "        rmse.append(_rmse)\n",
    "        r2.append(_r2)\n",
    "\n",
    "    print(\"RMSE\", np.mean(rmse))\n",
    "    print(\"R2\", np.mean(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "11c33e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_guess=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "d7472591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.40490237548091335\n",
      "R2 0.17288599460124274\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 0, closeness_to_vec1, skips=[])\n",
    "print_accuracy(feats, random_guess=random_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "4454838c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.39518452510090185\n",
      "R2 0.01315226793270619\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 0, authority_to_vec1, skips=[])\n",
    "print_accuracy(feats, random_guess=random_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d650d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "9e5f5c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.3306880896803744\n",
      "R2 0.034903721621206335\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 1, closeness_to_vec1, skips=[])\n",
    "print_accuracy(feats, random_guess=random_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "9167fd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.24797473375388374\n",
      "R2 0.15318322578028065\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 1, authority_to_vec2)\n",
    "print_accuracy(feats, random_guess=random_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d634e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "c58ca858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.24653696225942773\n",
      "R2 0.20312443854909148\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 2, closeness_to_vec1, skips=[])\n",
    "print_accuracy(feats, random_guess=random_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "5cae9d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.16542602154762986\n",
      "R2 0.1188264316478763\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"authority\", 2, authority_to_vec2)\n",
    "print_accuracy(feats, random_guess=random_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23894106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da725a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272d7e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
