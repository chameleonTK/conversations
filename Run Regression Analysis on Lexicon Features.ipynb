{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1877f9b4",
   "metadata": {},
   "source": [
    "## Load Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "93deeee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "import pandas as pd\n",
    "from utils import load_jsonl, dump_jsonl\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87c53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "79f99623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversations(in_dir, col_label, skips=[]):\n",
    "    conversations = load_jsonl(f\"{in_dir}\")\n",
    "    \n",
    "    \n",
    "    def to_message_str(messages, users):\n",
    "        s = []\n",
    "        u = []\n",
    "        for m in messages:\n",
    "            if users[m['user_id']] == \"SYS\":\n",
    "                s.append(m['text'])\n",
    "            else:\n",
    "                u.append(m['text'])\n",
    "                \n",
    "        return s, u\n",
    "        \n",
    "    newdata = []\n",
    "    for row in conversations:\n",
    "        row[\"messages\"].sort(key=lambda x: x[\"date_created\"], reverse=False)\n",
    "        \n",
    "        users = {}\n",
    "        for m in row[\"messages\"]:\n",
    "            if m[\"user_id\"] not in users:\n",
    "#                 username = \"USR\"+str(len(users)+1) if len(users.keys())==0 else \"SYS\"\n",
    "                username = \"USR\" if len(users.keys())==0 else \"SYS\"\n",
    "                users[m[\"user_id\"]] = username\n",
    "                \n",
    "#         if len(users)>2:\n",
    "#             print(\"More than 1 users\", len(users))\n",
    "        \n",
    "        \n",
    "        messages = row[\"messages\"]\n",
    "        chunk_size = 100\n",
    "        for i in range(0, len(messages), chunk_size):\n",
    "            sub_messages = messages[i:i+chunk_size]\n",
    "            s, u = to_message_str(sub_messages, users)\n",
    "            \n",
    "            if pd.isna(row[col_label]):\n",
    "                continue\n",
    "            \n",
    "            if row[col_label] in skips:\n",
    "                continue\n",
    "                \n",
    "            label = row[col_label]\n",
    "                \n",
    "            newdata.append({\n",
    "                \"user\": u,\n",
    "                \"sys\": s,\n",
    "                \"label\": label,\n",
    "                \"nturn\": len(sub_messages)\n",
    "            })\n",
    "        \n",
    "#     n_val = int(len(newdata)*0.05)\n",
    "#     n_test = n_val\n",
    "    \n",
    "#     test = newdata[0:n_test]\n",
    "#     val = newdata[n_test:n_test+n_val]\n",
    "#     train = newdata[n_test+n_val:]\n",
    "    \n",
    "    return pd.DataFrame(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25b1e94-ea48-4819-8271-dadf0dfba19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "92feb049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1234 records from ./Task1/annotated_conersations.jsonl\n",
      "Loaded 2486 records from ./Task2/annotated_conersations.jsonl\n",
      "Loaded 1221 records from ./Task3/annotated_conersations.jsonl\n"
     ]
    }
   ],
   "source": [
    "df1 = get_conversations(\"./Task1/annotated_conersations.jsonl\", \"closeness\", skips = [\"5. Don't like each other\"])\n",
    "df2 = get_conversations(\"./Task2/annotated_conersations.jsonl\", \"closeness\", skips = [\"5. Don't like each other\"])\n",
    "df3 = get_conversations(\"./Task3/annotated_conersations.jsonl\", \"closeness\", skips = [\"5. Don't like each other\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9f123050-8586-4d34-82ed-c31cf5ad3d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>label</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...</td>\n",
       "      <td>[ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...</td>\n",
       "      <td>2. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...</td>\n",
       "      <td>[โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...</td>\n",
       "      <td>1. Very Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...</td>\n",
       "      <td>[อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...</td>\n",
       "      <td>2. Close</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...</td>\n",
       "      <td>[ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...</td>\n",
       "      <td>2. Close</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...</td>\n",
       "      <td>[ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...</td>\n",
       "      <td>2. Close</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                user  \\\n",
       "0  [ดีๆวาย, เป็นยังไงบ้างช่วงนี้, รวยๆ เฮงๆ , เหม...   \n",
       "1  [วันนี้เรามาพูดถึงเรื่องภาพยนตร์กัน, ปกฅิแล้วค...   \n",
       "2  [เธอ, สรุป อ้วนจะซื้อรถเมื่อไหร่, แล้วอ้วนดูรถ...   \n",
       "3  [มึง, แมวมึงเป็นไงกันบ้างอ่ะ, ตอนนี้มีกี่ตัวนะ...   \n",
       "4  [อ้วน, อยากได้แมว, อยากเลี้ยง, เอาไว้ตอนตัวไม่...   \n",
       "\n",
       "                                                 sys          label  nturn  \n",
       "0  [ว่าไงปราง, เหมือนเดิม ขายของ นอนตื่น ขายของ ช...       2. Close     35  \n",
       "1  [โอเคค่ะ, ที่บ้านค่ะ, ดูแทบทุกวันเลย, ดูได้ทุก...  1. Very Close     39  \n",
       "2  [อะไรหมู, กลางปี, ว่าจะเอา  ativ ตัวใหม่, ว่าจ...       2. Close     40  \n",
       "3  [ว่า, เด็กๆหรอ, ซนปกติเลยมึง, 5ตัว, แค่บ้านกูน...       2. Close     35  \n",
       "4  [ไรหมู, เอาไปทำไมแมว, จะหาจากไหน, เดี๋ยวถามให้...       2. Close     39  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "aaa56b86-d927-47ab-a2cc-ffef7a32b5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2. Close', '1. Very Close', '3. Know each other',\n",
       "       \"4. Don't know each other\"], dtype=object)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "554617d6-e691-4d93-acd3-bd65c7e93cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Very Close</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Close</th>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Know each other</th>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. Don't know each other</th>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user  sys  nturn\n",
       "label                                     \n",
       "1. Very Close              102  102    102\n",
       "2. Close                   449  449    449\n",
       "3. Know each other         230  230    230\n",
       "4. Don't know each other   435  435    435"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b648fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "27de11af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Very Close</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Close</th>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Know each other</th>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. Don't know each other</th>\n",
       "      <td>1487</td>\n",
       "      <td>1487</td>\n",
       "      <td>1487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user   sys  nturn\n",
       "label                                      \n",
       "1. Very Close               42    42     42\n",
       "2. Close                   180   180    180\n",
       "3. Know each other         158   158    158\n",
       "4. Don't know each other  1487  1487   1487"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27dfc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "63a42643-11c4-427c-b3c5-662a21a5af31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sys</th>\n",
       "      <th>nturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Very Close</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Close</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Know each other</th>\n",
       "      <td>739</td>\n",
       "      <td>739</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. Don't know each other</th>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user  sys  nturn\n",
       "label                                     \n",
       "1. Very Close               66   66     66\n",
       "2. Close                   289  289    289\n",
       "3. Know each other         739  739    739\n",
       "4. Don't know each other   115  115    115"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d21d30-3555-4593-919c-6f7581ac0a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8d78a46",
   "metadata": {},
   "source": [
    "## Load Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "caafaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bdc8d6c5-4eac-4333-b05f-dcb909a87423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download https://github.com/chameleonTK/thai-dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "755a8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./Lexicons/thai-dictionary/RoyalInstituteDictionary/words.json\", encoding=\"utf-8\") as fin:\n",
    "    raw = json.load(fin)\n",
    "    thaidict_royal = set()\n",
    "    for k in raw:\n",
    "        thaidict_royal.update(raw[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "63a63c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 22991 records from lexicons.jsonl\n"
     ]
    }
   ],
   "source": [
    "lexicons_arr = load_jsonl(\"lexicons.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1bbccb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "tags = set()\n",
    "lexicons = {}\n",
    "lexicons_keys = defaultdict(list)\n",
    "\n",
    "for key, values  in lexicons_arr:\n",
    "    if len(key) <= 1:\n",
    "        continue\n",
    "        \n",
    "    key = key.lower()\n",
    "    if key.endswith(\"rep\"):\n",
    "        key = key.replace(\"rep\", \"\")\n",
    "        \n",
    "    w = word_tokenize(key)\n",
    "    \n",
    "    lexicons_keys[w[0]].append(key)\n",
    "    \n",
    "    tag = [t for t in values[\"tags\"] if not t.startswith(\"cat:\")]\n",
    "    lexicons[key] = tag\n",
    "    tags.update(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "320f0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.util import countthai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12380160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "388acee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "import emoji\n",
    "from pythainlp.util import countthai\n",
    "from tqdm import tqdm\n",
    "\n",
    "def rm_reptitive(text):\n",
    "    s = \"\"\n",
    "    groups = groupby(text)\n",
    "    for label, group in groups:\n",
    "        g = list(group)\n",
    "        if len(g) >= 3:\n",
    "            s += f\"{label*3} rep \"\n",
    "        else:\n",
    "            s += \"\".join(g)\n",
    "    return s\n",
    "\n",
    "def remove_space(sent):\n",
    "    newwords = []\n",
    "    for w in sent:\n",
    "        if len(w.strip())==0:\n",
    "            continue\n",
    "        newwords.append(w)\n",
    "    return newwords\n",
    "\n",
    "import re\n",
    "def notthai(w):\n",
    "    if countthai(w) > 50:\n",
    "        return False\n",
    "    \n",
    "    if w in [\"usr\", \"sys\", \"rep\"]:\n",
    "        return False\n",
    "    \n",
    "    nt = re.sub(r'\\W+', '', w)\n",
    "    if len(nt) > 0 and not nt.isnumeric():\n",
    "#         print(nt)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def analyse_conv_per_person(texts):\n",
    "    \n",
    "    # Word Statistic\n",
    "    texts = [t.lower() for t in texts]\n",
    "    texts = [rm_reptitive(t) for t in texts]\n",
    "    words = [word_tokenize(t) for t in texts]\n",
    "    words = [remove_space(w) for w in words]\n",
    "    \n",
    "    nlongword = 0\n",
    "    ndict = 0\n",
    "    nnotthai = 0\n",
    "    nthai = 0\n",
    "    for sent in words:\n",
    "        ndict += sum([1 if w in thaidict_royal else 0 for w in sent])\n",
    "        nlongword += sum([1 if len(w) > 7 else 0 for w in sent])\n",
    "        nthai += sum([1 if countthai(w) > 50 else 0 for w in sent])\n",
    "            \n",
    "        nnotthai += sum([1 if notthai(w) else 0 for w in sent])\n",
    "    \n",
    "    uwords = set()\n",
    "    for sent in words:\n",
    "        uwords.update(sent)\n",
    "    \n",
    "    # Lexicon \n",
    "    lex = []\n",
    "    for sidx, sent in enumerate(words):\n",
    "        for widx, w in enumerate(sent):\n",
    "            if w not in lexicons_keys:\n",
    "                continue \n",
    "            \n",
    "            s = \"\".join(sent[widx:])\n",
    "            for l in lexicons_keys[w]:\n",
    "                if not s.startswith(l):\n",
    "                    continue\n",
    "\n",
    "                lex.extend(lexicons[l])\n",
    "#                 print(\">>\", w, l, lexicons[l])\n",
    "\n",
    "    lexcat = {}\n",
    "    for l in lex:\n",
    "        if l not in lexcat:\n",
    "            lexcat[l] = 0\n",
    "        lexcat[l] += 1\n",
    "    \n",
    "    # Stylistic words\n",
    "    nrepeat = 0\n",
    "    for sidx, sent in enumerate(words):\n",
    "        nrepeat += sum([1 if w==\"rep\" else 0 for w in sent])\n",
    "    \n",
    "    s = \" \".join(texts)\n",
    "    nemoji = emoji.emoji_count(s)\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"nsent\": len(texts),\n",
    "        \"nword\": sum([len(w) for w in words]),\n",
    "        \"ndict\": ndict,\n",
    "        \"nunique\": len(uwords),\n",
    "        \"nlongword\": nlongword,\n",
    "        \"nrepeat\": nrepeat,\n",
    "        \"nthai\": nthai,\n",
    "        \"nnotthai\": nnotthai,\n",
    "        \"nemoji\": nemoji,\n",
    "        **lexcat\n",
    "    }\n",
    "  \n",
    "\n",
    "\n",
    "def analyse_conversation(df):\n",
    "    metrics = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        ms = analyse_conv_per_person(row[\"sys\"])\n",
    "        mu = analyse_conv_per_person(row[\"user\"])\n",
    "        metrics.append((ms, mu))\n",
    "        \n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# analyse_conv_per_person([\"เมิงงงงงงงมันโง่เหมือนควายยยยยยยยย\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ca28f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1[\"user\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e63519",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "14df6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj_values(filepath, obj):\n",
    "  with open(filepath, 'wb') as fin:\n",
    "    pickle.dump(obj, fin)\n",
    "    \n",
    "def load_obj_values(filepath):\n",
    "  with open(filepath, 'rb') as fin:\n",
    "    obj = pickle.load(fin)\n",
    "  return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "05a13ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_values = {\n",
    "    \"closeness\": [None, None, None],\n",
    "    # \"authority\": [None, None, None],\n",
    "}\n",
    "\n",
    "analysis_labels = {\n",
    "    \"closeness\": [None, None, None],\n",
    "    # \"authority\": [None, None, None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "07ac4a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1234 records from ./Task1/annotated_conersations.jsonl\n",
      "Loaded 2486 records from ./Task2/annotated_conersations.jsonl\n",
      "Loaded 1221 records from ./Task3/annotated_conersations.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1216/1216 [00:02<00:00, 548.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1867/1867 [00:01<00:00, 1107.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1209/1209 [00:02<00:00, 537.45it/s]\n"
     ]
    }
   ],
   "source": [
    "df1 = get_conversations(\"./Task1/annotated_conersations.jsonl\", \"closeness\", skips = [\"5. Don't like each other\"])\n",
    "df2 = get_conversations(\"./Task2/annotated_conersations.jsonl\", \"closeness\", skips = [\"5. Don't like each other\"])\n",
    "df3 = get_conversations(\"./Task3/annotated_conersations.jsonl\", \"closeness\", skips = [\"5. Don't like each other\"])\n",
    "\n",
    "\n",
    "metrics = analyse_conversation(df1)\n",
    "analysis_values[\"closeness\"][0] = metrics\n",
    "analysis_labels[\"closeness\"][0] = df1[\"label\"].values\n",
    "\n",
    "\n",
    "metrics = analyse_conversation(df2)\n",
    "analysis_values[\"closeness\"][1] = metrics\n",
    "analysis_labels[\"closeness\"][1] = df2[\"label\"].values\n",
    "\n",
    "metrics = analyse_conversation(df3)\n",
    "analysis_values[\"closeness\"][2] = metrics\n",
    "analysis_labels[\"closeness\"][2] = df3[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe536b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "16fbe703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_obj_values(\"analysis_values.pkl\", analysis_values)\n",
    "# save_obj_values(\"analysis_labels.pkl\", analysis_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af1b2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_values = load_obj_values(\"analysis_values.pkl\")\n",
    "analysis_labels = load_obj_values(\"analysis_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "439d8bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc = 0\n",
    "# pp = 0\n",
    "# for m in metrics:\n",
    "#     m1, m2 = m\n",
    "#     if \"pronoun\" in m1:\n",
    "#         pp += 1\n",
    "#     if \"pronoun_plural\" in m1:\n",
    "# #         print(m1[\"pronoun_plural\"])\n",
    "#         cc += m1[\"pronoun_plural\"]\n",
    "    \n",
    "# #     if \"pronoun_plural\" in m2:\n",
    "# #         print(m2[\"pronoun_plural\"])\n",
    "\n",
    "# cc/pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff512b96",
   "metadata": {},
   "source": [
    "## Appendix A: Descriptive Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b7098221",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = {\n",
    "    \"Corpus Statistics\" : {\n",
    "        \"nsent\": \"Number of utterance\",\n",
    "        \"nword\": \"Number of word\",\n",
    "        \"nunique\": \"Vocabulary size\",\n",
    "        \"nthai\": \"Thai words\",\n",
    "        \"nnotthai\": \"Non-Thai words\",\n",
    "        \"nlongword\": \"Long words\",\n",
    "        \"ndict\": \"Dictionary words\",\n",
    "        \"transliterated\": \"Transliteration\",\n",
    "    },\n",
    "    \"Pronoun\": {\n",
    "        \"pronoun\": \"All pronoun\",\n",
    "        \"pronoun_1st\": \">> 1st person pronoun\",\n",
    "        \"pronoun_2nd\": \">> 2nd person pronoun\",\n",
    "        \"pronoun_3rd\": \">> 3rd person pronoun\",\n",
    "        \"pronoun_singular\": \">> Singular pronoun\",\n",
    "        \"pronoun_plural\": \">> Plural pronoun\",\n",
    "        \"pronoun_misspelling\": \">> Pronoun in non-standard spelling\",\n",
    "    },\n",
    "    \n",
    "    \"Sentence-ending Particles\": {\n",
    "        \"particles\": \"All particles\",\n",
    "        \"particles_SARP\": \">> Socially-related particles\",\n",
    "        \"particles_notSARP\": \">> Non-socially-related particles\",\n",
    "        \"particles_misspelling\": \">> Particle in non-standard spelling\",\n",
    "    },\n",
    "    \n",
    "#     \"Sentiment-related\": {\n",
    "#         \"sentiment\": \"Sentiment words\",\n",
    "#         \"sentiment_positive\": \">> Positive words\",\n",
    "#         \"sentiment_negative\": \">> Negative words\",\n",
    "#     },\n",
    "    \n",
    "    \"Spelling Variation\": {\n",
    "        \"misspelling\": \"All spelling variation\",\n",
    "        \"misspelling_common\": \">> Common misspelt words\",\n",
    "        \"misspelling_intention\": \">> Morphophonemic variation\",\n",
    "        \"misspelling_shorten\": \">> Simplified variation\",\n",
    "        \"nrepeat\": \">> Repeated characters\",\n",
    "#         \"nemoji\": \">> Emoji\",\n",
    "#         \"abbr\": \"Abbreviation\",\n",
    "#         \"slang\": \"Slang\",\n",
    "#         \"swear\": \"Swear words\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aaf894e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clse_print_labels = [\n",
    "    \"1. Very Close\", \n",
    "    \"2. Close\", \n",
    "    \"3. Know each other\", \n",
    "    \"4. Don't know each other\", \n",
    "    # \"5. Don't like each other\"\n",
    "]\n",
    "# auth_print_labels = ['0. Very respect', '1. Respect', '2. Normal', '3. Not respect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7ba33341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lexi_stat(analysis_values, analysis_labels, factor, setting, print_labels):\n",
    "    values = analysis_values[factor][setting]\n",
    "    labels = analysis_labels[factor][setting]\n",
    "    assert(len(values)==len(labels))\n",
    "    \n",
    "    printed_text = \"\"\n",
    "    rows = []\n",
    "    for (ms, mu), l in zip(values, labels):\n",
    "        for m in mu:\n",
    "            if m in [\"nsent\", \"nword\"]:\n",
    "                v = mu[m]\n",
    "            else:\n",
    "#                 v = mu[m]*100/mu[\"nword\"]\n",
    "                v = mu[m]\n",
    "                \n",
    "            rows.append({\n",
    "                \"label\": l,\n",
    "                \"metric\": m,\n",
    "                \"value\": v\n",
    "            })\n",
    "        \n",
    "        if \"particles_SARP\" in mu:\n",
    "            particles_notSARP = mu[\"particles\"] - mu[\"particles_SARP\"]\n",
    "            rows.append({\n",
    "                \"label\": l,\n",
    "                \"metric\": \"particles_notSARP\",\n",
    "                \"value\": particles_notSARP\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows).groupby([\"label\", \"metric\"]).mean().reset_index()\n",
    "    \n",
    "    for g in metric_names:\n",
    "        # print(\"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "        printed_text += \"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "        printed_text += \"\\hline\"+\"\\n\"\n",
    "        for m in metric_names[g]:\n",
    "            s = f\"{metric_names[g][m]} \"\n",
    "            for l in print_labels:\n",
    "                row = df[(df[\"label\"]==l) & (df[\"metric\"]==m)]\n",
    "#                 print(l, m)\n",
    "#                 print(df)\n",
    "                if len(row)!=0:\n",
    "                    s += f\"& {row['value'].values[0]:.2f} \"\n",
    "                else:\n",
    "                    s += f\"& - \"\n",
    "\n",
    "            s += \"\\\\\\\\\"\n",
    "            # print(s)\n",
    "            printed_text += \"    \"+s+\"\\n\"\n",
    "        \n",
    "        printed_text += \"    &  & &  & \\\\\\\\\"+\"\\n\"\n",
    "        printed_text += \"\\hline\"+\"\\n\"\n",
    "        \n",
    "        # print(\"&  & &  & \\\\\\\\\")\n",
    "        # print(\"\\hline\")\n",
    "    # print(printed_text)\n",
    "    return df, printed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e49d35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text1 = print_lexi_stat(analysis_values, analysis_labels, \"closeness\", 0, clse_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1bd4031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, printed_text2 = print_lexi_stat(analysis_values, analysis_labels, \"authority\", 0, auth_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1066c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text3 = print_lexi_stat(analysis_values, analysis_labels, \"closeness\", 1, clse_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aec5617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, printed_text4 = print_lexi_stat(analysis_values, analysis_labels, \"authority\", 1, auth_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e702d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, printed_text5 = print_lexi_stat(analysis_values, analysis_labels, \"closeness\", 2, clse_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0d6b6aed-8f23-44ec-8f65-8aa698cbabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(analysis_labels[\"authority\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "81e5baab-871b-4647-a9cc-88819ca077c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, printed_text6 = print_lexi_stat(analysis_values, analysis_labels, \"authority\", 2, auth_print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f05354e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\n",
    "    \"Setting 1: Private Conversations with Self-Reported Labels (Private-Self)\",\n",
    "    \"Setting 2: Public Conversations with Labels from 3rd Party (Public-Perceived)\",\n",
    "    \"Setting 3: Private Conversations with Labels from 3rd Party (Private-Perceived)\",\n",
    "]\n",
    "\n",
    "table_contents = [\n",
    "    (printed_text1, \"\"),\n",
    "    (printed_text3, \"\"),\n",
    "    (printed_text5, \"\"),\n",
    "]\n",
    "\n",
    "printed_text = \"\"\n",
    "for section, (t1, t2) in zip(sections, table_contents):\n",
    "    \n",
    "    printed_text += \"\\subsection{\"+section+\"}\"+\"\\n\\n\"\n",
    "    \n",
    "    printed_text += '''\\subsubsection{Closeness}\n",
    "\\\\begin{longtable}[h]{\n",
    "    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\n",
    "    >{\\\\centering}p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    >{\\\\centering}p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    >{\\\\centering}p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    >{\\\\centering\\\\arraybackslash}p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "}\n",
    "    \\hline\n",
    "\n",
    "    Linguistic Features & Intimate & Close & Acquainted &  Unfamiliar\\\\\\\\\n",
    "    \\hline\n",
    "    \\endfirsthead\n",
    "\n",
    "    \\endhead\n",
    "    '''\n",
    "    \n",
    "    printed_text += (\"\\n\"+t1).replace(\"\\n\", \"\\n    \")\n",
    "    printed_text += \"\\n\"\n",
    "    printed_text += \"\\end{longtable}\"\n",
    "    printed_text += \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9e0566b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\subsection{Setting 1: Private Conversations with Self-Reported Labels (Private-Self)}\n",
      "\n",
      "\\subsubsection{Closeness}\n",
      "\\begin{longtable}[h]{\n",
      "    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "    >{\\centering}p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    >{\\centering}p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    >{\\centering}p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    >{\\centering\\arraybackslash}p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "}\n",
      "    \\hline\n",
      "\n",
      "    Linguistic Features & Intimate & Close & Acquainted &  Unfamiliar\\\\\n",
      "    \\hline\n",
      "    \\endfirsthead\n",
      "\n",
      "    \\endhead\n",
      "    \n",
      "    \\multicolumn{5}{l}{\\textit{Corpus Statistics}} \\\\\n",
      "    \\hline\n",
      "        Number of utterance & 19.08 & 19.05 & 17.67 & 17.94 \\\\\n",
      "        Number of word & 99.74 & 95.60 & 99.47 & 97.55 \\\\\n",
      "        Vocabulary size & 68.38 & 66.06 & 66.21 & 64.34 \\\\\n",
      "        Thai words & 95.25 & 91.18 & 94.70 & 91.84 \\\\\n",
      "        Non-Thai words & 0.38 & 0.56 & 0.50 & 0.60 \\\\\n",
      "        Long words & 3.83 & 3.61 & 4.41 & 3.97 \\\\\n",
      "        Dictionary words & 78.00 & 74.88 & 78.57 & 77.52 \\\\\n",
      "        Transliteration & 1.35 & 1.58 & 1.40 & 1.44 \\\\\n",
      "        &  & &  & \\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Pronoun}} \\\\\n",
      "    \\hline\n",
      "        All pronoun & 6.88 & 5.72 & 5.59 & 4.10 \\\\\n",
      "        >> 1st person pronoun & 4.06 & 3.44 & 3.57 & 2.67 \\\\\n",
      "        >> 2nd person pronoun & 3.94 & 3.85 & 4.04 & 3.18 \\\\\n",
      "        >> 3rd person pronoun & 3.58 & 2.38 & 2.23 & 1.76 \\\\\n",
      "        >> Singular pronoun & 6.88 & 5.70 & 5.58 & 4.09 \\\\\n",
      "        >> Plural pronoun & - & 1.00 & 1.00 & 1.00 \\\\\n",
      "        >> Pronoun in non-standard spelling & 2.74 & 2.34 & 2.45 & 1.39 \\\\\n",
      "        &  & &  & \\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "    \\hline\n",
      "        All particles & 6.78 & 6.69 & 9.08 & 10.38 \\\\\n",
      "        >> Socially-related particles & 2.85 & 2.80 & 5.34 & 5.79 \\\\\n",
      "        >> Non-socially-related particles & 5.42 & 5.67 & 5.31 & 5.06 \\\\\n",
      "        >> Particle in non-standard spelling & 1.74 & 1.87 & 1.58 & 1.57 \\\\\n",
      "        &  & &  & \\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Spelling Variation}} \\\\\n",
      "    \\hline\n",
      "        All spelling variation & 24.31 & 22.81 & 23.74 & 23.14 \\\\\n",
      "        >> Common misspelt words & 2.72 & 1.86 & 1.95 & 1.39 \\\\\n",
      "        >> Morphophonemic variation & 13.70 & 13.61 & 14.14 & 13.73 \\\\\n",
      "        >> Simplified variation & 12.71 & 11.38 & 12.08 & 12.45 \\\\\n",
      "        >> Repeated characters & 1.91 & 1.70 & 1.83 & 2.14 \\\\\n",
      "        &  & &  & \\\\\n",
      "    \\hline\n",
      "    \n",
      "\\end{longtable}\n",
      "\n",
      "\\subsection{Setting 2: Public Conversations with Labels from 3rd Party (Public-Perceived)}\n",
      "\n",
      "\\subsubsection{Closeness}\n",
      "\\begin{longtable}[h]{\n",
      "    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "    >{\\centering}p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    >{\\centering}p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    >{\\centering}p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    >{\\centering\\arraybackslash}p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "}\n",
      "    \\hline\n",
      "\n",
      "    Linguistic Features & Intimate & Close & Acquainted &  Unfamiliar\\\\\n",
      "    \\hline\n",
      "    \\endfirsthead\n",
      "\n",
      "    \\endhead\n",
      "    \n",
      "    \\multicolumn{5}{l}{\\textit{Corpus Statistics}} \\\\\n",
      "    \\hline\n",
      "        Number of utterance & 1.98 & 1.98 & 2.04 & 1.90 \\\\\n",
      "        Number of word & 45.71 & 40.69 & 59.89 & 62.46 \\\\\n",
      "        Vocabulary size & 37.69 & 33.32 & 47.33 & 49.30 \\\\\n",
      "        Thai words & 38.17 & 33.68 & 51.96 & 53.33 \\\\\n",
      "        Non-Thai words & 3.36 & 2.49 & 3.11 & 3.35 \\\\\n",
      "        Long words & 2.40 & 1.95 & 3.01 & 3.17 \\\\\n",
      "        Dictionary words & 31.17 & 27.04 & 42.20 & 43.70 \\\\\n",
      "        Transliteration & 1.00 & 1.29 & 1.24 & 1.42 \\\\\n",
      "        &  & &  & \\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Pronoun}} \\\\\n",
      "    \\hline\n",
      "        All pronoun & 3.15 & 2.32 & 3.41 & 3.27 \\\\\n",
      "        >> 1st person pronoun & 1.33 & 1.42 & 2.44 & 2.08 \\\\\n",
      "        >> 2nd person pronoun & 2.24 & 1.81 & 2.62 & 2.39 \\\\\n",
      "        >> 3rd person pronoun & 1.54 & 1.40 & 2.16 & 2.11 \\\\\n",
      "        >> Singular pronoun & 3.15 & 2.28 & 3.39 & 3.21 \\\\\n",
      "        >> Plural pronoun & - & 1.20 & 2.00 & 1.23 \\\\\n",
      "        >> Pronoun in non-standard spelling & 1.17 & 1.37 & 2.04 & 1.67 \\\\\n",
      "        &  & &  & \\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "    \\hline\n",
      "        All particles & 2.58 & 2.10 & 3.02 & 3.07 \\\\\n",
      "        >> Socially-related particles & 1.45 & 1.52 & 1.86 & 1.88 \\\\\n",
      "        >> Non-socially-related particles & 1.82 & 1.06 & 1.91 & 1.68 \\\\\n",
      "        >> Particle in non-standard spelling & 1.00 & 1.00 & 1.25 & 1.36 \\\\\n",
      "        &  & &  & \\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Spelling Variation}} \\\\\n",
      "    \\hline\n",
      "        All spelling variation & 9.83 & 7.88 & 11.75 & 10.85 \\\\\n",
      "        >> Common misspelt words & 1.12 & 1.43 & 1.53 & 1.33 \\\\\n",
      "        >> Morphophonemic variation & 5.47 & 4.34 & 6.36 & 5.52 \\\\\n",
      "        >> Simplified variation & 6.36 & 4.69 & 6.64 & 6.28 \\\\\n",
      "        >> Repeated characters & 0.74 & 0.99 & 0.79 & 0.50 \\\\\n",
      "        &  & &  & \\\\\n",
      "    \\hline\n",
      "    \n",
      "\\end{longtable}\n",
      "\n",
      "\\subsection{Setting 3: Private Conversations with Labels from 3rd Party (Private-Perceived)}\n",
      "\n",
      "\\subsubsection{Closeness}\n",
      "\\begin{longtable}[h]{\n",
      "    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "    >{\\centering}p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    >{\\centering}p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    >{\\centering}p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    >{\\centering\\arraybackslash}p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "}\n",
      "    \\hline\n",
      "\n",
      "    Linguistic Features & Intimate & Close & Acquainted &  Unfamiliar\\\\\n",
      "    \\hline\n",
      "    \\endfirsthead\n",
      "\n",
      "    \\endhead\n",
      "    \n",
      "    \\multicolumn{5}{l}{\\textit{Corpus Statistics}} \\\\\n",
      "    \\hline\n",
      "        Number of utterance & 19.20 & 19.03 & 18.74 & 13.95 \\\\\n",
      "        Number of word & 96.58 & 89.15 & 103.24 & 78.50 \\\\\n",
      "        Vocabulary size & 67.89 & 62.13 & 68.96 & 50.92 \\\\\n",
      "        Thai words & 92.86 & 84.46 & 97.80 & 75.06 \\\\\n",
      "        Non-Thai words & 0.21 & 0.35 & 0.67 & 0.46 \\\\\n",
      "        Long words & 3.92 & 2.99 & 4.27 & 3.90 \\\\\n",
      "        Dictionary words & 75.52 & 68.68 & 81.81 & 63.22 \\\\\n",
      "        Transliteration & 1.32 & 1.36 & 1.55 & 1.38 \\\\\n",
      "        &  & &  & \\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Pronoun}} \\\\\n",
      "    \\hline\n",
      "        All pronoun & 6.12 & 6.20 & 4.63 & 5.36 \\\\\n",
      "        >> 1st person pronoun & 3.27 & 3.53 & 2.99 & 3.76 \\\\\n",
      "        >> 2nd person pronoun & 3.64 & 3.90 & 3.47 & 4.06 \\\\\n",
      "        >> 3rd person pronoun & 3.18 & 2.53 & 2.04 & 2.30 \\\\\n",
      "        >> Singular pronoun & 6.09 & 6.19 & 4.62 & 5.35 \\\\\n",
      "        >> Plural pronoun & 1.00 & 1.00 & 1.00 & 1.00 \\\\\n",
      "        >> Pronoun in non-standard spelling & 2.27 & 2.73 & 1.67 & 1.00 \\\\\n",
      "        &  & &  & \\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "    \\hline\n",
      "        All particles & 6.19 & 6.49 & 9.15 & 10.41 \\\\\n",
      "        >> Socially-related particles & 2.62 & 2.50 & 5.15 & 6.32 \\\\\n",
      "        >> Non-socially-related particles & 5.46 & 5.48 & 5.40 & 4.33 \\\\\n",
      "        >> Particle in non-standard spelling & 2.23 & 1.74 & 1.63 & 1.76 \\\\\n",
      "        &  & &  & \\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Spelling Variation}} \\\\\n",
      "    \\hline\n",
      "        All spelling variation & 21.98 & 22.65 & 24.05 & 19.03 \\\\\n",
      "        >> Common misspelt words & 2.05 & 1.94 & 1.67 & 2.04 \\\\\n",
      "        >> Morphophonemic variation & 12.74 & 13.62 & 14.08 & 12.15 \\\\\n",
      "        >> Simplified variation & 11.66 & 11.36 & 12.57 & 9.41 \\\\\n",
      "        >> Repeated characters & 1.65 & 2.11 & 2.00 & 0.98 \\\\\n",
      "        &  & &  & \\\\\n",
      "    \\hline\n",
      "    \n",
      "\\end{longtable}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128a745-0d9e-4545-95f2-f2bbbe6df10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cad66f10",
   "metadata": {},
   "source": [
    "## Regression w/ Othogonal Polynomial Coding\n",
    "https://medium.com/@wyess/demystifying-statistical-analysis-3-the-one-way-anova-expressed-in-linear-regression-99269e84edd9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "65d94022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeness_to_vec(label):\n",
    "    if label == \"1. Very Close\":\n",
    "        return {\"x1\": -3, \"x2\": 1, \"x3\": -1}\n",
    "    elif label == \"2. Close\":\n",
    "        return {\"x1\": -1, \"x2\": -1, \"x3\": 3}\n",
    "    elif label == \"3. Know each other\":\n",
    "        return {\"x1\": 1, \"x2\": -1, \"x3\": -3}\n",
    "    elif label == \"4. Don't know each other\": \n",
    "        return {\"x1\": 3, \"x2\": 1, \"x3\": 1}\n",
    "    elif label == \"5. Don't like each other\":\n",
    "        return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7d08665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clse_coef_labels = [\"b\", \"a1\", \"a2\", \"a3\"]\n",
    "auth_coef_labels = [\"b\", 'a1', 'a2', \"a3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "85b93ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_features(analysis_values, analysis_labels, factor, setting, to_vec_func, skips=[]):\n",
    "    values = analysis_values[factor][setting]\n",
    "    labels = analysis_labels[factor][setting]\n",
    "    assert(len(values)==len(labels))\n",
    "    \n",
    "    rows = []\n",
    "    for (ms, mu), l in zip(values, labels):\n",
    "        if l in skips:\n",
    "            continue\n",
    "            \n",
    "        x = to_vec_func(l)\n",
    "        if x is None:\n",
    "            continue\n",
    "        \n",
    "        for m in mu:\n",
    "            if m in [\"nsent\", \"nword\"]:\n",
    "                v = mu[m]\n",
    "            else:\n",
    "                v = mu[m]*100/mu[\"nword\"]\n",
    "            \n",
    "            \n",
    "            rows.append({\n",
    "                \"metric\": m,\n",
    "                \"value\": v,\n",
    "                **x\n",
    "            })\n",
    "            \n",
    "        if \"particles_SARP\" in mu:\n",
    "            particles_notSARP = mu[\"particles\"] - mu[\"particles_SARP\"]\n",
    "            rows.append({\n",
    "                \"metric\": \"particles_notSARP\",\n",
    "                \"value\": particles_notSARP,\n",
    "                **x\n",
    "            })\n",
    "            \n",
    "    feats = pd.DataFrame(rows)  \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fceb9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "def print_anova_test(feats, n=3):\n",
    "    feat_names = feats[\"metric\"].unique()\n",
    "    \n",
    "    feat_important = []\n",
    "    for f in feat_names:\n",
    "        if \"cat:\" in f:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            d = feats[feats[\"metric\"]==f]\n",
    "        #     print(f, len(d))\n",
    "            x_columns = [f\"x{i+1}\" for i in range(n)]\n",
    "            X = d[x_columns]\n",
    "            X = sm.add_constant(X)\n",
    "            Y = d[\"value\"]\n",
    "            model = sm.OLS(Y,X)\n",
    "            results = model.fit()\n",
    "            \n",
    "            ncoef = n + 1\n",
    "            \n",
    "            t_test = results.t_test(np.identity(ncoef))\n",
    "            f_test = results.f_test(np.identity(ncoef))\n",
    "            o = {\"feat\": f, \"f_value\": f_test.pvalue}\n",
    "            for i in range(ncoef):\n",
    "                o[f\"coef{i}\"] = t_test.effect[i]\n",
    "                \n",
    "            for i in range(ncoef):\n",
    "                o[f\"pval{i}\"] = t_test.pvalue[i]\n",
    "                \n",
    "            feat_important.append(o)\n",
    "        except Exception as e:\n",
    "            print(\"error\", f, e)\n",
    "\n",
    "    outputs = pd.DataFrame(feat_important)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860eae70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e208f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "574751f3-cfd7-49fe-9bbd-bdfc44bf37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights(outputs):\n",
    "    \n",
    "    coefs = {}\n",
    "    coef_labels = [\"b\", \"a1\", \"a2\", \"a3\"]\n",
    "    for i, label in enumerate(coef_labels):\n",
    "        for _, row in outputs.iterrows():\n",
    "            coefs[(label, row[\"feat\"])] = (row[f\"coef{i}\"], row[f\"pval{i}\"])\n",
    "\n",
    "#     print(coefs)\n",
    "\n",
    "    printed_text = \"\"\n",
    "    for g in metric_names:\n",
    "        # print(\"\\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "        printed_text += \"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "        for m in metric_names[g]:\n",
    "            s = f\"{metric_names[g][m]} \"\n",
    "            for l in coef_labels:                    \n",
    "                val, pval = coefs[(l, m)]\n",
    "                if l==\"b\":\n",
    "                    s += f\"& {val:.2f} \"\n",
    "                elif pval < 0.05:\n",
    "                    s += \"& \\cellcolor{gray!25} \"+f\"{val:.2f}*\"\n",
    "                else:\n",
    "                    s += f\"& {val:.2f} \"\n",
    "            s += \"\\\\\\\\\"\n",
    "            # print(s)\n",
    "            printed_text += s+\"\\n\"\n",
    "        printed_text += \"&  & &\\\\\\\\\" + \"\\n\"\n",
    "        printed_text += \"\\hline\" + \"\\n\"\n",
    "        # print(\"&  & &\\\\\\\\\")\n",
    "        # print(\"\\hline\")\n",
    "    return printed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123595e1-f763-455a-87a6-62bc1fc253fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f82a11-1c8c-45b6-8b02-1a05e1563a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "11badd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imtk/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 4, but rank is 3\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 0, closeness_to_vec, skips=[])\n",
    "clse1_poly_outputs = print_anova_test(feats, n=3)\n",
    "# print_weights(outputs, clse_coef_labels, clse_print_labels, \"2. Know each other\")\n",
    "printed_text1 = print_weights(clse1_poly_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e733fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eeb1c491-f902-4174-b929-bb29eed0a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 1, closeness_to_vec)\n",
    "clse2_poly_outputs = print_anova_test(feats, n=3)\n",
    "# clse_coef_labels = [\"b\", \"2. Know each other\", \"4. Don't like each other\"]\n",
    "# print_weights(outputs, clse_coef_labels, clse_print_labels, \"3. Don't know each other\")\n",
    "printed_text3 = print_weights(clse2_poly_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b579e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "550f18a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 2, closeness_to_vec, skips=[])\n",
    "clse3_poly_outputs = print_anova_test(feats, n=3)\n",
    "# print_weights(outputs, clse_coef_labels, clse_print_labels, \"2. Know each other\")\n",
    "printed_text5 = print_weights(clse3_poly_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9cedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b1bd0f30-6750-4e6d-a1fc-60717f9b2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\n",
    "    \"Setting 1: Private Conversations with Self-Reported Labels\",\n",
    "    \"Setting 2: Public Conversations with Labels from 3rd Party \",\n",
    "    \"Setting 3: Private Conversations with Labels from 3rd Party \",\n",
    "]\n",
    "\n",
    "table_contents = [\n",
    "    (printed_text1, \"\"),\n",
    "    (printed_text3, \"\"),\n",
    "    (printed_text5, \"\"),\n",
    "]\n",
    "\n",
    "printed_text = \"\"\n",
    "for section, (t1, t2) in zip(sections, table_contents):\n",
    "    \n",
    "    printed_text += \"\\subsection{\"+section+\"}\"+\"\\n\\n\"\n",
    "    \n",
    "    printed_text += '''\\subsubsection{Closeness}\n",
    "\\\\begin{longtable}[h]{\n",
    "    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|c|c|c|c\n",
    "}\n",
    "    \\hline\n",
    "\n",
    "      \n",
    "\n",
    "    Lexical Features & Grand Mean & Linear & Quadratic & Cubic \\\\\\\\\n",
    "    \\hline\n",
    "    \\endfirsthead\n",
    "\n",
    "    \\endhead\n",
    "    '''\n",
    "    \n",
    "    printed_text += (\"\\n\"+t1).replace(\"\\n\", \"\\n    \")\n",
    "    printed_text += \"\\n\"\n",
    "    printed_text += \"\\end{longtable}\"\n",
    "\n",
    "    printed_text += \"\\clearpage\"\n",
    "    printed_text += \"\\n\\n\"\n",
    "    # break\n",
    "    \n",
    "# print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d391969-05f1-43d4-ba90-8eac82bc0c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7a88e-1efd-49c2-a577-7911b4e97529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46a1405-2b91-495b-b7c9-c393c8816fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d074d8d-640b-442a-9dc0-498d1313e900",
   "metadata": {},
   "source": [
    "# Regression w/ Effect Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c32a6648-fa5d-4398-8de5-daae33257db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def closeness_to_vec_effect(label):\n",
    "#     if label == \"1. Close\":\n",
    "#         return {\"x1\": 1, \"x2\": 0}\n",
    "#     elif label == \"2. Know each other\": ## Base category\n",
    "#         return {\"x1\": -1, \"x2\": -1}\n",
    "#     elif label == \"3. Don't know each other\": \n",
    "#         return {\"x1\": 0, \"x2\": 1}\n",
    "#     elif label == \"4. Don't like each other\":\n",
    "#         return None\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "def closeness_to_vec_effect(label):\n",
    "    if label == \"1. Very Close\":\n",
    "        return {\"x1\": -1, \"x2\": -1, \"x3\": -1}\n",
    "    elif label == \"2. Close\":\n",
    "        return {\"x1\": 1, \"x2\": 0, \"x3\": 0}\n",
    "    elif label == \"3. Know each other\":\n",
    "        return {\"x1\": 0, \"x2\": 1, \"x3\": 0}\n",
    "    elif label == \"4. Don't know each other\": \n",
    "        return {\"x1\": 0, \"x2\": 0, \"x3\": 1}\n",
    "    elif label == \"5. Don't like each other\":\n",
    "        return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "afbdeaca-b972-4eca-8be4-f7ab964cfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights_effect(outputs, coef_labels):\n",
    "    coefs = {}\n",
    "    for i, label in coef_labels.items():\n",
    "        if i is None:\n",
    "            continue\n",
    "            \n",
    "        for _, row in outputs.iterrows():\n",
    "            coefs[(label, row[\"feat\"])] = (row[f\"coef{i}\"], row[f\"pval{i}\"])\n",
    "\n",
    "    printed_text = \"\"\n",
    "    for g in metric_names:\n",
    "        # print(\"\\multicolumn{4}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\")\n",
    "        printed_text += \"\\multicolumn{5}{l}{\\\\textit{\"+g+\"}} \\\\\\\\\"+\"\\n\"\n",
    "        for m in metric_names[g]:\n",
    "            s = f\"{metric_names[g][m]} \"\n",
    "            for i, l in coef_labels.items():                    \n",
    "                if i is None:\n",
    "                    s += f\"& * \"\n",
    "                    continue\n",
    "                \n",
    "                val, pval = coefs[(l, m)]\n",
    "                if l==\"Grand Mean\":\n",
    "                    s += f\"& {val:.2f} \"\n",
    "                elif pval < 0.05:\n",
    "                    s += \"& \\cellcolor{gray!25} \"+f\"{val:.2f}* \"\n",
    "                else:\n",
    "                    s += f\"& {val:.2f} \"\n",
    "            s += \"\\\\\\\\\"\n",
    "            # print(s)\n",
    "            printed_text += s+\"\\n\"\n",
    "        printed_text += \"&  & &\\\\\\\\\" + \"\\n\"\n",
    "        printed_text += \"\\hline\" + \"\\n\"\n",
    "        # print(\"&  & &\\\\\\\\\")\n",
    "        # print(\"\\hline\")\n",
    "    return printed_text, coef_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fdc707fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imtk/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 4, but rank is 3\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 0, closeness_to_vec_effect, skips=[])\n",
    "clse1_effect_outputs = print_anova_test(feats, n=3)\n",
    "\n",
    "coef_labels = {0:\"Grand Mean\", 1: \"Close\", 2: \"Acquainted\", 3: \"Unfamiliar\"}\n",
    "printed_text1 = print_weights_effect(clse1_effect_outputs, coef_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e8173f18-559d-4331-ad86-1420469203cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nsent</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nword</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ndict</td>\n",
       "      <td>72.592593</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nunique</td>\n",
       "      <td>65.185185</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nlongword</td>\n",
       "      <td>5.185185</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27294</th>\n",
       "      <td>misspelling_intention</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27295</th>\n",
       "      <td>slang</td>\n",
       "      <td>6.944444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27296</th>\n",
       "      <td>misspelling_shorten</td>\n",
       "      <td>18.055556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27297</th>\n",
       "      <td>misspelling_common</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27298</th>\n",
       "      <td>particles</td>\n",
       "      <td>6.944444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27299 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      metric       value  x1  x2  x3\n",
       "0                      nsent   20.000000   1   0   0\n",
       "1                      nword  135.000000   1   0   0\n",
       "2                      ndict   72.592593   1   0   0\n",
       "3                    nunique   65.185185   1   0   0\n",
       "4                  nlongword    5.185185   1   0   0\n",
       "...                      ...         ...  ..  ..  ..\n",
       "27294  misspelling_intention   12.500000   1   0   0\n",
       "27295                  slang    6.944444   1   0   0\n",
       "27296    misspelling_shorten   18.055556   1   0   0\n",
       "27297     misspelling_common    2.777778   1   0   0\n",
       "27298              particles    6.944444   1   0   0\n",
       "\n",
       "[27299 rows x 5 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d119369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for u in feats[\"metric\"].unique():\n",
    "#     print(u)\n",
    "#     print(feats[feats[\"metric\"]==u][['x1', 'x2', 'x3']].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "96b3b6bd-54cb-46b6-85c4-a5c9649342e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 1, closeness_to_vec_effect, skips=[])\n",
    "clse2_effect_outputs = print_anova_test(feats, n=3)\n",
    "printed_text3 = print_weights_effect(clse2_effect_outputs, coef_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7126a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2f1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4d32ca6d-47e1-45b9-890f-f4e3842c9d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = to_features(analysis_values, analysis_labels, \"closeness\", 2, closeness_to_vec_effect, skips=[])\n",
    "clse3_effect_outputs = print_anova_test(feats, n=3)\n",
    "printed_text5 = print_weights_effect(clse3_effect_outputs, coef_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b89bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "76969f31-4866-4638-af6b-9ac3fe37cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Grand Mean\", \"Close\", \"Acquainted\", \"Unfamiliar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aaeda7c3-d475-4738-a743-69363387a7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\subsection{Setting 1: Private Conversations with Self-Reported Labels}\n",
      "\n",
      "\\subsubsection{Closeness}\n",
      "\\begin{longtable}[h]{\n",
      "    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "}\n",
      "    \\hline\n",
      "    Lexical Features & Grand Mean & Close & Acquainted & Unfamiliar\\\\\n",
      "    \\hline\n",
      "    \\endfirsthead\n",
      "\n",
      "    \\endhead\n",
      "    \n",
      "    \\multicolumn{5}{l}{\\textit{Corpus Statistics}} \\\\\n",
      "    Number of utterance & 18.43 & \\cellcolor{gray!25} 0.61* & \\cellcolor{gray!25} -0.77* & -0.49 \\\\\n",
      "    Number of word & 98.09 & -2.49 & 1.38 & -0.54 \\\\\n",
      "    Vocabulary size & 70.81 & \\cellcolor{gray!25} 1.01* & -0.61 & -0.82 \\\\\n",
      "    Thai words & 94.91 & -0.00 & 0.49 & \\cellcolor{gray!25} -0.97* \\\\\n",
      "    Non-Thai words & 0.47 & 0.09 & -0.06 & 0.08 \\\\\n",
      "    Long words & 3.84 & \\cellcolor{gray!25} -0.35* & \\cellcolor{gray!25} 0.38* & -0.06 \\\\\n",
      "    Dictionary words & 78.65 & \\cellcolor{gray!25} -1.03* & 0.36 & \\cellcolor{gray!25} 1.37* \\\\\n",
      "    Transliteration & 1.38 & 0.17 & -0.11 & 0.01 \\\\\n",
      "    &  & &\\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Pronoun}} \\\\\n",
      "    All pronoun & 5.48 & \\cellcolor{gray!25} 0.42* & 0.07 & \\cellcolor{gray!25} -1.56* \\\\\n",
      "    >> 1st person pronoun & 3.30 & 0.08 & 0.10 & \\cellcolor{gray!25} -0.67* \\\\\n",
      "    >> 2nd person pronoun & 3.73 & 0.26 & \\cellcolor{gray!25} 0.41* & \\cellcolor{gray!25} -0.61* \\\\\n",
      "    >> 3rd person pronoun & 2.49 & 0.05 & -0.17 & \\cellcolor{gray!25} -0.81* \\\\\n",
      "    >> Singular pronoun & 5.46 & \\cellcolor{gray!25} 0.41* & 0.07 & \\cellcolor{gray!25} -1.56* \\\\\n",
      "    >> Plural pronoun & 0.75 & 0.24 & 0.43 & 0.08 \\\\\n",
      "    >> Pronoun in non-standard spelling & 2.19 & 0.38 & 0.15 & \\cellcolor{gray!25} -0.88* \\\\\n",
      "    &  & &\\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "    All particles & 9.42 & \\cellcolor{gray!25} -2.23* & 0.77 & \\cellcolor{gray!25} 3.48* \\\\\n",
      "    >> Socially-related particles & 5.63 & \\cellcolor{gray!25} -2.41* & 1.10 & \\cellcolor{gray!25} 3.11* \\\\\n",
      "    >> Non-socially-related particles & 5.37 & 0.31 & -0.06 & -0.31 \\\\\n",
      "    >> Particle in non-standard spelling & 1.92 & 0.05 & -0.16 & 0.26 \\\\\n",
      "    &  & &\\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Spelling Variation}} \\\\\n",
      "    All spelling variation & 24.18 & 0.03 & -0.20 & -0.59 \\\\\n",
      "    >> Common misspelt words & 1.91 & -0.01 & -0.12 & \\cellcolor{gray!25} -0.62* \\\\\n",
      "    >> Morphophonemic variation & 14.66 & 0.07 & 0.11 & 0.10 \\\\\n",
      "    >> Simplified variation & 12.16 & -0.08 & -0.31 & -0.30 \\\\\n",
      "    >> Repeated characters & 2.05 & 0.11 & -0.19 & 0.12 \\\\\n",
      "    &  & &\\\\\n",
      "    \\hline\n",
      "    \n",
      "\\end{longtable}\n",
      "\n",
      "\\clearpage\n",
      "\n",
      "\\subsection{Setting 2: Public Conversations with Labels from 3rd Party }\n",
      "\n",
      "\\subsubsection{Closeness}\n",
      "\\begin{longtable}[h]{\n",
      "    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "}\n",
      "    \\hline\n",
      "    Lexical Features & Grand Mean & Close & Acquainted & Unfamiliar\\\\\n",
      "    \\hline\n",
      "    \\endfirsthead\n",
      "\n",
      "    \\endhead\n",
      "    \n",
      "    \\multicolumn{5}{l}{\\textit{Corpus Statistics}} \\\\\n",
      "    Number of utterance & 1.98 & 0.01 & 0.07 & \\cellcolor{gray!25} -0.07* \\\\\n",
      "    Number of word & 52.19 & \\cellcolor{gray!25} -11.50* & \\cellcolor{gray!25} 7.70* & \\cellcolor{gray!25} 10.27* \\\\\n",
      "    Vocabulary size & 84.95 & \\cellcolor{gray!25} 1.76* & \\cellcolor{gray!25} -2.03* & \\cellcolor{gray!25} -2.00* \\\\\n",
      "    Thai words & 78.31 & -0.49 & \\cellcolor{gray!25} 4.41* & \\cellcolor{gray!25} 3.80* \\\\\n",
      "    Non-Thai words & 10.74 & -0.56 & \\cellcolor{gray!25} -3.03* & \\cellcolor{gray!25} -3.38* \\\\\n",
      "    Long words & 5.29 & 0.13 & -0.08 & 0.00 \\\\\n",
      "    Dictionary words & 63.44 & -0.73 & \\cellcolor{gray!25} 2.80* & \\cellcolor{gray!25} 3.16* \\\\\n",
      "    Transliteration & 3.07 & 0.43 & \\cellcolor{gray!25} 1.12* & \\cellcolor{gray!25} -0.71* \\\\\n",
      "    &  & &\\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Pronoun}} \\\\\n",
      "    All pronoun & 5.23 & \\cellcolor{gray!25} 0.70* & -0.35 & -0.38 \\\\\n",
      "    >> 1st person pronoun & 3.07 & 0.41 & 0.31 & -0.06 \\\\\n",
      "    >> 2nd person pronoun & 3.87 & \\cellcolor{gray!25} 0.87* & -0.46 & \\cellcolor{gray!25} -0.44* \\\\\n",
      "    >> 3rd person pronoun & 3.06 & 0.58 & 0.23 & 0.08 \\\\\n",
      "    >> Singular pronoun & 5.17 & \\cellcolor{gray!25} 0.67* & -0.35 & -0.42 \\\\\n",
      "    >> Plural pronoun & 2.12 & \\cellcolor{gray!25} 1.12* & \\cellcolor{gray!25} 1.27* & -0.28 \\\\\n",
      "    >> Pronoun in non-standard spelling & 2.95 & \\cellcolor{gray!25} 1.65* & -0.25 & -0.22 \\\\\n",
      "    &  & &\\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "    All particles & 5.32 & 0.37 & 0.08 & -0.36 \\\\\n",
      "    >> Socially-related particles & 3.20 & 0.42 & 0.04 & -0.14 \\\\\n",
      "    >> Non-socially-related particles & 1.62 & \\cellcolor{gray!25} -0.56* & 0.29 & 0.06 \\\\\n",
      "    >> Particle in non-standard spelling & 2.31 & \\cellcolor{gray!25} 1.78* & -0.35 & 0.07 \\\\\n",
      "    &  & &\\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Spelling Variation}} \\\\\n",
      "    All spelling variation & 18.38 & 0.92 & 0.63 & \\cellcolor{gray!25} -1.84* \\\\\n",
      "    >> Common misspelt words & 2.11 & 0.40 & 0.18 & -0.23 \\\\\n",
      "    >> Morphophonemic variation & 10.49 & \\cellcolor{gray!25} 1.10* & 0.31 & \\cellcolor{gray!25} -1.76* \\\\\n",
      "    >> Simplified variation & 10.51 & 0.35 & -0.15 & \\cellcolor{gray!25} -0.99* \\\\\n",
      "    >> Repeated characters & 2.11 & \\cellcolor{gray!25} 0.94* & -0.10 & \\cellcolor{gray!25} -1.01* \\\\\n",
      "    &  & &\\\\\n",
      "    \\hline\n",
      "    \n",
      "\\end{longtable}\n",
      "\n",
      "\\clearpage\n",
      "\n",
      "\\subsection{Setting 3: Private Conversations with Labels from 3rd Party }\n",
      "\n",
      "\\subsubsection{Closeness}\n",
      "\\begin{longtable}[h]{\n",
      "    p{\\dimexpr 0.40\\linewidth-2\\tabcolsep}|\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "    p{\\dimexpr 0.15\\linewidth-2\\tabcolsep}\n",
      "}\n",
      "    \\hline\n",
      "    Lexical Features & Grand Mean & Close & Acquainted & Unfamiliar\\\\\n",
      "    \\hline\n",
      "    \\endfirsthead\n",
      "\n",
      "    \\endhead\n",
      "    \n",
      "    \\multicolumn{5}{l}{\\textit{Corpus Statistics}} \\\\\n",
      "    Number of utterance & 17.73 & \\cellcolor{gray!25} 1.31* & \\cellcolor{gray!25} 1.01* & \\cellcolor{gray!25} -3.78* \\\\\n",
      "    Number of word & 91.87 & -2.72 & \\cellcolor{gray!25} 11.38* & \\cellcolor{gray!25} -13.36* \\\\\n",
      "    Vocabulary size & 72.38 & 0.19 & \\cellcolor{gray!25} -2.93* & \\cellcolor{gray!25} 1.80* \\\\\n",
      "    Thai words & 94.93 & \\cellcolor{gray!25} -0.69* & -0.24 & 0.12 \\\\\n",
      "    Non-Thai words & 0.39 & 0.00 & \\cellcolor{gray!25} 0.22* & -0.06 \\\\\n",
      "    Long words & 3.75 & \\cellcolor{gray!25} -0.63* & 0.22 & 0.32 \\\\\n",
      "    Dictionary words & 78.89 & \\cellcolor{gray!25} -2.45* & 0.22 & \\cellcolor{gray!25} 3.96* \\\\\n",
      "    Transliteration & 1.36 & 0.09 & 0.09 & -0.27 \\\\\n",
      "    &  & &\\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Pronoun}} \\\\\n",
      "    All pronoun & 5.57 & \\cellcolor{gray!25} 1.15* & \\cellcolor{gray!25} -1.11* & -0.49 \\\\\n",
      "    >> 1st person pronoun & 3.26 & \\cellcolor{gray!25} 0.38* & \\cellcolor{gray!25} -0.38* & 0.09 \\\\\n",
      "    >> 2nd person pronoun & 3.83 & \\cellcolor{gray!25} 0.46* & \\cellcolor{gray!25} -0.44* & 0.16 \\\\\n",
      "    >> 3rd person pronoun & 2.53 & \\cellcolor{gray!25} 0.41* & \\cellcolor{gray!25} -0.57* & -0.03 \\\\\n",
      "    >> Singular pronoun & 5.55 & \\cellcolor{gray!25} 1.15* & \\cellcolor{gray!25} -1.11* & -0.48 \\\\\n",
      "    >> Plural pronoun & 1.01 & \\cellcolor{gray!25} 0.68* & -0.21 & -0.23 \\\\\n",
      "    >> Pronoun in non-standard spelling & 2.05 & \\cellcolor{gray!25} 0.90* & -0.39 & -0.82 \\\\\n",
      "    &  & &\\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Sentence-ending Particles}} \\\\\n",
      "    All particles & 10.61 & \\cellcolor{gray!25} -3.24* & \\cellcolor{gray!25} -0.83* & \\cellcolor{gray!25} 8.14* \\\\\n",
      "    >> Socially-related particles & 6.66 & \\cellcolor{gray!25} -3.60* & -0.43 & \\cellcolor{gray!25} 8.17* \\\\\n",
      "    >> Non-socially-related particles & 5.17 & 0.31 & 0.23 & \\cellcolor{gray!25} -0.84* \\\\\n",
      "    >> Particle in non-standard spelling & 2.00 & -0.08 & 0.00 & -0.25 \\\\\n",
      "    &  & &\\\\\n",
      "    \\hline\n",
      "    \\multicolumn{5}{l}{\\textit{Spelling Variation}} \\\\\n",
      "    All spelling variation & 23.62 & \\cellcolor{gray!25} 1.96* & 0.16 & \\cellcolor{gray!25} -2.15* \\\\\n",
      "    >> Common misspelt words & 1.91 & 0.18 & \\cellcolor{gray!25} -0.35* & -0.22 \\\\\n",
      "    >> Morphophonemic variation & 14.57 & \\cellcolor{gray!25} 1.10* & -0.10 & 0.06 \\\\\n",
      "    >> Simplified variation & 11.81 & \\cellcolor{gray!25} 0.95* & 0.15 & \\cellcolor{gray!25} -2.00* \\\\\n",
      "    >> Repeated characters & 1.95 & \\cellcolor{gray!25} 0.80* & 0.08 & \\cellcolor{gray!25} -0.80* \\\\\n",
      "    &  & &\\\\\n",
      "    \\hline\n",
      "    \n",
      "\\end{longtable}\n",
      "\n",
      "\\clearpage\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sections = [\n",
    "    \"Setting 1: Private Conversations with Self-Reported Labels\",\n",
    "    \"Setting 2: Public Conversations with Labels from 3rd Party \",\n",
    "    \"Setting 3: Private Conversations with Labels from 3rd Party \",\n",
    "]\n",
    "\n",
    "table_contents = [\n",
    "    (printed_text1, \"\"),\n",
    "    (printed_text3, \"\"),\n",
    "    (printed_text5, \"\"),\n",
    "]\n",
    "\n",
    "printed_text = \"\"\n",
    "for section, (v1, v2) in zip(sections, table_contents):\n",
    "    \n",
    "    printed_text += \"\\subsection{\"+section+\"}\"+\"\\n\\n\"\n",
    "    \n",
    "    printed_text += '''\\subsubsection{Closeness}\n",
    "\\\\begin{longtable}[h]{\n",
    "    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "    p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\n",
    "}\n",
    "    \\hline\n",
    "    '''\n",
    "    \n",
    "    printed_text += \"Lexical Features & \" + \" & \".join(columns) + \"\\\\\\\\\"\n",
    "        \n",
    "    printed_text +='''\n",
    "    \\hline\n",
    "    \\endfirsthead\n",
    "\n",
    "    \\endhead\n",
    "    '''\n",
    "\n",
    "    t1, _ = v1\n",
    "    printed_text += (\"\\n\"+t1).replace(\"\\n\", \"\\n    \")\n",
    "    printed_text += \"\\n\"\n",
    "    printed_text += \"\\end{longtable}\"\n",
    "    printed_text += \"\\n\\n\"\n",
    "\n",
    "    printed_text += \"\\clearpage\"\n",
    "    printed_text += \"\\n\\n\"\n",
    "    # break\n",
    "    \n",
    "print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3265f4a8-30e3-4152-a72c-b87a3a87f49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79a59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e7df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89049f3f",
   "metadata": {},
   "source": [
    "### Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "035f2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\n",
    "    \"Setting 1: Private Conversations with Self-Reported Labels\",\n",
    "    \"Setting 2: Public Conversations with Labels from 3rd Party \",\n",
    "    \"Setting 3: Private Conversations with Labels from 3rd Party \",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b7824106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def outputs_to_dict(outputs, coef_labels):\n",
    "#     coefs = {}\n",
    "#     for label in coef_labels.keys():\n",
    "#         for _, row in outputs.iterrows():\n",
    "#             coef_col, pval_col = coef_labels[label]\n",
    "#             if coef_col is None:\n",
    "#                 coefs[(label, row[\"feat\"])] = (None, None)\n",
    "#             elif coef_col not in row:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 coefs[(label, row[\"feat\"])] = (row[coef_col], row[pval_col])\n",
    "\n",
    "#     return coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e7398c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feats[feats[\"metric\"]==\"nsent\"].groupby([\"x1\", \"x2\"]).count()\n",
    "# labelmap = {\n",
    "#     '1. Close': \"1. Close\", \n",
    "#     '2. Know each other': \"2. Acquainted\", \n",
    "#     \"3. Don't know each other\": \"3. Unfamiliar\",\n",
    "    \n",
    "    \n",
    "#     '0. Very respect': \"0. Highly Respectful\", \n",
    "#     '1. Respect': \"1. Respectful\", \n",
    "#     '2. Normal': \"2. Normal\", \n",
    "#     '3. Not respect': \"3. Disrespectful\"\n",
    "# }\n",
    "\n",
    "# def label2newlabel(label):\n",
    "#     if type(label) is list or type(label) is np.ndarray:\n",
    "#         return [labelmap[l] if l in labelmap else l for l in label ]\n",
    "    \n",
    "#     if label in labelmap:\n",
    "#         return labelmap[label]\n",
    "#     return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259b1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "471573ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_printed_text_by_section(title, coef_labels, outputs, section_label):\n",
    "#     printed_text = \"\"\n",
    "#     printed_text += \"\\subsubsection{\"+title+\"}\"+\"\\n\"\n",
    "#     printed_text += \"\\label{\"+section_label+\"}\"+\"\\n\"\n",
    "    \n",
    "#     printed_text += \"\\\\begin{longtable}[h]{\"+\"\\n\"\n",
    "\n",
    "    \n",
    "#     ncol = len(coef_labels)\n",
    "#     if ncol==5:\n",
    "#         printed_text += \"    p{\\dimexpr 0.35\\linewidth-2\\\\tabcolsep}|\"+\"\\n\"\n",
    "#         printed_text += \"    >{\\\\centering}p{\\dimexpr 0.13\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "#         printed_text += \"    >{\\\\centering}p{\\dimexpr 0.13\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "#         printed_text += \"    >{\\\\centering}p{\\dimexpr 0.13\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "#         printed_text += \"    >{\\\\centering}p{\\dimexpr 0.13\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "#         printed_text += \"    >{\\\\centering\\\\arraybackslash}p{\\dimexpr 0.13\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "#     elif ncol==4:\n",
    "#         printed_text += \"    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\"+\"\\n\"\n",
    "#         printed_text += \"    >{\\\\centering}p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "#         printed_text += \"    >{\\\\centering}p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "#         printed_text += \"    >{\\\\centering}p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "#         printed_text += \"    >{\\\\centering\\\\arraybackslash}p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "#     elif ncol==3:\n",
    "#         printed_text += \"    p{\\dimexpr 0.40\\linewidth-2\\\\tabcolsep}|\"+\"\\n\"\n",
    "#         printed_text += \"    >{\\\\centering}p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "#         printed_text += \"    >{\\\\centering}p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "#         printed_text += \"    >{\\\\centering\\\\arraybackslash}p{\\dimexpr 0.15\\linewidth-2\\\\tabcolsep}\"+\"\\n\"\n",
    "#     else:\n",
    "#         assert(False)\n",
    "        \n",
    "#     printed_text += \"}\"+\"\\n\"\n",
    "#     printed_text += \"    \\hline\"+\"\\n\"\n",
    "#     printed_text += \"    Lexical Features & \"+\" & \".join(coef_labels)+\"\\\\\\\\\"+\"\\n\"\n",
    "#     printed_text += \"    \\hline\"+\"\\n\"\n",
    "# #     printed_text += \"    \\endfirsthead\"+\"\\n\"\n",
    "# #     printed_text += \"\"+\"\\n\"\n",
    "#     printed_text += \"    \\endhead\"+\"\\n\"\n",
    "#     printed_text += \"\"+\"\\n\"\n",
    "    \n",
    "#     for sec, results in zip(sections, outputs):\n",
    "#         printed_text += \"    \\multicolumn{4}{l}{\\\\textit{\"+sec+\"}} \\\\\\\\\"+\"\\n\"\n",
    "#         printed_text += \"    \\hline\"+\"\\n\"\n",
    "        \n",
    "#         for m in metric_names[g]:\n",
    "#             s = f\"        {metric_names[g][m]} \"\n",
    "#             for l in coef_labels:   \n",
    "#                 k = (l, m)\n",
    "                \n",
    "#                 if k not in results:\n",
    "#                     s += f\"& - \"\n",
    "#                 else:\n",
    "#                     val, pval = results[k]\n",
    "#                     if l==\"Grand Mean\":\n",
    "#                         s += f\"& {val:.2f} \"\n",
    "#                     elif val is None:\n",
    "#                         s += f\"& - \" ## Base Category\n",
    "#                     elif pval < 0.05:\n",
    "#                         s += \"& \\cellcolor{gray!25} \"+f\"{val:.2f}* \"\n",
    "#                     else:\n",
    "#                         s += f\"& {val:.2f} \"\n",
    "#             s += \"\\\\\\\\\"\n",
    "#             # print(s)\n",
    "#             printed_text += s+\"\\n\"\n",
    "            \n",
    "        \n",
    "# #         printed_text += \"        &  & &\\\\\\\\\"+\"\\n\"\n",
    "#         printed_text += \"    \\hline\"+\"\\n\"\n",
    "#         printed_text += \"\"+\"\\n\"\n",
    "    \n",
    "#     printed_text += \"\\end{longtable}\"+\"\\n\"\n",
    "    \n",
    "    \n",
    "#     return printed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "925d851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_names_code = {\n",
    "# #     \"Corpus Statistics\": \"corp_stat\",\n",
    "#     \"Pronoun\": \"pronoun\",\n",
    "#     \"Sentence-ending Particles\": \"particle\",\n",
    "# #     \"Sentiment-related\": \"sentiment\",\n",
    "#     \"Spelling Variation\": \"spelling\",\n",
    "# }\n",
    "\n",
    "# printed_text = \"\" \n",
    "# for g in metric_names:\n",
    "#     if g in [\"Corpus Statistics\"]:\n",
    "#         continue\n",
    "        \n",
    "#     printed_text += \"\\subsection{\"+g+\"}\"+\"\\n\"+\"\\n\"\n",
    "    \n",
    "#     ###### Closeness Effect Coding #######\n",
    "#     coef_labels = {\n",
    "#         \"Grand Mean\": (\"coef0\", \"pval0\"),\n",
    "#         \"Close\": (\"coef1\", \"pval1\"),\n",
    "#         \"Acquainted\": (None, None),\n",
    "#         \"Unfamiliar\": (\"coef2\", \"pval2\"),\n",
    "#     }\n",
    "        \n",
    "#     outputs = [\n",
    "#         outputs_to_dict(clse1_effect_outputs, coef_labels),\n",
    "#         outputs_to_dict(clse2_effect_outputs, coef_labels),\n",
    "#         outputs_to_dict(clse3_effect_outputs, coef_labels),\n",
    "#     ]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     printed_text += get_printed_text_by_section(\n",
    "#         \"Regression Analysis on Closeness with Effect Coding\",\n",
    "#         coef_labels.keys(), \n",
    "#         outputs,\n",
    "#         \"tab:closeness_effect_\"+metric_names_code[g]\n",
    "#     )\n",
    "    \n",
    "#     ###### Closeness Polynomial Coding #######\n",
    "    \n",
    "#     coef_labels = {\n",
    "#         \"Grand Mean\": (\"coef0\", \"pval0\"),\n",
    "#         \"Linear\": (\"coef1\", \"pval1\"),\n",
    "#         \"Quadratic\": (\"coef2\", \"pval2\"),\n",
    "#     }\n",
    "    \n",
    "#     outputs = [\n",
    "#         outputs_to_dict(clse1_poly_outputs, coef_labels),\n",
    "#         outputs_to_dict(clse2_poly_outputs, coef_labels),\n",
    "#         outputs_to_dict(clse3_poly_outputs, coef_labels),\n",
    "#     ]\n",
    "    \n",
    "#     printed_text += get_printed_text_by_section(\n",
    "#         \"Regression Analysis on Closeness with Orthogonal Polynomial Coding\",\n",
    "#         coef_labels.keys(), \n",
    "#         outputs,\n",
    "#         \"tab:closeness_polynomial_\"+metric_names_code[g]\n",
    "#     )\n",
    "    \n",
    "#     printed_text += \"\\clearpage\"+\"\\n\\n\"\n",
    "    \n",
    "    \n",
    "#     ###### Respect Effect Coding #######\n",
    "    \n",
    "        \n",
    "#     coef_labels1 = {\n",
    "#         \"Grand Mean\": (\"coef0\", \"pval0\"),\n",
    "#         \"Highly Respectful\": (\"coef1\", \"pval1\"),\n",
    "#         \"Respectful\": (\"coef2\", \"pval2\"),\n",
    "#         \"Normal\": (None, None),\n",
    "#         \"Disrespectful\": (\"-\", \"-\"),\n",
    "#     }\n",
    "    \n",
    "#     coef_labels2 = {\n",
    "#         \"Grand Mean\": (\"coef0\", \"pval0\"),\n",
    "#         \"Highly Respectful\": (\"-\", \"-\"),\n",
    "#         \"Respectful\": (\"coef2\", \"pval2\"),\n",
    "#         \"Normal\": (None, None),\n",
    "#         \"Disrespectful\": (\"coef1\", \"pval1\"),\n",
    "        \n",
    "#     }\n",
    "    \n",
    "#     outputs = [\n",
    "#         outputs_to_dict(auth1_effect_outputs, coef_labels1),\n",
    "#         outputs_to_dict(auth2_effect_outputs, coef_labels2),\n",
    "#         outputs_to_dict(auth3_effect_outputs, coef_labels2),\n",
    "#     ]\n",
    "    \n",
    "    \n",
    "#     printed_text += get_printed_text_by_section(\n",
    "#         \"Regression Analysis on Respect with Effect Coding\",\n",
    "#         coef_labels1.keys(), \n",
    "#         outputs,\n",
    "#         \"tab:respect_effect_\"+metric_names_code[g]\n",
    "#     )\n",
    "    \n",
    "#     ###### Respect Polynomial Coding #######\n",
    "    \n",
    "#     coef_labels = {\n",
    "#         \"Grand Mean\": (\"coef0\", \"pval0\"),\n",
    "#         \"Linear\": (\"coef1\", \"pval1\"),\n",
    "#         \"Quadratic\": (\"coef2\", \"pval2\"),\n",
    "#     }\n",
    "    \n",
    "#     outputs = [\n",
    "#         outputs_to_dict(auth1_poly_outputs, coef_labels),\n",
    "#         outputs_to_dict(auth2_poly_outputs, coef_labels),\n",
    "#         outputs_to_dict(auth3_poly_outputs, coef_labels),\n",
    "#     ]\n",
    "    \n",
    "#     printed_text += get_printed_text_by_section(\n",
    "#         \"Regression Analysis on Respect with Orthogonal Polynomial Coding\",\n",
    "#         coef_labels.keys(), \n",
    "#         outputs,\n",
    "#         \"tab:respect_polynomial_\"+metric_names_code[g]\n",
    "#     )\n",
    "    \n",
    "#     printed_text += \"\\clearpage\"+\"\\n\\n\"\n",
    "    \n",
    "# #     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce97bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b5381ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(printed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4880a525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b156e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9603ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840fe80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
