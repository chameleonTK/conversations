{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a602036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def dump_jsonl(data, output_path, append=False, progress=False):\n",
    "    \"\"\"\n",
    "    Write list of objects to a JSON lines file.\n",
    "    \"\"\"\n",
    "    mode = 'a+' if append else 'w'\n",
    "    with open(output_path, mode, encoding='utf-8') as f:\n",
    "        if progress:\n",
    "            data = tqdm(data)\n",
    "            \n",
    "        for line in data:\n",
    "            json_record = json.dumps(line, ensure_ascii=False)\n",
    "            f.write(json_record + '\\n')\n",
    "    print('Wrote {} records to {}'.format(len(data), output_path))\n",
    "\n",
    "def load_jsonl(input_path, verbose=True, progress=False) -> list:\n",
    "    \"\"\"\n",
    "    Read list of objects from a JSON lines file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        if progress:\n",
    "            f = tqdm(f)\n",
    "            \n",
    "        for line in f:\n",
    "                data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "    \n",
    "    if verbose:\n",
    "        print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff94087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user0.jsonl  user1.jsonl  user2.jsonl  user3.jsonl\n"
     ]
    }
   ],
   "source": [
    "ls annotated/v0.1/closeness_v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e75440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "users = [\"user0\", \"user1\", \"user2\", \"user3\"]\n",
    "\n",
    "def authority_to_degree(label):\n",
    "    if label == 'B ให้เกียรติ':\n",
    "        return 3\n",
    "    elif label == 'B ทำตัวปกติ':\n",
    "        return 2\n",
    "    elif label == 'B ไม่ให้เกียรติกัน':\n",
    "        return 1\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def closeness_to_degree(label):\n",
    "    if label == 'สนิทกันมาก':\n",
    "        return 4\n",
    "    elif label == 'แค่คนรู้จักกัน':\n",
    "        return 3\n",
    "    elif label == 'ไม่รู้จักกัน':\n",
    "        return 2\n",
    "    elif label == 'ไม่ชอบหน้ากัน':\n",
    "        return 1\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def load_data(filename, column_name, to_degree):\n",
    "    annotated = load_jsonl(filename)\n",
    "    \n",
    "    _df = []\n",
    "    for row in annotated:\n",
    "        if len(row[\"label\"])==0:\n",
    "            continue\n",
    "\n",
    "        _df.append({\n",
    "            \"text\": row[\"text\"],\n",
    "            \"tweet\": row[\"tweet\"],\n",
    "            column_name: row[\"label\"][0],\n",
    "            f\"{column_name}_degree\": to_degree(row[\"label\"][0])\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e955bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# ordinal_weights\n",
    "def get_weights(categories):\n",
    "    weights = defaultdict(dict)\n",
    "    if len(categories)==3:\n",
    "        mat = [[1.00, 0.67, 0.00], \n",
    "               [0.67, 1.00, 0.67], \n",
    "               [0.00, 0.67, 1.00]]\n",
    "    elif len(categories)==4:\n",
    "        mat = [[1.00, 0.83, 0.50, 0.00], \n",
    "               [0.83, 1.00, 0.83, 0.50], \n",
    "               [0.50, 0.83, 1.00, 0.83], \n",
    "               [0.00, 0.50, 0.83, 1.00]]\n",
    "    elif len(categories)==5:\n",
    "        mat = [[1, 0.9, 0.7, 0.4, 0.0], \n",
    "               [0.9, 1, 0.9, 0.7, 0.4], \n",
    "               [0.7, 0.9, 1, 0.9, 0.7], \n",
    "               [0.4, 0.7, 0.9, 1, 0.9],\n",
    "               [0.0, 0.4, 0.7, 0.9, 1]]\n",
    "    else:\n",
    "        # Lazy to implement in case of len(categories) > 5\n",
    "        raise Exception(\"No Implementation\")\n",
    "        \n",
    "    for i, l in enumerate(categories): \n",
    "        for j, k in enumerate(categories): \n",
    "            weights[l][k] = mat[i][j]\n",
    "    return weights\n",
    "\n",
    "    \n",
    "def cal_agreement(df1, df2, column, categories, cat_column):\n",
    "    merged = pd.merge(df1, df2, on=column)\n",
    "#     assert(len(df1)==len(merged))\n",
    "    merged = merged.dropna()    \n",
    "    cnt_matrix = defaultdict(dict)\n",
    "    acc_matrix = defaultdict(dict)\n",
    "    \n",
    "    for l in categories: \n",
    "        for k in categories: \n",
    "            d = merged\n",
    "            d = d[d[f\"{cat_column}_x\"]==k]\n",
    "            d = d[d[f\"{cat_column}_y\"]==l]\n",
    "            cnt_matrix[l][k] = len(d)\n",
    "    \n",
    "    for l in categories: \n",
    "        d = merged\n",
    "        d = d[d[f\"{cat_column}_x\"]==l]\n",
    "        acc_matrix[\"x\"][l] = len(d)\n",
    "        \n",
    "        d = merged\n",
    "        d = d[d[f\"{cat_column}_y\"]==l]\n",
    "        acc_matrix[\"y\"][l] = len(d)\n",
    "    \n",
    "    weights = get_weights(categories)\n",
    "    \n",
    "    N = len(merged)\n",
    "    Pa = 0\n",
    "    for l in categories: \n",
    "        for k in categories: \n",
    "            Pa += weights[l][k]*cnt_matrix[l][k]/N\n",
    "    \n",
    "    Pe = 0\n",
    "    for l in categories: \n",
    "        for k in categories: \n",
    "            Pe += weights[l][k]*(acc_matrix[\"x\"][l]/N)*(acc_matrix[\"y\"][k]/N)\n",
    "    \n",
    "    if Pe==1:\n",
    "        raise Exception(\"Divide by zero\")\n",
    "    \n",
    "    kappa = (Pa-Pe)/(1-Pe)\n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4c200",
   "metadata": {},
   "source": [
    "# Test Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4a89685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 records from annotated/v0.1/authority_v0.1/user0.jsonl\n",
      "Loaded 20 records from annotated/v0.1/closeness_v0.1/user0.jsonl\n",
      "Loaded 20 records from annotated/v0.1/authority_v0.1/user1.jsonl\n",
      "Loaded 20 records from annotated/v0.1/closeness_v0.1/user1.jsonl\n",
      "Loaded 20 records from annotated/v0.1/authority_v0.1/user2.jsonl\n",
      "Loaded 20 records from annotated/v0.1/closeness_v0.1/user2.jsonl\n",
      "Loaded 20 records from annotated/v0.1/authority_v0.1/user3.jsonl\n",
      "Loaded 20 records from annotated/v0.1/closeness_v0.1/user3.jsonl\n"
     ]
    }
   ],
   "source": [
    "auth_df = {}\n",
    "clos_df = {}\n",
    "for u in users:\n",
    "    auth_df[u] = load_data(f\"annotated/v0.1/authority_v0.1/{u}.jsonl\", \"authority\", authority_to_degree)\n",
    "    clos_df[u] = load_data(f\"annotated/v0.1/closeness_v0.1/{u}.jsonl\", \"closeness\", closeness_to_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7743df87-c341-413e-99ea-a8fc4aa3e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "51247a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authority\n",
      "user1 0.5152998776009788\n",
      "user2 0.5152998776009788\n",
      "user3 0.5119356512714061\n",
      "[0.5152998776009788, 0.5152998776009788, 0.5119356512714061] 0.5141784688244546\n"
     ]
    }
   ],
   "source": [
    "print(\"Authority\")\n",
    "alliaa = []\n",
    "for u in users[1:]:\n",
    "    iaa = cal_agreement(auth_df[\"user0\"], auth_df[u], column=\"tweet\", categories=[1,2,3], cat_column=\"authority_degree\")\n",
    "    print(u, iaa)\n",
    "    alliaa.append(iaa)\n",
    "    \n",
    "print(alliaa, np.mean(alliaa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "420f6cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closeness\n",
      "user1 0.6161425159235672\n",
      "user2 0.6734563971992363\n",
      "user3 0.6373333333333332\n",
      "[0.6161425159235672, 0.6734563971992363, 0.6373333333333332] 0.6423107488187122\n"
     ]
    }
   ],
   "source": [
    "print(\"Closeness\")\n",
    "alliaa = []\n",
    "for u in users[1:]:\n",
    "    iaa = cal_agreement(clos_df[\"user0\"], clos_df[u], column=\"tweet\", categories=[1,2,3,4], cat_column=\"closeness_degree\")\n",
    "    print(u, iaa)\n",
    "    alliaa.append(iaa)\n",
    "    \n",
    "print(alliaa, np.mean(alliaa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21491e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c3c1f7-5954-4704-ae18-7df7bb3112de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19321f-ba25-43d9-8275-ca56c39922bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
